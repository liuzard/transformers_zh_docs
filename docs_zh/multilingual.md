<!--ç‰ˆæƒæ‰€æœ‰2022å¹´HuggingFaceå›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apacheè®¸å¯è¯ç¬¬2.0ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰è·å¾—è®¸å¯ï¼›é™¤éç¬¦åˆè®¸å¯è¯çš„è§„å®šï¼Œå¦åˆ™ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚æ‚¨å¯ä»¥åœ¨

http://www.apache.org/licenses/LICENSE-2.0
   
è·å¾—è®¸å¯è¯çš„å‰¯æœ¬
é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯æŒ‰"åŸæ ·"åˆ†å‘
åŸºç¡€ï¼Œæ— è®ºæ˜ç¤ºæˆ–æš—ç¤ºï¼ŒåŒ…æ‹¬ä½†ä¸é™äºå¯¹é€‚é”€æ€§ã€ç‰¹å®šç›®çš„çš„é€‚ç”¨æ€§å’Œéä¾µæƒæ€§çš„ä¿è¯ã€‚æœ‰å…³è®¸å¯è¯çš„è¯¦ç»†ä¿¡æ¯è¯·å‚è§

è®¸å¯ä¸‹çš„ç‰¹å®šè¯­è¨€å’Œé™åˆ¶ã€‚

âš ï¸è¯·æ³¨æ„ï¼Œè¿™ä¸ªæ–‡ä»¶æ˜¯Markdownæ ¼å¼çš„ï¼Œä½†å«æœ‰æˆ‘ä»¬çš„doc-builderçš„ç‰¹å®šè¯­æ³•ï¼ˆç±»ä¼¼äºMDXï¼‰ï¼Œåœ¨æ‚¨çš„MarkdownæŸ¥çœ‹å™¨ä¸­å¯èƒ½æ— æ³•æ­£ç¡®æ¸²æŸ“ã€‚

-->

# ç”¨äºæ¨ç†çš„å¤šè¯­è¨€æ¨¡å‹

[[open-in-colab]]

åœ¨ğŸ¤— Transformersä¸­æœ‰å‡ ä¸ªå¤šè¯­è¨€æ¨¡å‹ï¼Œå®ƒä»¬ä¸å•è¯­è¨€æ¨¡å‹çš„æ¨ç†ä½¿ç”¨æ–¹å¼ä¸åŒã€‚å½“ç„¶ï¼Œå¹¶ä¸æ˜¯*æ‰€æœ‰*çš„å¤šè¯­è¨€æ¨¡å‹çš„ç”¨æ³•éƒ½ä¸åŒã€‚æœ‰äº›æ¨¡å‹ï¼Œä¾‹å¦‚[bert-base-multilingual-uncased](https://huggingface.co/bert-base-multilingual-uncased)ï¼Œå¯ä»¥åƒå•è¯­è¨€æ¨¡å‹ä¸€æ ·ä½¿ç”¨ã€‚æœ¬æŒ‡å—å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨åœ¨æ¨ç†ä¸­ç”¨æ³•ä¸åŒçš„å¤šè¯­è¨€æ¨¡å‹ã€‚

## XLM

XLMæœ‰åä¸ªä¸åŒçš„æ£€æŸ¥ç‚¹ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªæ˜¯å•è¯­è¨€çš„ã€‚å…¶ä½™ä¹ä¸ªæ¨¡å‹æ£€æŸ¥ç‚¹å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šä½¿ç”¨è¯­è¨€åµŒå…¥å’Œä¸ä½¿ç”¨è¯­è¨€åµŒå…¥çš„æ£€æŸ¥ç‚¹ã€‚

### å¸¦æœ‰è¯­è¨€åµŒå…¥çš„XLM

ä»¥ä¸‹XLMæ¨¡å‹åœ¨æ¨ç†ä¸­ä½¿ç”¨è¯­è¨€åµŒå…¥æ¥æŒ‡å®šæ‰€ä½¿ç”¨çš„è¯­è¨€ï¼š

- `xlm-mlm-ende-1024` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹ï¼Œè‹±æ–‡-å¾·æ–‡ï¼‰
- `xlm-mlm-enfr-1024` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹ï¼Œè‹±æ–‡-æ³•æ–‡ï¼‰
- `xlm-mlm-enro-1024` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹ï¼Œè‹±æ–‡-ç½—é©¬å°¼äºšæ–‡ï¼‰
- `xlm-mlm-xnli15-1024` ï¼ˆè¯­è¨€æ©ç æ¨¡å‹ï¼ŒXNLIè¯­è¨€ï¼‰
- `xlm-mlm-tlm-xnli15-1024` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹+ç¿»è¯‘ï¼ŒXNLIè¯­è¨€ï¼‰
- `xlm-clm-enfr-1024` ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±æ–‡-æ³•æ–‡ï¼‰
- `xlm-clm-ende-1024` ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±æ–‡-å¾·æ–‡ï¼‰

è¯­è¨€åµŒå…¥è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªä¸ä¼ é€’ç»™æ¨¡å‹çš„`input_ids`å½¢çŠ¶ç›¸åŒçš„å¼ é‡ã€‚è¿™äº›å¼ é‡ä¸­çš„å€¼å–å†³äºæ‰€ä½¿ç”¨çš„è¯­è¨€ï¼Œå¹¶ç”±åˆ†è¯å™¨çš„`lang2id`å’Œ`id2lang`å±æ€§è¿›è¡Œè¯†åˆ«ã€‚

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½`xlm-clm-enfr-1024`æ£€æŸ¥ç‚¹ï¼ˆå› æœè¯­è¨€å»ºæ¨¡ï¼Œè‹±æ³•åŒè¯­ï¼‰ï¼š

```py
>>> import torch
>>> from transformers import XLMTokenizer, XLMWithLMHeadModel

>>> tokenizer = XLMTokenizer.from_pretrained("xlm-clm-enfr-1024")
>>> model = XLMWithLMHeadModel.from_pretrained("xlm-clm-enfr-1024")
```

åˆ†è¯å™¨çš„`lang2id`å±æ€§æ˜¾ç¤ºäº†æ­¤æ¨¡å‹çš„è¯­è¨€åŠå…¶IDï¼š

```py
>>> print(tokenizer.lang2id)
{'en': 0, 'fr': 1}
```

æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªç¤ºä¾‹è¾“å…¥ï¼š

```py
>>> input_ids = torch.tensor([tokenizer.encode("Wikipedia was used to")])  # æ‰¹é‡å¤§å°ä¸º1
```

å°†è¯­è¨€IDè®¾ç½®ä¸º`"en"`ï¼Œå¹¶ä½¿ç”¨å…¶å®šä¹‰è¯­è¨€åµŒå…¥ã€‚è¯­è¨€åµŒå…¥æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œå¡«å……ä¸º`0`ï¼Œå› ä¸ºè¿™æ˜¯è‹±è¯­çš„è¯­è¨€IDã€‚è¿™ä¸ªå¼ é‡çš„å¤§å°åº”ä¸`input_ids`ç›¸åŒã€‚

```py
>>> language_id = tokenizer.lang2id["en"]  # 0
>>> langs = torch.tensor([language_id] * input_ids.shape[1])  # torch.tensor([0, 0, 0, ..., 0])

>>> # å°†å…¶é‡å¡‘ä¸ºå¤§å°ä¸ºï¼ˆbatch_sizeï¼Œsequence_lengthï¼‰
>>> langs = langs.view(1, -1)  # ç°åœ¨çš„å½¢çŠ¶æ˜¯[1ï¼Œsequence_length]ï¼ˆæ‰¹é‡å¤§å°ä¸º1ï¼‰
```

ç°åœ¨ï¼Œå¯ä»¥å°†`input_ids`å’Œè¯­è¨€åµŒå…¥ä¼ é€’ç»™æ¨¡å‹ï¼š

```py
>>> outputs = model(input_ids, langs=langs)
```

[run_generation.py](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py)è„šæœ¬å¯ä»¥ä½¿ç”¨å¸¦æœ‰è¯­è¨€åµŒå…¥çš„`xlm-clm`æ£€æŸ¥ç‚¹ç”Ÿæˆæ–‡æœ¬ã€‚

### ä¸å¸¦è¯­è¨€åµŒå…¥çš„XLM

ä»¥ä¸‹XLMæ¨¡å‹åœ¨æ¨ç†ä¸­ä¸éœ€è¦è¯­è¨€åµŒå…¥ï¼š

- `xlm-mlm-17-1280` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹ï¼Œ17ç§è¯­è¨€ï¼‰
- `xlm-mlm-100-1280` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹ï¼Œ100ç§è¯­è¨€ï¼‰

è¿™äº›æ¨¡å‹ç”¨äºé€šç”¨çš„å¥å­è¡¨ç¤ºï¼Œä¸å‰é¢çš„XLMæ£€æŸ¥ç‚¹ä¸åŒã€‚

## BERT

ä»¥ä¸‹BERTæ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ä»»åŠ¡ï¼š

- `bert-base-multilingual-uncased` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹+ä¸‹ä¸€å¥é¢„æµ‹ï¼Œ102ç§è¯­è¨€ï¼‰
- `bert-base-multilingual-cased` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹+ä¸‹ä¸€å¥é¢„æµ‹ï¼Œ104ç§è¯­è¨€ï¼‰

è¿™äº›æ¨¡å‹åœ¨æ¨ç†ä¸­ä¸éœ€è¦è¯­è¨€åµŒå…¥ã€‚å®ƒä»¬åº”æ ¹æ®ä¸Šä¸‹æ–‡è¯†åˆ«è¯­è¨€å¹¶è¿›è¡Œæ¨ç†ã€‚

## XLM-RoBERTa

ä»¥ä¸‹XLM-RoBERTaæ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ä»»åŠ¡ï¼š

- `xlm-roberta-base` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹ï¼Œ100ç§è¯­è¨€ï¼‰
- `xlm-roberta-large` ï¼ˆè¯­è¨€æ©è”½æ¨¡å‹ï¼Œ100ç§è¯­è¨€ï¼‰

XLM-RoBERTaåœ¨100ç§è¯­è¨€çš„æ–°åˆ›å»ºå’Œæ¸…ç†çš„CommonCrawlæ•°æ®ä¸Šè¿›è¡Œäº†2.5TBçš„è®­ç»ƒã€‚ç›¸æ¯”å…ˆå‰å‘å¸ƒçš„å¤šè¯­è¨€æ¨¡å‹ï¼ˆå¦‚mBERTæˆ–XLMï¼‰ï¼Œå®ƒåœ¨åˆ†ç±»ã€åºåˆ—æ ‡æ³¨å’Œé—®ç­”ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸Šæä¾›äº†å¾ˆå¤§çš„æ”¹è¿›ã€‚

## M2M100

ä»¥ä¸‹M2M100æ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ç¿»è¯‘ï¼š

- `facebook/m2m100_418M` ï¼ˆç¿»è¯‘ï¼‰
- `facebook/m2m100_1.2B` ï¼ˆç¿»è¯‘ï¼‰

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½`facebook/m2m100_418M`æ£€æŸ¥ç‚¹ï¼Œå°†ä¸­æ–‡ç¿»è¯‘ä¸ºè‹±æ–‡ã€‚æ‚¨å¯ä»¥åœ¨åˆ†è¯å™¨ä¸­è®¾ç½®æºè¯­è¨€ï¼š

```py
>>> from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer

>>> en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
>>> chinese_text = "ä¸è¦æ’æ‰‹å·«å¸ˆçš„äº‹åŠ¡, å› ä¸ºä»–ä»¬æ˜¯å¾®å¦™çš„, å¾ˆå¿«å°±ä¼šå‘æ€’."

>>> tokenizer = M2M100Tokenizer.from_pretrained("facebook/m2m100_418M", src_lang="zh")
>>> model = M2M100ForConditionalGeneration.from_pretrained("facebook/m2m100_418M")
```

å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼š

```py
>>> encoded_zh = tokenizer(chinese_text, return_tensors="pt")
```

M2M100è¦æ±‚å°†ç›®æ ‡è¯­è¨€IDä½œä¸ºç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°ï¼Œä»¥å°†å…¶ç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€ã€‚åœ¨`generate`æ–¹æ³•ä¸­ï¼Œå°†`forced_bos_token_id`è®¾ç½®ä¸º`en`ä»¥å°†å…¶ç¿»è¯‘ä¸ºè‹±è¯­ï¼š

```py
>>> generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id("en"))
>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
'Do not interfere with the matters of the witches, because they are delicate and will soon be angry.'
```

## MBart

ä»¥ä¸‹MBartæ¨¡å‹å¯ç”¨äºå¤šè¯­è¨€ç¿»è¯‘ï¼š

- `facebook/mbart-large-50-one-to-many-mmt` ï¼ˆä¸€å¯¹å¤šå¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰
- `facebook/mbart-large-50-many-to-many-mmt` ï¼ˆå¤šå¯¹å¤šå¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰
- `facebook/mbart-large-50-many-to-one-mmt` ï¼ˆå¤šå¯¹ä¸€å¤šè¯­è¨€æœºå™¨ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰
- `facebook/mbart-large-50` ï¼ˆå¤šè¯­è¨€ç¿»è¯‘ï¼Œ50ç§è¯­è¨€ï¼‰
- `facebook/mbart-large-cc25`

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼ŒåŠ è½½`facebook/mbart-large-50-many-to-many-mmt`æ£€æŸ¥ç‚¹ï¼Œå°†èŠ¬å…°è¯­ç¿»è¯‘ä¸ºè‹±è¯­ã€‚æ‚¨å¯ä»¥åœ¨åˆ†è¯å™¨ä¸­è®¾ç½®æºè¯­è¨€ï¼š

```py
>>> from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

>>> en_text = "Do not meddle in the affairs of wizards, for they are subtle and quick to anger."
>>> fi_text = "Ã„lÃ¤ sekaannu velhojen asioihin, sillÃ¤ ne ovat hienovaraisia ja nopeasti vihaisia."

>>> tokenizer = AutoTokenizer.from_pretrained("facebook/mbart-large-50-many-to-many-mmt", src_lang="fi_FI")
>>> model = AutoModelForSeq2SeqLM.from_pretrained("facebook/mbart-large-50-many-to-many-mmt")
```

å¯¹æ–‡æœ¬è¿›è¡Œåˆ†è¯ï¼š

```py
>>> encoded_en = tokenizer(en_text, return_tensors="pt")
```

MBartè¦æ±‚å°†ç›®æ ‡è¯­è¨€IDä½œä¸ºç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°ï¼Œä»¥å°†å…¶ç¿»è¯‘ä¸ºç›®æ ‡è¯­è¨€ã€‚åœ¨`generate`æ–¹æ³•ä¸­ï¼Œå°†`forced_bos_token_id`è®¾ç½®ä¸º`en_XX`ä»¥å°†å…¶ç¿»è¯‘ä¸ºè‹±è¯­ï¼š

```py
>>> generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id["en_XX"])
>>> tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)
"Don't interfere with the wizard's affairs, because they are subtle, will soon get angry."
```

ä½¿ç”¨`facebook/mbart-large-50-many-to-one-mmt`æ£€æŸ¥ç‚¹æ—¶ï¼Œä¸éœ€è¦å¼ºåˆ¶è®¾ç½®ç›®æ ‡è¯­è¨€IDä½œä¸ºç¬¬ä¸€ä¸ªç”Ÿæˆçš„æ ‡è®°ï¼Œå¦åˆ™ç”¨æ³•ç›¸åŒã€‚