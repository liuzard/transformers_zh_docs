<!--ç‰ˆæƒ 2022 The HuggingFace Teamã€‚ç‰ˆæƒæ‰€æœ‰ã€‚

æ ¹æ® Apache è®¸å¯è¯ç¬¬2ç‰ˆï¼ˆ"è®¸å¯è¯"ï¼‰ï¼Œä½ é™¤äº†éµå®ˆè®¸å¯è¯çš„è§„å®šä¹‹å¤–ï¼Œä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚
ä½ å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è·å–è®¸å¯è¯çš„å‰¯æœ¬:

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯æŒ‰"åŸæ ·"åˆ†å‘çš„ï¼Œæ²¡æœ‰ä»»ä½•æ‹…ä¿æˆ–æ¡ä»¶ï¼Œä¸è®ºæ˜¯æ˜ç¤ºçš„è¿˜æ˜¯éšå«çš„ã€‚è¯·å‚é˜…è®¸å¯è¯è·å–æ›´å¤šä¿¡æ¯ã€‚

âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯ä½¿ç”¨ Markdown ç¼–å†™çš„ï¼Œä½†åŒ…å«ç‰¹å®šäºæˆ‘ä»¬çš„ doc-builder çš„è¯­æ³•ï¼ˆç±»ä¼¼äº MDXï¼‰ï¼Œè¿™å¯èƒ½åœ¨ä½ çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ— æ³•æ­£ç¡®æ¸²æŸ“ã€‚

-->

# Pipelinesç”¨äºæ¨ç†

[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)ä½¿å¾—åœ¨ä»»ä½•è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸Šä½¿ç”¨[Hub](https://huggingface.co/models)ä¸­çš„ä»»ä½•æ¨¡å‹å˜å¾—éå¸¸ç®€å•ã€‚å³ä½¿ä½ å¯¹ç‰¹å®šæ¨¡æ€æ²¡æœ‰ç»éªŒæˆ–ä¸ç†Ÿæ‚‰æ¨¡å‹èƒŒåçš„åº•å±‚ä»£ç ï¼Œä½ ä»ç„¶å¯ä»¥ä½¿ç”¨[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)è¿›è¡Œæ¨ç†ï¼æœ¬æ•™ç¨‹å°†æ•™ä½ ï¼š

- ä½¿ç”¨[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)è¿›è¡Œæ¨ç†ã€‚
- ä½¿ç”¨ç‰¹å®šçš„åˆ†è¯å™¨æˆ–æ¨¡å‹ã€‚
- åœ¨éŸ³é¢‘ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸­ä½¿ç”¨[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)ã€‚

æ³¨æ„ï¼š

>æŸ¥çœ‹[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)æ–‡æ¡£ï¼Œä»¥è·å–æ”¯æŒçš„ä»»åŠ¡åˆ—è¡¨å’Œå¯ç”¨å‚æ•°çš„å®Œæ•´ä¿¡æ¯ã€‚



## Pipelineä½¿ç”¨æ–¹æ³•

è™½ç„¶æ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªç›¸å…³è”çš„[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)ï¼Œä½†ä½¿ç”¨é€šç”¨çš„[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)æŠ½è±¡æ›´ä¸ºç®€å•ï¼Œè¯¥æŠ½è±¡åŒ…å«äº†æ‰€æœ‰ç‰¹å®šä»»åŠ¡çš„pipelinesã€‚[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)ä¼šè‡ªåŠ¨åŠ è½½é»˜è®¤æ¨¡å‹å’Œé€‚ç”¨äºä½ æ‰€å¤„ç†ä»»åŠ¡çš„é¢„å¤„ç†ç±»ï¼Œä»¥å®ç°æ¨ç†åŠŸèƒ½ã€‚

1. é¦–å…ˆåˆ›å»ºä¸€ä¸ª[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)å¹¶æŒ‡å®šä¸€ä¸ªæ¨ç†ä»»åŠ¡ï¼š

```py
>>> from transformers import pipeline

>>> generator = pipeline(task="automatic-speech-recognition")
```

2. å°†è¾“å…¥æ–‡æœ¬ä¼ é€’ç»™[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)ï¼š

```py
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}
```

ç»“æœä¸ç¬¦åˆä½ çš„æœŸæœ›ï¼Ÿè¯·æŸ¥çœ‹Hubä¸Šä¸€äº›[æœ€å—æ¬¢è¿çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads)ï¼Œçœ‹çœ‹æ˜¯å¦å¯ä»¥è·å¾—æ›´å¥½çš„è½¬å½•ç»“æœã€‚ 

è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹[openai/whisper-large](https://huggingface.co/openai/whisper-large)ï¼š

```py
>>> generator = pipeline(model="openai/whisper-large")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

ç°åœ¨çš„ç»“æœçœ‹èµ·æ¥æ›´å‡†ç¡®äº†ï¼

æˆ‘ä»¬é¼“åŠ±ä½ åœ¨Hubä¸Šå¯»æ‰¾é€‚ç”¨äºä¸åŒè¯­è¨€ã€ä¸“é—¨é’ˆå¯¹ä½ é¢†åŸŸçš„æ¨¡å‹ã€‚ä½ å¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨ä¸ŠæŸ¥çœ‹å’Œæ¯”è¾ƒHubä¸Šçš„æ¨¡å‹ç»“æœï¼Œä»¥ç¡®å®šæ˜¯å¦ç¬¦åˆä½ çš„éœ€æ±‚æˆ–æ˜¯å¦èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ç‰¹æ®Šæƒ…å†µã€‚å¦‚æœä½ æ²¡æœ‰æ‰¾åˆ°é€‚åˆä½ ç”¨ä¾‹çš„æ¨¡å‹ï¼Œä½ å§‹ç»ˆå¯ä»¥å¼€å§‹[è®­ç»ƒ](http://liuzard.com/tag/ä¸­æ–‡/)è‡ªå·±çš„æ¨¡å‹ï¼

å¦‚æœä½ æœ‰å¤šä¸ªè¾“å…¥ï¼Œä½ å¯ä»¥å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)ï¼š

```py
generator(
    [
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac",
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac",
    ]
)
```

å¦‚æœä½ æƒ³è¿­ä»£æ•´ä¸ªæ•°æ®é›†ï¼Œæˆ–è€…æƒ³å°†å…¶ç”¨äºWebæœåŠ¡å™¨ä¸­çš„æ¨ç†ï¼Œè¯·æŸ¥çœ‹ä¸“é—¨çš„éƒ¨åˆ†

[åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨pipelines](#using-pipelines-on-a-dataset)

[åœ¨WebæœåŠ¡å™¨ä¸Šä½¿ç”¨pipelines](pipeline_webserver.md)

## å‚æ•°

[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)æ”¯æŒè®¸å¤šå‚æ•°ï¼›å…¶ä¸­ä¸€äº›æ˜¯ç‰¹å®šäºä»»åŠ¡çš„ï¼Œè€Œå¦ä¸€äº›æ˜¯é€‚ç”¨äºæ‰€æœ‰pipelinesçš„é€šç”¨å‚æ•°ã€‚
ä¸€èˆ¬æ¥è¯´ï¼Œä½ å¯ä»¥åœ¨ä»»ä½•åœ°æ–¹æŒ‡å®šå‚æ•°ï¼š

```py
generator = pipeline(model="openai/whisper-large", my_parameter=1)
out = generator(...)  # This will use `my_parameter=1`.
out = generator(..., my_parameter=2)  # This will override and use `my_parameter=2`.
out = generator(...)  # This will go back to using `my_parameter=1`.
```

è®©æˆ‘ä»¬æŸ¥çœ‹ä¸‰ä¸ªé‡è¦çš„å‚æ•°ï¼š

### è®¾å¤‡ï¼ˆDeviceï¼‰

å¦‚æœä½ ä½¿ç”¨`device=n`ï¼Œåˆ™[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)ä¼šè‡ªåŠ¨å°†æ¨¡å‹æ”¾ç½®åœ¨æŒ‡å®šçš„è®¾å¤‡ä¸Šã€‚
æ— è®ºä½ æ˜¯ä½¿ç”¨PyTorchè¿˜æ˜¯Tensorflowï¼Œéƒ½å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‚æ•°ã€‚

```py
generator = pipeline(model="openai/whisper-large", device=0)
```

å¦‚æœæ¨¡å‹å¯¹äºå•ä¸ªGPUæ¥è¯´å¤ªå¤§äº†ï¼Œä½ å¯ä»¥å°†`device_map="auto"`è®¾ç½®ä¸ºå…è®¸ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate)è‡ªåŠ¨ç¡®å®šå¦‚ä½•åŠ è½½å’Œå­˜å‚¨æ¨¡å‹æƒé‡ã€‚

```py
#!pip install accelerate
generator = pipeline(model="openai/whisper-large", device_map="auto")
```

è¯·æ³¨æ„ï¼Œå¦‚æœä¼ é€’äº†`device_map="auto"`å‚æ•°ï¼Œåˆ™åœ¨å®ä¾‹åŒ–[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)æ—¶ä¸éœ€è¦æ·»åŠ `device=device`å‚æ•°ï¼Œå¦åˆ™å¯èƒ½ä¼šé‡åˆ°ä¸€äº›æ„å¤–çš„è¡Œä¸ºï¼

### æ‰¹å¤„ç†å¤§å°ï¼ˆBatch sizeï¼‰

é»˜è®¤æƒ…å†µä¸‹ï¼Œpipelinesä¸ä¼šå¯¹æ¨ç†è¿›è¡Œæ‰¹å¤„ç†ï¼Œè¯¦ç»†åŸå› å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)æ‰¾åˆ°ã€‚åŸå› æ˜¯æ‰¹å¤„ç†å¹¶ä¸ä¸€å®šæ›´å¿«ï¼Œè€Œä¸”åœ¨æŸäº›æƒ…å†µä¸‹å®é™…ä¸Šå¯èƒ½æ›´æ…¢ã€‚

ä½†æ˜¯ï¼Œå¦‚æœåœ¨ä½ çš„ç”¨ä¾‹ä¸­å¯ä»¥ä½¿ç”¨æ‰¹å¤„ç†ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹å¼ï¼š

```py
generator = pipeline(model="openai/whisper-large", device=0, batch_size=2)
audio_filenames = [f"audio_{i}.flac" for i in range(10)]
texts = generator(audio_filenames)
```

è¿™ä¼šå¯¹æä¾›çš„10ä¸ªéŸ³é¢‘æ–‡ä»¶è¿è¡Œpipelineï¼Œä½†å®ƒä¼šå°†å®ƒä»¬ä»¥2ä¸ªä¸€ç»„çš„æ‰¹æ¬¡ä¼ é€’ç»™æ¨¡å‹ï¼ˆæ¨¡å‹ä½äºGPUä¸Šï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ‰¹å¤„ç†å¯èƒ½æ›´æœ‰å¸®åŠ©ï¼‰ï¼Œè€Œæ— éœ€ä½ è¿›ä¸€æ­¥ç¼–å†™ä»»ä½•ä»£ç ã€‚ è¾“å‡ºåº”è¯¥å§‹ç»ˆä¸ä½ åœ¨æ²¡æœ‰æ‰¹å¤„ç†çš„æƒ…å†µä¸‹æ¥æ”¶åˆ°çš„ç»“æœç›¸åŒ¹é…ã€‚è¿™åªæ˜¯ä¸€ç§å¸®åŠ©ä½ æé«˜pipelineé€Ÿåº¦çš„æ–¹å¼ã€‚

pipelinesè¿˜å¯ä»¥å‡è½»æ‰¹å¤„ç†çš„ä¸€äº›å¤æ‚æ€§ï¼Œå› ä¸ºå¯¹äºæŸäº›pipelinesæ¥è¯´ï¼Œéœ€è¦å°†å•ä¸ªè¾“å…¥ï¼ˆå¦‚é•¿éŸ³é¢‘æ–‡ä»¶ï¼‰åˆ†æˆå¤šä¸ªéƒ¨åˆ†ä»¥ä¾›æ¨¡å‹å¤„ç†ã€‚pipelineä¼šä¸ºä½ æ‰§è¡Œè¿™ç§[*chunk batching*](http://liuzard.com/main_classes/pipelines#pipeline-chunk-batching)ã€‚

### ç‰¹å®šä»»åŠ¡çš„å‚æ•°

æ‰€æœ‰ä»»åŠ¡éƒ½æä¾›ç‰¹å®šä»»åŠ¡çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°å…è®¸é¢å¤–çš„çµæ´»æ€§å’Œé€‰é¡¹ï¼Œä»¥å¸®åŠ©ä½ å®Œæˆå·¥ä½œã€‚ ä¾‹å¦‚ï¼Œ[`transformers.AutomaticSpeechRecognitionPipeline.__call__`](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.AutomaticSpeechRecognitionPipeline.__call__)æ–¹æ³•å…·æœ‰ä¸€ä¸ª`return_timestamps`å‚æ•°ï¼Œå¯¹äºä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•ä¼¼ä¹æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„é€‰æ‹©ã€‚

```py
>>> # Not using whisper, as it cannot provide timestamps.
>>> generator = pipeline(model="facebook/wav2vec2-large-960h-lv60-self", return_timestamps="word")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP AND LIVE OUT THE TRUE MEANING OF ITS CREED', 'chunks': [{'text': 'I', 'timestamp': (1.22, 1.24)}, {'text': 'HAVE', 'timestamp': (1.42, 1.58)}, {'text': 'A', 'timestamp': (1.66, 1.68)}, {'text': 'DREAM', 'timestamp': (1.76, 2.14)}, {'text': 'BUT', 'timestamp': (3.68, 3.8)}, {'text': 'ONE', 'timestamp': (3.94, 4.06)}, {'text': 'DAY', 'timestamp': (4.16, 4.3)}, {'text': 'THIS', 'timestamp': (6.36, 6.54)}, {'text': 'NATION', 'timestamp': (6.68, 7.1)}, {'text': 'WILL', 'timestamp': (7.32, 7.56)}, {'text': 'RISE', 'timestamp': (7.8, 8.26)}, {'text': 'UP', 'timestamp': (8.38, 8.48)}, {'text': 'AND', 'timestamp': (10.08, 10.18)}, {'text': 'LIVE', 'timestamp': (10.26, 10.48)}, {'text': 'OUT', 'timestamp': (10.58, 10.7)}, {'text': 'THE', 'timestamp': (10.82, 10.9)}, {'text': 'TRUE', 'timestamp': (10.98, 11.18)}, {'text': 'MEANING', 'timestamp': (11.26, 11.58)}, {'text': 'OF', 'timestamp': (11.66, 11.7)}, {'text': 'ITS', 'timestamp': (11.76, 11.88)}, {'text': 'CREED', 'timestamp': (12.0, 12.38)}]}
```

æ­£å¦‚ä½ æ‰€è§ï¼Œæ¨¡å‹æ¨æ–­å‡ºäº†æ–‡æœ¬ï¼Œå¹¶è¾“å‡ºäº†å¥å­ä¸­å„ä¸ªå•è¯çš„å‘éŸ³æ—¶é—´ã€‚

æ¯ä¸ªä»»åŠ¡éƒ½æœ‰è®¸å¤šå¯ç”¨çš„å‚æ•°ï¼Œå› æ­¤è¯·æŸ¥çœ‹æ¯ä¸ªä»»åŠ¡çš„APIå‚è€ƒï¼Œäº†è§£ä½ å¯ä»¥è¿›è¡Œå“ªäº›è°ƒæ•´ï¼ä¾‹å¦‚ï¼Œ[`~transformers.AutomaticSpeechRecognitionPipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.AutomaticSpeechRecognitionPipeline)å…·æœ‰ä¸€ä¸ª`chunk_length_s`å‚æ•°ï¼Œå¯¹äºå¤„ç†éå¸¸é•¿çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œä¸ºæ•´éƒ¨ç”µå½±æˆ–é•¿è¾¾ä¸€å°æ—¶çš„è§†é¢‘æ·»åŠ å­—å¹•ï¼‰éå¸¸æœ‰å¸®åŠ©ã€‚è¿™æ ·çš„éŸ³é¢‘æ–‡ä»¶é€šå¸¸ä¸€ä¸ªæ¨¡å‹æ— æ³•ç‹¬è‡ªå¤„ç†ã€‚

å¦‚æœä½ æ‰¾ä¸åˆ°çœŸæ­£æœ‰ç”¨çš„å‚æ•°ï¼Œè¯·éšæ—¶[æå‡ºè¯·æ±‚](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)ï¼

## ä½¿ç”¨pipelinesåœ¨æ•°æ®é›†ä¸Šè¿›è¡Œæ¨ç†

pipelineè¿˜å¯ä»¥åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿è¡Œæ¨ç†ã€‚æˆ‘ä»¬å»ºè®®çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨è¿­ä»£å™¨ï¼š

```py
def data():
    for i in range(1000):
        yield f"My example {i}"


pipe = pipeline(model="gpt2", device=0)
generated_characters = 0
for out in pipe(data()):
    generated_characters += len(out[0]["generated_text"])
```

è¿­ä»£å™¨`data()`ä¼šé€ä¸ªç”Ÿæˆç»“æœï¼Œè€Œpipelineä¼šè‡ªåŠ¨è¯†åˆ«è¾“å…¥ä¸ºå¯è¿­ä»£å¯¹è±¡ï¼Œå¹¶åœ¨ç»§ç»­åœ¨GPUä¸Šå¤„ç†æ•°æ®çš„åŒæ—¶å¼€å§‹è·å–æ•°æ®ï¼ˆè¿™åœ¨åº•å±‚ä½¿ç”¨äº†[DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ï¼‰ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºä½ ä¸éœ€è¦ä¸ºæ•´ä¸ªæ•°æ®é›†åˆ†é…å†…å­˜ï¼Œå¯ä»¥å°½å¯èƒ½å¿«åœ°å°†æ•°æ®æä¾›ç»™GPUã€‚

ç”±äºæ‰¹å¤„ç†å¯èƒ½åŠ å¿«é€Ÿåº¦ï¼Œè°ƒæ•´`batch_size`å‚æ•°å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ã€‚

è¿­ä»£æ•´ä¸ªæ•°æ®é›†çš„æœ€ç®€å•æ–¹æ³•å°±æ˜¯ä»ğŸ¤— [Datasets](https://github.com/huggingface/datasets/)ä¸­åŠ è½½æ•°æ®é›†ï¼š

```py
# KeyDataset is a util that will just output the item we're interested in.
from transformers.pipelines.utils import KeyDataset
from datasets import load_dataset

pipe = pipeline(model="hf-internal-testing/tiny-random-wav2vec2", device=0)
dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation[:10]")

for out in pipe(KeyDataset(dataset, "audio")):
    print(out)
```

## ä½¿ç”¨pipelinesæ„å»ºWebæœåŠ¡å™¨

æ³¨æ„ï¼š
>åˆ›å»ºæ¨ç†å¼•æ“æ˜¯ä¸€ä¸ªå¤æ‚çš„ä¸»é¢˜ï¼Œè¯¥ä¸»é¢˜ä¼šç”¨å•ç‹¬çš„å†…å®¹æ¥è¯´æ˜ã€‚

[é“¾æ¥](http://liuzard.com/pipeline_webserver)

## è§†è§‰ä»»åŠ¡çš„pipeline

å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œä½¿ç”¨[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚

æŒ‡å®šä½ çš„ä»»åŠ¡ï¼Œå¹¶å°†å›¾åƒä¼ é€’ç»™åˆ†ç±»å™¨ã€‚å›¾åƒå¯ä»¥æ˜¯é“¾æ¥ã€æœ¬åœ°è·¯å¾„æˆ–Base64ç¼–ç çš„å›¾åƒã€‚ä¾‹å¦‚ï¼Œä¸‹é¢æ˜¾ç¤ºçš„æ˜¯å“ªç§çŒ«çš„å“ç§ï¼Ÿ

![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)

```py
>>> from transformers import pipeline

>>> vision_classifier = pipeline(model="google/vit-base-patch16-224")
>>> preds = vision_classifier(
...     images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]
```

## æ–‡æœ¬ä»»åŠ¡çš„pipeline

å¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ï¼Œä½¿ç”¨[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚

```py
>>> from transformers import pipeline

>>> # This model is a `zero-shot-classification` model.
>>> # It will classify text, except you are free to choose any label you might imagine
>>> classifier = pipeline(model="facebook/bart-large-mnli")
>>> classifier(
...     "I have a problem with my iphone that needs to be resolved asap!!",
...     candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
... )
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

## å¤šæ¨¡æ€ä»»åŠ¡çš„pipeline

[`pipeline`](https://huggingface.co/transformers/main_classes/pipelines.html#pipelines-overview-pipelines)æ”¯æŒå¤šä¸ªæ¨¡æ€ã€‚ä¾‹å¦‚ï¼Œè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒã€‚ä½ å¯ä»¥éšæ„ä½¿ç”¨ä»»ä½•ä½ å–œæ¬¢çš„å›¾åƒé“¾æ¥å’Œè¦æå‡ºçš„é—®é¢˜ã€‚å›¾åƒå¯ä»¥æ˜¯URLæˆ–æŒ‡å‘å›¾åƒçš„æœ¬åœ°è·¯å¾„ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨è¿™å¼ [å‘ç¥¨å›¾åƒ](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)ï¼š

```py
>>> from transformers import pipeline

>>> vqa = pipeline(model="impira/layoutlm-document-qa")
>>> vqa(
...     image="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png",
...     question="What is the invoice number?",
... )
[{'score': 0.42515, 'answer': 'us-001', 'start': 16, 'end': 16}]
```

æ³¨æ„ï¼š

> è¦è¿è¡Œä¸Šé¢çš„ç¤ºä¾‹ï¼Œé™¤äº†ğŸ¤— Transformersä¹‹å¤–ï¼Œä½ è¿˜éœ€è¦å®‰è£…[`pytesseract`](https://pypi.org/project/pytesseract/)ï¼š

```bash
sudo apt install -y tesseract-ocr
pip install pytesseract
```



## ä½¿ç”¨`pipeline`å¤„ç†å¤§å‹æ¨¡å‹ä¸ğŸ¤— `accelerate`ï¼š

ä½ å¯ä»¥ä½¿ç”¨ğŸ¤— `accelerate`è½»æ¾åœ°åœ¨å¤§å‹æ¨¡å‹ä¸Šè¿è¡Œ`pipeline`ï¼é¦–å…ˆç¡®ä¿å·²ç»ä½¿ç”¨`pip install accelerate`å®‰è£…äº†`accelerate`ã€‚

é¦–å…ˆä½¿ç”¨`device_map="auto"`åŠ è½½ä½ çš„æ¨¡å‹ï¼æˆ‘ä»¬å°†åœ¨ç¤ºä¾‹ä¸­ä½¿ç”¨`facebook/opt-1.3b`ã€‚

```py
# pip install accelerate
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", torch_dtype=torch.bfloat16, device_map="auto")
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

å¦‚æœä½ å®‰è£…äº†`bitsandbytes`å¹¶æ·»åŠ äº†å‚æ•°`load_in_8bit=True`ï¼Œè¿˜å¯ä»¥ä¼ é€’åŠ è½½çš„8ä½æ¨¡å‹ã€‚

```py
# pip install accelerate bitsandbytes
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", device_map="auto", model_kwargs={"load_in_8bit": True})
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

è¯·æ³¨æ„ï¼Œä½ å¯ä»¥å°†æ£€æŸ¥ç‚¹æ›¿æ¢ä¸ºä»»ä½•æ”¯æŒå¤§æ¨¡å‹åŠ è½½çš„Hugging Faceæ¨¡å‹ï¼Œä¾‹å¦‚BLOOMï¼
