<!--ç‰ˆæƒæ‰€æœ‰ 2022 HuggingFaceå›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apacheè®¸å¯è¯ç¬¬2ç‰ˆ ï¼ˆâ€œè®¸å¯è¯â€ï¼‰è¿›è¡Œè®¸å¯;é™¤éç¬¦åˆè®¸å¯è¯çš„è¦æ±‚ï¼Œå¦åˆ™ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚
æ‚¨å¯ä»¥åœ¨

http://www.apache.org/licenses/LICENSE-2.0

å¤„è·å–è®¸å¯è¯çš„å‰¯æœ¬ã€‚

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯â€œæŒ‰åŸæ ·â€åˆ†å‘çš„ï¼Œ
æ²¡æœ‰ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯æˆ–æ¡ä»¶ã€‚æœ‰å…³çš„è®¸å¯è¯çš„ç‰¹å®šè¯­è¨€ä¸‹æ‰€è½½æ˜çš„æƒåˆ©å’Œé™åˆ¶ï¼Œ
è¯·å‚é˜…è¯¥è®¸å¯è¯ã€‚

æ³¨æ„ï¼šæ­¤æ–‡ä»¶ä½¿ç”¨Markdownï¼Œä½†åŒ…å«æˆ‘ä»¬çš„doc-builderçš„ç‰¹å®šè¯­æ³•ï¼ˆç±»ä¼¼äºMDXï¼‰ï¼Œå¯èƒ½æ— æ³•åœ¨MarkdownæŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ¸²æŸ“ã€‚

-->

# ä½¿ç”¨è„šæœ¬è¿›è¡Œè®­ç»ƒ

é™¤äº†ğŸ¤— Transformers [notebooks](./noteboks/README)å¤–ï¼Œè¿˜æœ‰ä¸€äº›æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨[PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch)ï¼Œ[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow)æˆ–[JAX/Flax](https://github.com/huggingface/transformers/tree/main/examples/flax)è®­ç»ƒæ¨¡å‹çš„ç¤ºä¾‹è„šæœ¬ã€‚

æ‚¨è¿˜ä¼šå‘ç°æˆ‘ä»¬åœ¨[ç ”ç©¶é¡¹ç›®](https://github.com/huggingface/transformers/tree/main/examples/research_projects)å’Œ[æ—§ç¤ºä¾‹](https://github.com/huggingface/transformers/tree/main/examples/legacy)ä¸­ä½¿ç”¨çš„è„šæœ¬ï¼Œå®ƒä»¬ä¸»è¦æ˜¯ç”±ç¤¾åŒºè´¡çŒ®çš„ã€‚è¿™äº›è„šæœ¬ä¸å†å¾—åˆ°ç»´æŠ¤ï¼Œå¹¶ä¸”éœ€è¦ç‰¹å®šç‰ˆæœ¬çš„ğŸ¤— Transformersï¼Œè¿™å¯èƒ½ä¸åº“çš„æœ€æ–°ç‰ˆæœ¬ä¸å…¼å®¹ã€‚

è¿™äº›ç¤ºä¾‹è„šæœ¬ä¸æ˜¯é¢„è®¡åœ¨æ¯ä¸ªé—®é¢˜ä¸Šéƒ½å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œæ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨å°è¯•è§£å†³çš„é—®é¢˜æ¥è°ƒæ•´è„šæœ¬ã€‚ä¸ºäº†å¸®åŠ©æ‚¨è¿›è¡Œè°ƒæ•´ï¼Œå¤§å¤šæ•°è„šæœ¬å®Œå…¨æ˜¾ç¤ºäº†å¦‚ä½•é¢„å¤„ç†æ•°æ®ï¼Œå…è®¸æ‚¨æ ¹æ®éœ€è¦è¿›è¡Œç¼–è¾‘ä»¥é€‚åº”æ‚¨çš„ç”¨ä¾‹ã€‚

å¦‚æœæ‚¨æƒ³åœ¨ç¤ºä¾‹è„šæœ¬ä¸­å®ç°æŸä¸ªåŠŸèƒ½ï¼Œè¯·åœ¨æäº¤Pullè¯·æ±‚ä¹‹å‰åœ¨[è®ºå›](https://discuss.huggingface.co/)æˆ–[é—®é¢˜](https://github.com/huggingface/transformers/issues)ä¸­è®¨è®ºã€‚è™½ç„¶æˆ‘ä»¬æ¬¢è¿ä¿®å¤é”™è¯¯ï¼Œä½†æˆ‘ä»¬ä¸å¤ªå¯èƒ½åˆå¹¶ä¸€ä¸ªåœ¨å¯è¯»æ€§æ–¹é¢å…·æœ‰æ›´å¤šåŠŸèƒ½ä½†ç‰ºç‰²æ€§èƒ½çš„Pullè¯·æ±‚ã€‚

è¿™ä¸ªæŒ‡å—å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•åœ¨[PyTorch](https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization)å’Œ[TensorFlow](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization)ä¸­è¿è¡Œä¸€ä¸ªç¤ºä¾‹æ‘˜è¦è®­ç»ƒè„šæœ¬ã€‚é™¤éå¦æœ‰è¯´æ˜ï¼Œæ‰€æœ‰ç¤ºä¾‹éƒ½å¯ä»¥åœ¨è¿™ä¸¤ä¸ªæ¡†æ¶ä¸Šå·¥ä½œã€‚

## è®¾ç½®

è¦æˆåŠŸè¿è¡Œç¤ºä¾‹è„šæœ¬çš„æœ€æ–°ç‰ˆæœ¬ï¼Œæ‚¨å¿…é¡»åœ¨æ–°çš„è™šæ‹Ÿç¯å¢ƒä¸­**ä»æºä»£ç å®‰è£…ğŸ¤— Transformers**ï¼š

```bash
git clone https://github.com/huggingface/transformers
cd transformers
pip install .
```

å¯¹äºæ—§ç‰ˆæœ¬çš„ç¤ºä¾‹è„šæœ¬ï¼Œè¯·ç‚¹å‡»ä¸‹é¢çš„åˆ‡æ¢ï¼š

<details>
  <summary>æ—©æœŸç‰ˆæœ¬çš„ğŸ¤— Transformersç¤ºä¾‹</summary>
	<ul>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.5.1/examples">v4.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.4.2/examples">v4.4.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.3.3/examples">v4.3.3</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.2.2/examples">v4.2.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.1.1/examples">v4.1.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v4.0.1/examples">v4.0.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.5.1/examples">v3.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.4.0/examples">v3.4.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.3.1/examples">v3.3.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.2.0/examples">v3.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.1.0/examples">v3.1.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v3.0.2/examples">v3.0.2</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.11.0/examples">v2.11.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.10.0/examples">v2.10.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.9.1/examples">v2.9.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.8.0/examples">v2.8.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.7.0/examples">v2.7.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.6.0/examples">v2.6.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.5.1/examples">v2.5.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.4.0/examples">v2.4.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.3.0/examples">v2.3.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.2.0/examples">v2.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.1.1/examples">v2.1.1</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v2.0.0/examples">v2.0.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.2.0/examples">v1.2.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.1.0/examples">v1.1.0</a></li>
		<li><a href="https://github.com/huggingface/transformers/tree/v1.0.0/examples">v1.0.0</a></li>
	</ul>
</details>

ç„¶åå°†æ‚¨å½“å‰çš„ğŸ¤— Transformerså…‹éš†åˆ‡æ¢åˆ°ç‰¹å®šç‰ˆæœ¬ï¼Œä¾‹å¦‚v3.5.1ï¼š

```bash
git checkout tags/v3.5.1
```

è®¾ç½®æ­£ç¡®çš„åº“ç‰ˆæœ¬åï¼Œåˆ‡æ¢åˆ°æ‰€é€‰ç¤ºä¾‹æ–‡ä»¶å¤¹ï¼Œå¹¶å®‰è£…ç¤ºä¾‹ç‰¹å®šè¦æ±‚ï¼š

```bash
pip install -r requirements.txt
```

## è¿è¡Œè„šæœ¬

<frameworkcontent>
<pt>
ç¤ºä¾‹è„šæœ¬ä¸‹è½½å¹¶é¢„å¤„ç†äº†ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/)åº“ä¸­çš„æ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬ä½¿ç”¨æ”¯æŒæ‘˜è¦ç”Ÿæˆçš„æ¶æ„åœ¨[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)ä¸Šå¾®è°ƒäº†æ•°æ®é›†ã€‚ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•åœ¨[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail)æ•°æ®é›†ä¸Šå¾®è°ƒ[T5-small](https://huggingface.co/t5-small)æ¨¡å‹ã€‚ç”±äºT5æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼Œéœ€è¦æ·»åŠ é¢å¤–çš„`source_prefix`å‚æ•°ã€‚è¿™ä¸ªpromptè®©T5çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚

```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```
</pt>
<tf>
ç¤ºä¾‹è„šæœ¬ä¸‹è½½å¹¶é¢„å¤„ç†äº†ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/)åº“ä¸­çš„æ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬ä½¿ç”¨Kerasåœ¨æ”¯æŒæ‘˜è¦ç”Ÿæˆçš„æ¶æ„ä¸Šå¾®è°ƒäº†æ•°æ®é›†ã€‚ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•åœ¨[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail)æ•°æ®é›†ä¸Šå¾®è°ƒ[T5-small](https://huggingface.co/t5-small)æ¨¡å‹ã€‚ç”±äºT5æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼Œéœ€è¦æ·»åŠ é¢å¤–çš„`source_prefix`å‚æ•°ã€‚è¿™ä¸ªpromptè®©T5çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚

```bash
python examples/tensorflow/summarization/run_summarization.py  \
    --model_name_or_path t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```
</tf>
</frameworkcontent>

## åˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦

[è®­ç»ƒå™¨](https://huggingface.co/docs/transformers/main_classes/trainer)æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦ï¼Œè¿™æ„å‘³ç€æ‚¨ä¹Ÿå¯ä»¥åœ¨è„šæœ¬ä¸­ä½¿ç”¨å®ƒä»¬ã€‚è¦å¯ç”¨è¿™ä¸¤ä¸ªåŠŸèƒ½ï¼š

- æ·»åŠ `fp16`å‚æ•°ä»¥å¯ç”¨æ··åˆç²¾åº¦ã€‚
- ä½¿ç”¨`nproc_per_node`å‚æ•°è®¾ç½®è¦ä½¿ç”¨çš„GPUæ•°é‡ã€‚

```bash
python -m torch.distributed.launch \
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \
    --fp16 \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

TensorFlowè„šæœ¬ä½¿ç”¨[`MirroredStrategy`](https://www.tensorflow.org/guide/distributed_training#mirroredstrategy)è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œåœ¨è®­ç»ƒè„šæœ¬ä¸­ä¸éœ€è¦æ·»åŠ ä»»ä½•é¢å¤–å‚æ•°ã€‚å¦‚æœå¯ç”¨ï¼ŒTensorFlowè„šæœ¬å°†é»˜è®¤ä½¿ç”¨å¤šä¸ªGPUã€‚

## åœ¨TPUä¸Šè¿è¡Œè„šæœ¬

<frameworkcontent>
<pt>
æä¾›tensorå¤„ç†å•å…ƒï¼ˆTensor Processing Unitsï¼ŒTPUsï¼‰æ˜¯ä¸ºäº†åŠ é€Ÿæ€§èƒ½è€Œä¸“é—¨è®¾è®¡çš„ã€‚PyTorchä½¿ç”¨[XLA](https://www.tensorflow.org/xla)æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨æ¥æ”¯æŒTPUï¼ˆæœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[è¿™é‡Œ](https://github.com/pytorch/xla/blob/master/README.md)ï¼‰ã€‚è¦ä½¿ç”¨TPUï¼Œè¯·è¿è¡Œ`xla_spawn.py`è„šæœ¬ï¼Œå¹¶ä½¿ç”¨`num_cores`å‚æ•°è®¾ç½®è¦ä½¿ç”¨çš„TPUæ ¸å¿ƒæ•°ã€‚

```bash
python xla_spawn.py --num_cores 8 \
    summarization/run_summarization.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```
</pt>
<tf>
æä¾›tensorå¤„ç†å•å…ƒï¼ˆTensor Processing Unitsï¼ŒTPUsï¼‰æ˜¯ä¸ºäº†åŠ é€Ÿæ€§èƒ½è€Œä¸“é—¨è®¾è®¡çš„ã€‚TensorFlowè„šæœ¬ä½¿ç”¨[`TPUStrategy`](https://www.tensorflow.org/guide/distributed_training#tpustrategy)è¿›è¡ŒTPUä¸Šçš„è®­ç»ƒã€‚è¦ä½¿ç”¨TPUï¼Œè¯·å°†TPUèµ„æºçš„åç§°ä¼ é€’ç»™`tpu`å‚æ•°ã€‚

```bash
python run_summarization.py  \
    --tpu name_of_tpu_resource \
    --model_name_or_path t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --output_dir /tmp/tst-summarization  \
    --per_device_train_batch_size 8 \
    --per_device_eval_batch_size 16 \
    --num_train_epochs 3 \
    --do_train \
    --do_eval
```
</tf>
</frameworkcontent>

## ä½¿ç”¨ğŸ¤— Accelerateè¿è¡Œè„šæœ¬

ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate)æ˜¯ä»…é€‚ç”¨äºPyTorchçš„åº“ï¼Œå®ƒæä¾›äº†ä¸€ç§ç»Ÿä¸€çš„æ–¹æ³•ï¼Œåœ¨ä¿æŒå¯¹PyTorchè®­ç»ƒå¾ªç¯å®Œå…¨å¯è§çš„åŒæ—¶ï¼Œåœ¨å¤šç§è®¾ç½®ï¼ˆä»…CPUã€å¤šä¸ªGPUã€TPUï¼‰ä¸Šè®­ç»ƒæ¨¡å‹ã€‚å¦‚æœæ‚¨å°šæœªå®‰è£…ğŸ¤— Accelerateï¼Œè¯·ç¡®ä¿å·²å®‰è£…ï¼š

> æ³¨æ„ï¼šç”±äºAccelerateçš„å¿«é€Ÿå¼€å‘ï¼Œå¿…é¡»å®‰è£…accelerateçš„gitç‰ˆæœ¬æ¥è¿è¡Œè„šæœ¬
```bash
pip install git+https://github.com/huggingface/accelerate
```

ä¸å†ä½¿ç”¨`run_summarization.py`è„šæœ¬ï¼Œè€Œæ˜¯ä½¿ç”¨`run_summarization_no_trainer.py`è„šæœ¬ã€‚æ”¯æŒğŸ¤— Accelerateçš„è„šæœ¬å°†åœ¨æ–‡ä»¶å¤¹ä¸­å…·æœ‰ä¸€ä¸ª`task_no_trainer.py`æ–‡ä»¶ã€‚é¦–å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åˆ›å»ºå¹¶ä¿å­˜é…ç½®æ–‡ä»¶ï¼š

```bash
accelerate config
```

æµ‹è¯•æ‚¨çš„è®¾ç½®ä»¥ç¡®ä¿å…¶æ­£ç¡®é…ç½®ï¼š

```bash
accelerate test
```

ç°åœ¨ï¼Œå¯ä»¥å¯åŠ¨åŸ¹è®­ï¼š

```bash
accelerate launch run_summarization_no_trainer.py \
    --model_name_or_path t5-small \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir ~/tmp/tst-summarization
```

## ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†

æ‘˜è¦è„šæœ¬æ”¯æŒè‡ªå®šä¹‰æ•°æ®é›†ï¼Œåªè¦å®ƒä»¬æ˜¯CSVæˆ–JSON Lineæ–‡ä»¶ã€‚å½“ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†æ—¶ï¼Œæ‚¨éœ€è¦æŒ‡å®šä¸€äº›é¢å¤–çš„å‚æ•°ï¼š

- `train_file`å’Œ`validation_file`æŒ‡å®šè®­ç»ƒå’ŒéªŒè¯æ–‡ä»¶çš„è·¯å¾„ã€‚
- `text_column`æ˜¯è¾“å…¥è¦è¿›è¡Œæ‘˜è¦çš„æ–‡æœ¬ã€‚
- `summary_column`æ˜¯è¦è¾“å‡ºçš„ç›®æ ‡æ–‡æœ¬ã€‚

ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†çš„æ‘˜è¦è„šæœ¬å¦‚ä¸‹ï¼š

```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --train_file path_to_csv_or_jsonlines_file \
    --validation_file path_to_csv_or_jsonlines_file \
    --text_column text_column_name \
    --summary_column summary_column_name \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --overwrite_output_dir \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --predict_with_generate
```

## æµ‹è¯•è„šæœ¬

åœ¨æäº¤æ•´ä¸ªå¯èƒ½éœ€è¦å‡ å°æ—¶æ‰èƒ½å®Œæˆçš„æ•°æ®é›†ä¹‹å‰ï¼Œé€šå¸¸æœ€å¥½å…ˆåœ¨è¾ƒå°æ•°é‡çš„æ•°æ®é›†ç¤ºä¾‹ä¸Šè¿è¡Œè„šæœ¬ä»¥ç¡®ä¿ä¸€åˆ‡æ­£å¸¸ã€‚ä½¿ç”¨ä»¥ä¸‹å‚æ•°å°†æ•°æ®é›†æˆªæ–­ä¸ºæœ€å¤§æ ·æœ¬æ•°ï¼š

- `max_train_samples`
- `max_eval_samples`
- `max_predict_samples`

```bash
python examples/pytorch/summarization/run_summarization.py \
    --model_name_or_path t5-small \
    --max_train_samples 50 \
    --max_eval_samples 50 \
    --max_predict_samples 50 \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```

å¹¶ä¸æ˜¯æ‰€æœ‰ç¤ºä¾‹è„šæœ¬éƒ½æ”¯æŒ`max_predict_samples`å‚æ•°ã€‚å¦‚æœä¸ç¡®å®šè„šæœ¬æ˜¯å¦æ”¯æŒè¯¥å‚æ•°ï¼Œè¯·æ·»åŠ `-h`å‚æ•°æ£€æŸ¥ï¼š

```bash
examples/pytorch/summarization/run_summarization.py -h
```

## ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ

åœ¨è®­ç»ƒä¸­æ–­æ—¶ï¼Œä»å…ˆå‰çš„æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒæ˜¯ä¸€ä¸ªæœ‰ç”¨çš„é€‰é¡¹ï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿æ‚¨å¯ä»¥ç»§ç»­ä¹‹å‰çš„å·¥ä½œï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹ã€‚ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒæœ‰ä¸¤ç§æ–¹æ³•ã€‚

ç¬¬ä¸€ç§æ–¹æ³•ä½¿ç”¨`output_dir previous_output_dir`å‚æ•°ä»å­˜å‚¨åœ¨`output_dir`ä¸­çš„æœ€æ–°æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨åº”è¯¥åˆ é™¤`overwrite_output_dir`ï¼š

```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --output_dir previous_output_dir \
    --predict_with_generate
```

ç¬¬äºŒç§æ–¹æ³•ä½¿ç”¨ `resume_from_checkpoint path_to_specific_checkpoint` å‚æ•°ä»ç‰¹å®šçš„æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹æ¢å¤è®­ç»ƒã€‚

```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --resume_from_checkpoint path_to_specific_checkpoint \
    --predict_with_generate
```

## å…±äº«ä½ çš„æ¨¡å‹

æ‰€æœ‰çš„è„šæœ¬éƒ½å¯ä»¥å°†ä½ çš„æœ€ç»ˆæ¨¡å‹ä¸Šä¼ åˆ° [Model Hub](https://huggingface.co/models)ã€‚åœ¨å¼€å§‹ä¹‹å‰ï¼Œç¡®ä¿ä½ å·²ç™»å½•åˆ° Hugging Faceï¼š

```bash
huggingface-cli login
```

ç„¶åå°† `push_to_hub` å‚æ•°æ·»åŠ åˆ°è„šæœ¬ä¸­ã€‚è¯¥å‚æ•°å°†åœ¨ `output_dir` ä¸­åˆ›å»ºä¸€ä¸ªåŒ…å«ä½ çš„ Hugging Face ç”¨æˆ·åå’Œæ–‡ä»¶å¤¹åçš„ä»“åº“ã€‚

å¦‚æœè¦ä¸ºä½ çš„ä»“åº“æŒ‡å®šä¸€ä¸ªç‰¹å®šçš„åç§°ï¼Œè¯·ä½¿ç”¨ `push_to_hub_model_id` å‚æ•°æ·»åŠ å®ƒã€‚è¯¥ä»“åº“å°†è‡ªåŠ¨åˆ—åœ¨ä½ çš„å‘½åç©ºé—´ä¸‹ã€‚

ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä¸Šä¼ å…·æœ‰ç‰¹å®šä»“åº“åç§°çš„æ¨¡å‹ï¼š

```bash
python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path t5-small \
    --do_train \
    --do_eval \
    --dataset_name cnn_dailymail \
    --dataset_config "3.0.0" \
    --source_prefix "summarize: " \
    --push_to_hub \
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \
    --output_dir /tmp/tst-summarization \
    --per_device_train_batch_size=4 \
    --per_device_eval_batch_size=4 \
    --overwrite_output_dir \
    --predict_with_generate
```