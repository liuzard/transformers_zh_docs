<!--
ç‰ˆæƒæ‰€æœ‰2020 The HuggingFaceå›¢é˜Ÿã€‚ç‰ˆæƒæ‰€æœ‰ã€‚

æ ¹æ®Apacheè®¸å¯è¯ç¬¬2ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰çš„è§„å®šï¼Œé™¤éç¬¦åˆè®¸å¯è¯ï¼Œå¦åˆ™ç¦æ­¢ä½¿ç”¨æ­¤è½¯ä»¶ã€‚
æ‚¨å¯ä»¥åœ¨ä¸‹é¢çš„é“¾æ¥æ‰¾åˆ°è®¸å¯è¯çš„å‰¯æœ¬

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶åŸºäºåŸºâ€œåŸæ ·â€å‘å¸ƒï¼Œæ— ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºä¿è¯æˆ–æ¡ä»¶ã€‚è¯·å‚é˜…è®¸å¯è¯ä»¥è·å–
å…·ä½“çº¦æŸå’Œé™åˆ¶çš„ç‰¹å®šè¯­è¨€ã€‚

âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯ä»¥Markdownæ ¼å¼ç¼–å†™çš„ï¼Œä½†åŒ…å«äº†æˆ‘ä»¬doc-builderï¼ˆç±»ä¼¼äºMDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½åœ¨æ‚¨çš„MarkdownæŸ¥çœ‹å™¨ä¸­æ— æ³•æ­£å¸¸æ˜¾ç¤ºã€‚

-->

# DeepSpeedé›†æˆ

[DeepSpeed](https://github.com/microsoft/DeepSpeed)å®ç°äº†[ZeROè®ºæ–‡](https://arxiv.org/abs/1910.02054)ä¸­æè¿°çš„æ‰€æœ‰å†…å®¹ã€‚ç›®å‰ï¼Œå®ƒæä¾›äº†å¯¹ä»¥ä¸‹åŠŸèƒ½çš„å®Œå…¨æ”¯æŒï¼š

1. ä¼˜åŒ–å™¨çŠ¶æ€åˆ†åŒºï¼ˆZeROé˜¶æ®µ1ï¼‰
2. æ¢¯åº¦åˆ†åŒºï¼ˆZeROé˜¶æ®µ2ï¼‰
3. å‚æ•°åˆ†åŒºï¼ˆZeROé˜¶æ®µ3ï¼‰
4. è‡ªå®šä¹‰æ··åˆç²¾åº¦è®­ç»ƒå¤„ç†
5. ä¸€ç³»åˆ—åŸºäºå¿«é€ŸCUDAæ‰©å±•çš„ä¼˜åŒ–å™¨
6. é’ˆå¯¹CPUå’ŒNVMeçš„ZeRO-Offload

[ZeRO-Offload](https://arxiv.org/abs/2101.06840)æœ‰è‡ªå·±çš„ä¸“ç”¨è®ºæ–‡ã€‚NVMeæ”¯æŒåœ¨è®ºæ–‡[ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning](https://arxiv.org/abs/2104.07857)ä¸­è¿›è¡Œäº†æè¿°ã€‚

DeepSpeed ZeRO-2ä¸»è¦ç”¨äºè®­ç»ƒï¼Œå› ä¸ºå®ƒçš„ç‰¹æ€§å¯¹æ¨ç†æ²¡æœ‰ç”¨å¤„ã€‚

DeepSpeed ZeRO-3ä¹Ÿå¯ä»¥ç”¨äºæ¨ç†ï¼Œå› ä¸ºå®ƒå…è®¸åœ¨å¤šä¸ªGPUä¸ŠåŠ è½½å¤§å‹æ¨¡å‹ï¼Œè¿™åœ¨å•ä¸ªGPUä¸Šæ˜¯ä¸å¯èƒ½çš„ã€‚

ğŸ¤— Transformersé€šè¿‡2ç§æ–¹å¼é›†æˆ[DeepSpeed](https://github.com/microsoft/DeepSpeed)ï¼š

1. é€šè¿‡[`Trainer`]é›†æˆæ ¸å¿ƒDeepSpeedåŠŸèƒ½ã€‚è¿™æ˜¯ä¸€ç§ä¸€åˆ‡éƒ½ä¸ºæ‚¨å®Œæˆçš„é›†æˆæ–¹å¼-åªéœ€æä¾›è‡ªå®šä¹‰é…ç½®æ–‡ä»¶æˆ–ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡æ¿ï¼Œä¸éœ€è¦åšå…¶ä»–äº‹æƒ…ã€‚æœ¬æ–‡æ¡£çš„å¤§éƒ¨åˆ†å†…å®¹éƒ½é›†ä¸­åœ¨æ­¤åŠŸèƒ½ä¸Šã€‚
2. å¦‚æœæ‚¨ä¸ä½¿ç”¨[`Trainer`]ï¼Œè€Œæ˜¯è¦ä½¿ç”¨è‡ªå·±é›†æˆäº†DeepSpeedçš„è‡ªå®šä¹‰Trainerï¼Œæ ¸å¿ƒåŠŸèƒ½å‡½æ•°ï¼ˆä¾‹å¦‚`from_pretrained`å’Œ`from_config`ï¼‰å°†åŒ…å«DeepSpeedçš„å…³é”®éƒ¨åˆ†é›†æˆï¼Œå¦‚ZeROé˜¶æ®µ3åŠæ›´é«˜çº§åˆ«çš„`zero.Init`ã€‚è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·é˜…è¯»æœ‰å…³[éTrainerçš„DeepSpeedé›†æˆ](#nontrainer-deepspeed-integration)çš„æ–‡æ¡£ã€‚

é›†æˆçš„å†…å®¹ï¼š

è®­ç»ƒï¼š

1. DeepSpeed ZeROè®­ç»ƒä¸ZeROé˜¶æ®µ1ã€2å’Œ3ä»¥åŠZeRO-Infinityï¼ˆCPUå’ŒNVME offloadï¼‰å®Œå…¨å…¼å®¹ã€‚

æ¨ç†ï¼š

1. DeepSpeed ZeROæ¨ç†æ”¯æŒZeROé˜¶æ®µ3å’ŒZeRO-Infinityã€‚å®ƒä½¿ç”¨ä¸è®­ç»ƒç›¸åŒçš„ZeROåè®®ï¼Œä½†ä¸ä½¿ç”¨ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨ï¼Œåªæœ‰é˜¶æ®µ3ä¸æ¨ç†ç›¸å…³ã€‚æœ‰å…³æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜…[zero-inference](#zero-inference)ã€‚

è¿˜æœ‰DeepSpeedæ¨ç†-è¿™æ˜¯ä¸€ç§å®Œå…¨ä¸åŒçš„æŠ€æœ¯ï¼Œå®ƒä½¿ç”¨Tensor Parallelismè€Œä¸æ˜¯ZeROï¼ˆå³å°†æ¨å‡ºï¼‰ã€‚


<a id='deepspeed-trainer-integration'></a>


## é€šè¿‡Traineré›†æˆDeepSpeed


<a id='deepspeed-installation'></a>

### å®‰è£…

é€šè¿‡pypiå®‰è£…åº“ï¼š

```bash
pip install deepspeed
```

æˆ–é€šè¿‡`transformers`çš„`extras`å®‰è£…ï¼š

```bash
pip install transformers[deepspeed]
```

æˆ–åœ¨[DeepSpeedçš„GitHubé¡µé¢](https://github.com/microsoft/deepspeed#installation)æŸ¥æ‰¾æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œ[é«˜çº§å®‰è£…](https://www.deepspeed.ai/tutorials/advanced-install/)ã€‚

å¦‚æœæ‚¨ä»ç„¶åœ¨æ„å»ºæ–¹é¢é‡åˆ°å›°éš¾ï¼Œè¯·é¦–å…ˆç¡®ä¿é˜…è¯»[CUDAæ‰©å±•å®‰è£…è¯´æ˜](trainer#cuda-extension-installation-notes)ã€‚

å¦‚æœæ‚¨æ²¡æœ‰é¢„å…ˆæ„å»ºæ‰©å±•ï¼Œå¹¶ä¸”ä¾èµ–äºè¿è¡Œæ—¶æ„å»ºå®ƒä»¬ï¼Œå³ä½¿å°è¯•äº†ä¸Šè¿°æ‰€æœ‰è§£å†³æ–¹æ¡ˆä»ç„¶æ— æ³•æˆåŠŸï¼Œåˆ™ä¸‹ä¸€æ­¥å°è¯•åº”è¯¥æ˜¯åœ¨å®‰è£…å®ƒä»¬ä¹‹å‰æ„å»ºæ¨¡å—ã€‚

è¦è¿›è¡ŒDeepSpeedçš„æœ¬åœ°æ„å»ºï¼š

```bash
git clone https://github.com/microsoft/DeepSpeed/
cd DeepSpeed
rm -rf build
TORCH_CUDA_ARCH_LIST="8.6" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 pip install . \
--global-option="build_ext" --global-option="-j8" --no-cache -v \
--disable-pip-version-check 2>&1 | tee build.log
```

å¦‚æœæ‚¨æ‰“ç®—ä½¿ç”¨NVMe offloadï¼Œæ‚¨è¿˜éœ€è¦åœ¨ä¸Šè¿°æŒ‡ä»¤ä¸­åŒ…æ‹¬`DS_BUILD_AIO=1`ï¼ˆåŒæ—¶è¿˜éœ€åœ¨ç³»ç»ŸèŒƒå›´å†…å®‰è£…*libaio-dev*ï¼‰ã€‚

ç¼–è¾‘`TORCH_CUDA_ARCH_LIST`ä»¥æ’å…¥æ‚¨æ‰“ç®—ä½¿ç”¨çš„GPUå¡çš„æ¶æ„ä»£ç ã€‚å‡è®¾æ‚¨çš„æ‰€æœ‰å¡éƒ½æ˜¯ç›¸åŒçš„ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æ¶æ„ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python -c "import torch; print(torch.cuda.get_device_capability())"
```

å› æ­¤ï¼Œå¦‚æœæ‚¨è·å¾—`8, 6`ï¼Œé‚£ä¹ˆè¯·ä½¿ç”¨`TORCH_CUDA_ARCH_LIST="8.6"`ã€‚å¦‚æœæ‚¨æœ‰å¤šä¸ªä¸åŒçš„å¡ï¼Œå¯ä»¥åƒè¿™æ ·åˆ—å‡ºæ‰€æœ‰å¡ï¼š`TORCH_CUDA_ARCH_LIST="6.1;8.6"`ã€‚

å¦‚æœæ‚¨éœ€è¦åœ¨å¤šå°æœºå™¨ä¸Šä½¿ç”¨ç›¸åŒçš„è®¾ç½®ï¼Œè¯·ä¸‹è½½äºŒè¿›åˆ¶è½®å­ï¼š

```bash
git clone https://github.com/microsoft/DeepSpeed/
cd DeepSpeed
rm -rf build
TORCH_CUDA_ARCH_LIST="8.6" DS_BUILD_CPU_ADAM=1 DS_BUILD_UTILS=1 \
python setup.py build_ext -j8 bdist_wheel
```

å®ƒå°†ç”Ÿæˆç±»ä¼¼äº`dist/deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl`çš„ä¸œè¥¿ï¼Œæ‚¨ç°åœ¨å¯ä»¥åœ¨æœ¬åœ°æˆ–ä»»ä½•å…¶ä»–æœºå™¨ä¸Šå®‰è£…å®ƒä¸º`pip install deepspeed-0.3.13+8cd046f-cp38-cp38-linux_x86_64.whl`ã€‚

å†æ¬¡ï¼Œè¯·ç¡®ä¿è°ƒæ•´`TORCH_CUDA_ARCH_LIST`ä»¥é€‚åº”ç›®æ ‡æ¶æ„ã€‚

æ‚¨å¯ä»¥åœ¨[æ­¤å¤„](https://developer.nvidia.com/cuda-gpus)æ‰¾åˆ°NVIDIA GPUçš„å®Œæ•´åˆ—è¡¨ä»¥åŠå…¶å¯¹åº”çš„**è®¡ç®—èƒ½åŠ›**ï¼ˆåœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­ä¸æ¶æ„ç›¸åŒï¼‰ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ£€æŸ¥PyTorchæ„å»ºæ—¶æ‰€ä½¿ç”¨çš„æ¶æ„ï¼š

```bash
python -c "import torch; print(torch.cuda.get_arch_list())"
```

ä»¥ä¸‹æ˜¯å¦‚ä½•æ‰¾å‡ºå·²å®‰è£…çš„GPUä¹‹ä¸€çš„æ¶æ„çš„ç¤ºä¾‹ã€‚ä¾‹å¦‚ï¼Œå¯¹äºGPU 0ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 python -c "import torch; \
print(torch.cuda.get_device_properties(torch.device('cuda')))"
```

å¦‚æœè¾“å‡ºç»“æœæ˜¯ï¼š

```bash
_CudaDeviceProperties(name='GeForce RTX 3090', major=8, minor=6, total_memory=24268MB, multi_processor_count=82)
```

åˆ™æ‚¨çŸ¥é“æ­¤å¡çš„æ¶æ„æ˜¯`8.6`ã€‚

æ‚¨ä¹Ÿå¯ä»¥å®Œå…¨ä¸ä½¿ç”¨`TORCH_CUDA_ARCH_LIST`ï¼Œç„¶åæ„å»ºç¨‹åºå°†è‡ªåŠ¨æŸ¥è¯¢æ„å»ºæ‰€ä½¿ç”¨GPUçš„æ¶æ„ã€‚è¿™å¯èƒ½ä¸ç›®æ ‡æœºå™¨ä¸Šçš„GPUåŒ¹é…ï¼Œä¹Ÿå¯èƒ½ä¸åŒ¹é…ï¼Œè¿™å°±æ˜¯æ˜ç¡®æŒ‡å®šæ‰€éœ€æ¶æ„çš„æœ€ä½³æ–¹å¼ã€‚

å¦‚æœå°è¯•äº†æ‰€æœ‰å»ºè®®çš„è§£å†³åŠæ³•åä»ç„¶é‡åˆ°æ„å»ºé—®é¢˜ï¼Œè¯·ç»§ç»­ä½¿ç”¨[Deepspeed](https://github.com/microsoft/DeepSpeed/issues)çš„GitHub Issueã€‚


<a id='deepspeed-multi-gpu'></a>

### å¤šGPUéƒ¨ç½²

è¦éƒ¨ç½²DeepSpeedé›†æˆï¼Œè¯·è°ƒæ•´[`Trainer`]å‘½ä»¤è¡Œå‚æ•°ï¼ŒåŒ…æ‹¬ä¸€ä¸ªæ–°çš„å‚æ•°`--deepspeed ds_config.json`ï¼Œå…¶ä¸­`ds_config.json`æ˜¯DeepSpeedé…ç½®æ–‡ä»¶ï¼Œå¦‚[æ­¤å¤„](https://www.deepspeed.ai/docs/config-json/)æ‰€è¿°ã€‚æ–‡ä»¶å‘½åç”±æ‚¨å†³å®šã€‚
å»ºè®®ä½¿ç”¨DeepSpeedçš„`add_config_arguments`å®ç”¨ç¨‹åºæ¥å‘æ‚¨çš„ä»£ç ä¸­æ·»åŠ å¿…è¦çš„å‘½ä»¤è¡Œå‚æ•°ã€‚
æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[DeepSpeedçš„å‚æ•°è§£æ](https://deepspeed.readthedocs.io/en/latest/initialize.html#argument-parsing)æ–‡æ¡£ã€‚

æ‚¨å¯ä»¥åœ¨æ­¤å¤„ç»§ç»­ä½¿ç”¨pytorchå¯åŠ¨å™¨ï¼š

```bash
torch.distributed.run --nproc_per_node=2 your_program.py <normal cl args> --deepspeed ds_config.json
```

æˆ–ä½¿ç”¨`deepspeed`æä¾›çš„å¯åŠ¨å™¨ï¼š

```bash
deepspeed --num_gpus=2 your_program.py <normal cl args> --deepspeed ds_config.json
```

å¦‚æ‚¨æ‰€è§ï¼Œè¿™äº›å‚æ•°ä¸åŒï¼Œä½†å¯¹äºå¤§å¤šæ•°éœ€æ±‚ï¼Œå…¶ä¸­ä»»ä½•ä¸€ä¸ªéƒ½å¯ä»¥å·¥ä½œã€‚æœ‰å…³å¤šä¸ªèŠ‚ç‚¹å’ŒGPUé…ç½®çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§[æ­¤å¤„](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)ã€‚

å½“æ‚¨ä½¿ç”¨`deepspeed`å¯åŠ¨å™¨å¹¶ä¸”å¸Œæœ›ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„GPUæ—¶ï¼Œå¯ä»¥çœç•¥`--num_gpus`æ ‡å¿—ã€‚

ä¸‹é¢æ˜¯åœ¨DeepSpeedä¸Šä½¿ç”¨æ‰€æœ‰å¯ç”¨GPUè¿è¡Œ`run_translation.py`çš„ç¤ºä¾‹ï¼š

```bash
deepspeed examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero3.json \
--model_name_or_path t5-small --per_device_train_batch_size 1 \
--output_dir output_dir --overwrite_output_dir --fp16 \
--do_train --max_train_samples 500 --num_train_epochs 1 \
--dataset_name wmt16 --dataset_config "ro-en" \
--source_lang en --target_lang ro
```

è¯·æ³¨æ„ï¼Œåœ¨DeepSpeedæ–‡æ¡£ä¸­ï¼Œæ‚¨å¯èƒ½ä¼šçœ‹åˆ°`--deepspeed --deepspeed_config ds_config.json`-å³ä¸¤ä¸ªDeepSpeedç›¸å…³çš„å‚æ•°ï¼Œä½†ä¸ºäº†ç®€å•èµ·è§ï¼Œå¹¶ä¸”å·²ç»æœ‰å¤ªå¤šå‚æ•°è¦å¤„ç†ï¼Œæˆ‘ä»¬å°†ä¸¤è€…åˆå¹¶ä¸ºä¸€ä¸ªå‚æ•°ã€‚

æœ‰å…³ä¸€äº›å®é™…ç”¨æ³•ç¤ºä¾‹ï¼Œè¯·å‚è§[æ­¤å¤„](https://github.com/huggingface/transformers/issues/8771#issuecomment-759248400)çš„å†…å®¹ã€‚


<a id='deepspeed-one-gpu'></a>

### å•GPUéƒ¨ç½²

è¦ä½¿ç”¨å•ä¸ªGPUéƒ¨ç½²DeepSpeedï¼Œè¯·è°ƒæ•´ä»¥ä¸‹[`Trainer`]å‘½ä»¤è¡Œå‚æ•°ï¼š

```bash
deepspeed --num_gpus=1 examples/pytorch/translation/run_translation.py \
--deepspeed tests/deepspeed/ds_config_zero2.json \
--model_name_or_path t5-small --per_device_train_batch_size 1 \
--output_dir output_dir --overwrite_output_dir --fp16 \
--do_train --max_train_samples 500 --num_train_epochs 1 \
--dataset_name wmt16 --dataset_config "ro-en" \
--source_lang en --target_lang ro
```

è¿™ä¸å¤šä¸ªGPUçš„æƒ…å†µå‡ ä¹ç›¸åŒï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬é€šè¿‡`--num_gpus=1`æ˜ç¡®å‘Šè¯‰DeepSpeedä»…ä½¿ç”¨ä¸€ä¸ªGPUã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒDeepSpeedä¼šä½¿ç”¨ç»™å®šèŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰GPUã€‚å¦‚æœå¼€å§‹æ—¶åªæœ‰1ä¸ªGPUï¼Œåˆ™ä¸éœ€è¦æ­¤å‚æ•°ã€‚ä»¥ä¸‹æ–‡æ¡£ä¸­è®¨è®ºäº†å¯åŠ¨å™¨é€‰é¡¹ã€‚

ä¸ºä»€ä¹ˆè¦ä½¿ç”¨åªæœ‰ä¸€ä¸ªGPUçš„DeepSpeedï¼Ÿ

1. å®ƒå…·æœ‰ZeRO-offloadåŠŸèƒ½ï¼Œå¯ä»¥å°†ä¸€äº›è®¡ç®—å’Œå†…å­˜å§”æ´¾ç»™ä¸»æœºçš„CPUå’ŒRAMï¼Œä»è€Œä¸ºæ¨¡å‹çš„éœ€æ±‚ç•™ä¸‹æ›´å¤šçš„GPUèµ„æº-ä¾‹å¦‚æ›´å¤§çš„æ‰¹æ¬¡å¤§å°ï¼Œæˆ–å¯ç”¨é€šå¸¸æ— æ³•å®¹çº³çš„éå¸¸å¤§çš„æ¨¡å‹ã€‚
2. å®ƒæä¾›äº†æ™ºèƒ½çš„GPUå†…å­˜ç®¡ç†ç³»ç»Ÿï¼Œæœ€å°åŒ–å†…å­˜ç¢ç‰‡åŒ–ï¼Œè¿™æ ·å†æ¬¡å¯ä»¥é€‚åº”æ›´å¤§çš„æ¨¡å‹å’Œæ•°æ®æ‰¹æ¬¡ã€‚

è™½ç„¶æˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„èŠ‚ä¸­è¯¦ç»†è®¨è®ºé…ç½®ï¼Œä½†è¦åœ¨å…·æœ‰ä¸€ä¸ªGPUçš„DeepSpeedä¸Šè·å¾—å·¨å¤§æ”¹è¿›çš„å…³é”®æ˜¯åœ¨é…ç½®æ–‡ä»¶ä¸­è‡³å°‘æœ‰ä»¥ä¸‹é…ç½®ï¼š

```json
{
  "zero_optimization": {
     "stage": 2,
     "offload_optimizer": {
         "device": "cpu",
         "pin_memory": true
     },
     "allgather_partitions": true,
     "allgather_bucket_size": 2e8,
     "reduce_scatter": true,
     "reduce_bucket_size": 2e8,
     "overlap_comm": true,
     "contiguous_gradients": true
  }
}
```

å®ƒå¯ç”¨äº†ä¼˜åŒ–å™¨å¸è½½å’Œå…¶ä»–ä¸€äº›é‡è¦åŠŸèƒ½ã€‚æ‚¨å¯ä»¥æ ¹æ®éœ€è¦å°è¯•ä¸åŒçš„ç¼“å†²åŒºå¤§å°ï¼Œæœ‰å…³è¯¦ç»†è®¨è®ºï¼Œè¯·å‚è§ä¸‹é¢çš„è®¨è®ºã€‚

æœ‰å…³æ­¤ç±»éƒ¨ç½²çš„å®é™…ç”¨æ³•ç¤ºä¾‹ï¼Œè¯·å‚è§[æ­¤å¤„](https://github.com/huggingface/transformers/issues/8771#issuecomment-759176685)ã€‚

æ‚¨è¿˜å¯ä»¥å°è¯•ä½¿ç”¨æè¿°æ–‡ä»¶ä¸­è¿›ä¸€æ­¥è§£é‡Šçš„å¸¦æœ‰CPUå’ŒNVMe offloadçš„ZeRO-3ã€‚


<a id='deepspeed-multi-node'></a>

### å¤šèŠ‚ç‚¹éƒ¨ç½²

æœ¬èŠ‚ä¸­çš„ä¿¡æ¯ä¸ä»…é€‚ç”¨äºDeepSpeedé›†æˆï¼Œè¿˜é€‚ç”¨äºä»»ä½•å¤šèŠ‚ç‚¹ç¨‹åºã€‚ä½†æ˜¯DeepSpeedå§‹ç»ˆæä¾›äº†ä¸€ä¸ª`deepspeed`å¯åŠ¨å™¨ï¼Œå®ƒæ¯”å…¶ä»–å¯åŠ¨å™¨æ›´å®¹æ˜“ä½¿ç”¨ï¼Œé™¤éæ‚¨å¤„äºSLURMç¯å¢ƒä¸­ã€‚

åœ¨æœ¬èŠ‚çš„æŒç»­æ—¶é—´ä¸­ï¼Œè®©æˆ‘ä»¬å‡è®¾æ‚¨æœ‰2ä¸ªæ‹¥æœ‰8ä¸ªGPUçš„èŠ‚ç‚¹ã€‚æ‚¨å¯ä»¥é€šè¿‡`ssh hostname1`è®¿é—®ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼Œé€šè¿‡`ssh hostname2`è®¿é—®ç¬¬äºŒä¸ªèŠ‚ç‚¹ï¼Œå¹¶ä¸”ä¸¤è€…å¿…é¡»èƒ½å¤Ÿé€šè¿‡æœ¬åœ°sshåœ¨æ²¡æœ‰å¯†ç çš„æƒ…å†µä¸‹ç›¸äº’è®¿é—®ã€‚å½“ç„¶ï¼Œæ‚¨éœ€è¦å°†è¿™äº›ä¸»æœºï¼ˆèŠ‚ç‚¹ï¼‰åç§°é‡æ–°å‘½åä¸ºæ‚¨ä½¿ç”¨çš„å®é™…ä¸»æœºåç§°ã€‚

#### torch.distributed.runå¯åŠ¨å™¨


ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨`torch.distributed.run`ï¼Œæ‚¨å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```bash
python -m torch.distributed.run --nproc_per_node=8 --nnode=2 --node_rank=0 --master_addr=hostname1 \
--master_port=9901 your_program.py <normal cl args> --deepspeed ds_config.json
```

æ‚¨å¿…é¡»sshåˆ°æ¯ä¸ªèŠ‚ç‚¹å¹¶åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œç›¸åŒçš„å‘½ä»¤ï¼ä¸ç”¨ç€æ€¥ï¼Œå¯åŠ¨å™¨ä¼šç­‰å¾…ç›´åˆ°ä¸¤ä¸ªèŠ‚ç‚¹åŒæ­¥ã€‚

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[torchrun](https://pytorch.org/docs/stable/elastic/run.html)ã€‚é¡ºä¾¿è¯´ä¸€å¥ï¼Œè¿™ä¹Ÿæ˜¯å‡ ä¸ªPyTorchç‰ˆæœ¬å‰æ›¿ä»£äº†`torch.distributed.launch`çš„å¯åŠ¨å™¨ã€‚


#### deepspeedå¯åŠ¨å™¨

è¦æ”¹ç”¨`deepspeed`å¯åŠ¨å™¨ï¼Œæ‚¨é¦–å…ˆå¿…é¡»åˆ›å»ºä¸€ä¸ª`hostfile`æ–‡ä»¶ï¼š

```
hostname1 slots=8
hostname2 slots=8
```
ç„¶åæ‚¨å¯ä»¥å¯åŠ¨å®ƒï¼š

```bash
deepspeed --num_gpus 8 --num_nodes 2 --hostfile hostfile --master_addr hostname1 --master_port=9901 \
your_program.py <normal cl args> --deepspeed ds_config.json
```

ä¸`torch.distributed.run`å¯åŠ¨å™¨ä¸åŒï¼Œ`deepspeed`å°†è‡ªåŠ¨åœ¨ä¸¤ä¸ªèŠ‚ç‚¹ä¸Šå¯åŠ¨æ­¤å‘½ä»¤ï¼

æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è§[èµ„æºé…ç½®ï¼ˆå¤šèŠ‚ç‚¹ï¼‰](https://www.deepspeed.ai/getting-started/#resource-configuration-multi-node)ã€‚


#### åœ¨SLURMç¯å¢ƒä¸­å¯åŠ¨

åœ¨SLURMç¯å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªslurmè„šæœ¬`launch.slurm`ï¼Œæ‚¨éœ€è¦æ ¹æ®ç‰¹å®šçš„SLURMç¯å¢ƒå¯¹å…¶è¿›è¡Œè°ƒæ•´ã€‚

```bash
#SBATCH --job-name=test-nodes        # åç§°
#SBATCH --nodes=2                    # èŠ‚ç‚¹æ•°
#SBATCH --ntasks-per-node=1          # è‡³å…³é‡è¦ - æ¯ä¸ªèŠ‚ç‚¹ä¸Šåªæœ‰1ä¸ªä»»åŠ¡åˆ†å‘ï¼
#SBATCH --cpus-per-task=10           # æ¯ä¸ªä»»åŠ¡çš„æ ¸æ•°
#SBATCH --gres=gpu:8                 # GPUæ•°
#SBATCH --time 20:00:00              # æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆHH:MM:SSï¼‰
#SBATCH --output=%x-%j.out           # è¾“å‡ºæ–‡ä»¶å

export GPUS_PER_NODE=8
export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=9901

srun --jobid $SLURM_JOBID bash -c 'python -m torch.distributed.run \
 --nproc_per_node $GPUS_PER_NODE --nnodes $SLURM_NNODES --node_rank $SLURM_PROCID \
 --master_addr $MASTER_ADDR --master_port $MASTER_PORT \
your_program.py <normal cl args> --deepspeed ds_config.json'
```

åªéœ€å®‰æ’å®ƒè¿è¡Œï¼š
```bash
sbatch launch.slurm
```

`srun`ä¼šè´Ÿè´£åŒæ—¶åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šå¯åŠ¨ç¨‹åºã€‚


#### ä½¿ç”¨éå…±äº«æ–‡ä»¶ç³»ç»Ÿ

é»˜è®¤æƒ…å†µä¸‹ï¼ŒDeepSpeedå‡è®¾å¤šèŠ‚ç‚¹ç¯å¢ƒä½¿ç”¨å…±äº«å­˜å‚¨ã€‚å¦‚æœä¸æ˜¯è¿™ç§æƒ…å†µï¼Œè€Œä¸”æ¯ä¸ªèŠ‚ç‚¹åªèƒ½çœ‹åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼Œåˆ™éœ€è¦è°ƒæ•´é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«ä»¥ä¸‹è®¾ç½®çš„[`checkpoint`_section](https://www.deepspeed.ai/docs/config-json/#checkpoint-options)ï¼š

```json
{
  "checkpoint": {
    "use_node_local_storage": true
  }
}
```

å¦å¤–ï¼Œæ‚¨è¿˜å¯ä»¥ä½¿ç”¨[`Trainer`]çš„`--save_on_each_node`å‚æ•°ï¼Œä¸Šè¿°é…ç½®å°†è‡ªåŠ¨ä¸ºæ‚¨æ·»åŠ ã€‚

### åœ¨ç¬”è®°æœ¬ä¸­çš„éƒ¨ç½²
ä½œä¸ºè„šæœ¬è¿è¡Œç¬”è®°æœ¬å•å…ƒæ ¼çš„é—®é¢˜åœ¨äºæ²¡æœ‰å¸¸è§„çš„`deepspeed`å¯åŠ¨å™¨å¯ä»¥ä¾èµ–ï¼Œå› æ­¤åœ¨æŸäº›è®¾ç½®ä¸‹ï¼Œæˆ‘ä»¬ä¸å¾—ä¸æ¨¡æ‹Ÿè¯¥è¿‡ç¨‹ã€‚

å¦‚æœæ‚¨åªä½¿ç”¨ä¸€ä¸ªGPUï¼Œä»¥ä¸‹æ˜¯åœ¨ç¬”è®°æœ¬ä¸­è°ƒæ•´è®­ç»ƒä»£ç ä»¥ä½¿ç”¨DeepSpeedçš„æ–¹æ³•ï¼š

```python
# DeepSpeedè¦æ±‚å³ä½¿åœ¨åªä½¿ç”¨ä¸€ä¸ªè¿›ç¨‹æ—¶ä¹Ÿéœ€è¦ä¸€ä¸ªåˆ†å¸ƒå¼ç¯å¢ƒ
# è¿™åœ¨ç¬”è®°æœ¬ä¸­æ¨¡æ‹Ÿäº†ä¸€ä¸ªå¯åŠ¨å™¨
import os

os.environ["MASTER_ADDR"] = "localhost"
os.environ["MASTER_PORT"] = "9994"  # modify if RuntimeError: Address already in use
os.environ["RANK"] = "0"
os.environ["LOCAL_RANK"] = "0"
os.environ["WORLD_SIZE"] = "1"

# ç°åœ¨ç»§ç»­æ­£å¸¸æ“ä½œï¼Œå¹¶ä¼ é€’deepspeedé…ç½®æ–‡ä»¶
training_args = TrainingArguments(..., deepspeed="ds_config_zero3.json")
trainer = Trainer(...)
trainer.train()
```

æ³¨æ„ï¼š`...`ä»£è¡¨æ‚¨ä¼ é€’ç»™å‡½æ•°çš„æ­£å¸¸å‚æ•°ã€‚

å¦‚æœæ‚¨è¦ä½¿ç”¨å¤šä¸ªGPUï¼Œæ‚¨å¿…é¡»ä½¿ç”¨å¤šè¿›ç¨‹ç¯å¢ƒæ‰èƒ½ä½¿DeepSpeedå·¥ä½œã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨å¯åŠ¨å™¨æ¥å®ç°è¿™ä¸ªç›®çš„ï¼Œè€Œä¸èƒ½é€šè¿‡æ¨¡æ‹Ÿå¼€å§‹éƒ¨åˆ†ä¸­ä»‹ç»çš„åˆ†å¸ƒå¼ç¯å¢ƒæ¥å®Œæˆã€‚

å¦‚æœæ‚¨æƒ³è¦åœ¨ç¬”è®°æœ¬ä¸­åœ¨å½“å‰ç›®å½•ä¸­å³æ—¶åˆ›å»ºé…ç½®æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä¸“ç”¨å•å…ƒæ ¼ï¼š

```python no-style
%%bash
cat <<'EOT' > ds_config_zero3.json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
EOT
```

å¦‚æœè®­ç»ƒè„šæœ¬ä½äºæ™®é€šæ–‡ä»¶ä¸­è€Œä¸æ˜¯ç¬”è®°æœ¬å•å…ƒæ ¼ä¸­ï¼Œæ‚¨å¯ä»¥ä»å•å…ƒæ ¼ä¸­ä½¿ç”¨shellæ­£å¸¸å¯åŠ¨`deepspeed`ã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨`run_translation.py`å¯åŠ¨å®ƒï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š

```python no-style
!git clone https://github.com/huggingface/transformers
!cd transformers; deepspeed examples/pytorch/translation/run_translation.py ...
```

æˆ–è€…ä½¿ç”¨`%%bash`é­”æœ¯ï¼Œæ‚¨å¯ä»¥ç¼–å†™ä¸€ä¸ªå¤šè¡Œä»£ç ä¾›shellç¨‹åºè¿è¡Œï¼š

```python no-style
%%bash

git clone https://github.com/huggingface/transformers
cd transformers
deepspeed examples/pytorch/translation/run_translation.py ...
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨ä¸éœ€è¦ä½¿ç”¨å¼€å§‹éƒ¨åˆ†ä¸­æä¾›çš„ä»»ä½•ä»£ç ã€‚

æ³¨æ„ï¼šè™½ç„¶`%%bash`é­”æœ¯å¾ˆæ–¹ä¾¿ï¼Œä½†ç›®å‰å®ƒä¼šç¼“å†²è¾“å‡ºï¼Œå› æ­¤åœ¨è¿›ç¨‹å®Œæˆä¹‹å‰æ‚¨ä¸ä¼šçœ‹åˆ°æ—¥å¿—ã€‚

`stage3_max_live_parameters`æ˜¯åœ¨ä»»ä½•ç»™å®šæ—¶é—´å†…ä¿ç•™åœ¨GPUä¸Šçš„å®Œæ•´å‚æ•°çš„ä¸Šé™ã€‚"é‡å¤ä½¿ç”¨è·ç¦»"æ˜¯ä¸€ä¸ªè¡¡é‡å‚æ•°å°†æ¥ä½•æ—¶å†æ¬¡ä½¿ç”¨çš„åº¦é‡æ ‡å‡†ï¼Œæˆ‘ä»¬ä½¿ç”¨`stage3_max_reuse_distance`æ¥å†³å®šæ˜¯ä¸¢å¼ƒå‚æ•°è¿˜æ˜¯ä¿ç•™å‚æ•°ã€‚å¦‚æœä¸€ä¸ªå‚æ•°å°†åœ¨ä¸ä¹…çš„å°†æ¥å†æ¬¡ä½¿ç”¨ï¼ˆå°äº`stage3_max_reuse_distance`ï¼‰ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†ä¿ç•™å®ƒä»¥å‡å°‘é€šä¿¡å¼€é”€ã€‚å½“æ‚¨å¯ç”¨æ¿€æ´»æ£€æŸ¥ç‚¹æ—¶ï¼Œè¿™éå¸¸æœ‰ç”¨ï¼Œå…¶ä¸­æˆ‘ä»¬å¯¹å•å±‚è¿›è¡Œå‰å‘é‡è®¡ç®—å’Œåå‘ä¼ é€’ï¼Œå¹¶å¸Œæœ›åœ¨å‰å‘é‡è®¡ç®—ä¸­ä¿ç•™å‚æ•°ç›´åˆ°åå‘ä¼ é€’ã€‚

ä»¥ä¸‹é…ç½®å€¼å–å†³äºæ¨¡å‹çš„éšè—å¤§å°ï¼š

- `reduce_bucket_size`ï¼š`hidden_size*hidden_size`
- `stage3_prefetch_bucket_size`ï¼š`0.9 * hidden_size * hidden_size`
- `stage3_param_persistence_threshold`ï¼š`10 * hidden_size`

å› æ­¤ï¼Œå°†è¿™äº›å€¼è®¾ç½®ä¸º`auto`ï¼Œ[`Trainer`]å°†è‡ªåŠ¨åˆ†é…æ¨èçš„å€¼ã€‚å½“ç„¶ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ˜¾å¼è®¾ç½®è¿™äº›å€¼ã€‚

`stage3_gather_16bit_weights_on_model_save`åœ¨ä¿å­˜æ¨¡å‹æ—¶å¯ç”¨æ¨¡å‹fp16æƒé‡åˆå¹¶ã€‚å¯¹äºå¤§å‹æ¨¡å‹å’Œå¤šä¸ªGPUï¼Œè¿™æ˜¯ä¸€é¡¹æ˜‚è´µçš„æ“ä½œï¼Œæ— è®ºæ˜¯åœ¨å†…å­˜è¿˜æ˜¯é€Ÿåº¦æ–¹é¢ã€‚å¦‚æœæ‚¨è®¡åˆ’æ¢å¤è®­ç»ƒï¼Œç›®å‰éœ€è¦å®ƒã€‚è¯·æ³¨æ„ï¼Œå°†æ¥ä¼šæœ‰æ›´æ–°ï¼Œæ¶ˆé™¤æ­¤é™åˆ¶å¹¶æä¾›æ›´çµæ´»çš„åŠŸèƒ½ã€‚

å¦‚æœæ‚¨ä»ZeRO-2é…ç½®è¿ç§»ï¼Œè¯·æ³¨æ„ï¼ŒZeRO-3ä¸ä½¿ç”¨`allgather_partitions`ï¼Œ`allgather_bucket_size`å’Œ`reduce_scatter`é…ç½®å‚æ•°ã€‚å¦‚æœæ‚¨åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿ç•™è¿™äº›å‚æ•°ï¼Œå®ƒä»¬å°†è¢«å¿½ç•¥ã€‚

- `sub_group_size`ï¼š`1e9`

`sub_group_size`æ§åˆ¶åœ¨ä¼˜åŒ–å™¨æ­¥éª¤æœŸé—´å‚æ•°æ›´æ–°çš„ç²’åº¦ã€‚å‚æ•°åˆ†ç»„åˆ°`sub_group_size`å¤§å°çš„å­˜å‚¨æ¡¶ä¸­ï¼Œå¹¶ä¸”æ¯ä¸ªå­˜å‚¨æ¡¶éƒ½é€ä¸ªæ›´æ–°ã€‚å½“ä¸ZeRO-Infinityä¸­çš„NVMeå¸è½½ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œ`sub_group_size`æ§åˆ¶æ¨¡å‹çŠ¶æ€åœ¨ä¼˜åŒ–å™¨æ­¥éª¤æœŸé—´ä»NVMeç§»å…¥å’Œç§»å‡ºCPUå†…å­˜çš„ç²’åº¦ã€‚è¿™å¯é˜²æ­¢åœ¨æå¤§å‹æ¨¡å‹çš„æƒ…å†µä¸‹CPUå†…å­˜ä¸è¶³ã€‚

å½“ä¸ä½¿ç”¨NVMeå¸è½½æ—¶ï¼Œæ‚¨å¯ä»¥å°†`sub_group_size`ä¿ç•™ä¸ºé»˜è®¤å€¼*1e9*ã€‚åœ¨ä»¥ä¸‹æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½å¸Œæœ›æ›´æ”¹å…¶é»˜è®¤å€¼ï¼š

1. ä¼˜åŒ–å™¨æ­¥éª¤æ—¶é‡åˆ°OOMï¼šå‡å°`sub_group_size`ä»¥å‡å°‘ä¸´æ—¶ç¼“å†²åŒºçš„å†…å­˜ä½¿ç”¨
2. ä¼˜åŒ–å™¨æ­¥éª¤èŠ±è´¹å¾ˆé•¿æ—¶é—´ï¼šå¢åŠ `sub_group_size`ä»¥æé«˜ç”±äºå¢åŠ æ•°æ®ç¼“å†²åŒºè€Œå¯¼è‡´çš„å¸¦å®½åˆ©ç”¨ç‡ã€‚

#### ZeRO-0é…ç½®

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å°†ç¬¬0å’Œç¬¬1é˜¶æ®µæ”¾åœ¨æœ€åï¼Œå› ä¸ºå®ƒä»¬å¾ˆå°‘ä½¿ç”¨ã€‚

é˜¶æ®µ0æ˜¯ç¦ç”¨æ‰€æœ‰åˆ†ç‰‡ç±»å‹ï¼Œä»…ä½¿ç”¨DeepSpeedä½œä¸ºDDPã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•å¯ç”¨å®ƒï¼š

```json
{
    "zero_optimization": {
        "stage": 0
    }
}
```

è¿™å°†å®Œå…¨ç¦ç”¨ZeROï¼Œè€Œæ‚¨æ— éœ€æ›´æ”¹å…¶ä»–ä»»ä½•å†…å®¹ã€‚

#### ZeRO-1é…ç½®

ç¬¬1é˜¶æ®µæ˜¯ç¬¬2é˜¶æ®µå‡å»æ¢¯åº¦åˆ†ç‰‡ã€‚æ‚¨å¯ä»¥å°è¯•ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ¥ç¨å¾®åŠ å¿«é€Ÿåº¦ï¼Œåªåœ¨ä¼˜åŒ–å™¨çŠ¶æ€ä¸­è¿›è¡Œåˆ†ç‰‡ï¼š

```json
{
    "zero_optimization": {
        "stage": 1
    }
}
```

### NVMeæ”¯æŒ

é€šè¿‡ä½¿ç”¨NVMeå†…å­˜å¯ä»¥æ‰©å±•GPUå’ŒCPUå†…å­˜ï¼ŒZeRO-Infinityå…è®¸è®­ç»ƒè§„æ¨¡éå¸¸å¤§çš„æ¨¡å‹ã€‚ç”±äºæ™ºèƒ½åˆ’åˆ†å’Œå¹³é“ºç®—æ³•ï¼Œæ¯ä¸ªGPUåœ¨å¸è½½è¿‡ç¨‹ä¸­éœ€è¦å‘é€å’Œæ¥æ”¶éå¸¸å°‘é‡çš„æ•°æ®ï¼Œå› æ­¤ç°ä»£NVMeè¢«è¯æ˜é€‚åˆä¸ºè®­ç»ƒè¿‡ç¨‹æä¾›æ€»å…±æ›´å¤§çš„å†…å­˜æ± ã€‚ZeRO-Infinityéœ€è¦å¯ç”¨ZeRO-3ã€‚

ä»¥ä¸‹é…ç½®ç¤ºä¾‹å¯ç”¨äº†å°†ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°åŒæ—¶å¸è½½åˆ°NVMeï¼š

```json
{
    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "nvme",
            "nvme_path": "/local_nvme",
            "pin_memory": true,
            "buffer_count": 4,
            "fast_init": false
        },
        "offload_param": {
            "device": "nvme",
            "nvme_path": "/local_nvme",
            "pin_memory": true,
            "buffer_count": 5,
            "buffer_size": 1e8,
            "max_in_cpu": 1e9
        },
        "aio": {
            "block_size": 262144,
            "queue_depth": 32,
            "thread_count": 1,
            "single_submit": false,
            "overlap_events": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },
}
```

æ‚¨å¯ä»¥é€‰æ‹©åŒæ—¶å¸è½½ä¼˜åŒ–å™¨çŠ¶æ€å’Œå‚æ•°åˆ°NVMeï¼Œæˆ–è€…åªå¸è½½å®ƒä»¬ä¸­çš„ä¸€ä¸ªï¼Œæˆ–è€…éƒ½ä¸å¸è½½ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æœ‰å¤§é‡çš„CPUå†…å­˜å¯ç”¨ï¼Œå¯ä»¥åªå¸è½½åˆ°CPUå†…å­˜ï¼Œå› ä¸ºå®ƒçš„é€Ÿåº¦æ›´å¿«ï¼ˆæç¤ºï¼š"device": "cpu"ï¼‰ã€‚

è¿™æ˜¯å¸è½½[ä¼˜åŒ–å™¨çŠ¶æ€](https://www.deepspeed.ai/docs/config-json/#optimizer-offloading)å’Œ[å‚æ•°](https://www.deepspeed.ai/docs/config-json/#parameter-offloading)çš„å®Œæ•´æ–‡æ¡£ã€‚

ç¡®ä¿`nvme_path`å®é™…ä¸Šæ˜¯ä¸€ä¸ªNVMeï¼Œå› ä¸ºå®ƒå¯ä»¥ä¸å¸¸è§„ç¡¬ç›˜æˆ–å›ºæ€ç¡¬ç›˜ä¸€èµ·ä½¿ç”¨ï¼Œä½†é€Ÿåº¦è¦æ…¢å¾—å¤šã€‚å¿«é€Ÿå¯æ‰©å±•çš„è®­ç»ƒæ˜¯é’ˆå¯¹ç°ä»£NVMeä¼ è¾“é€Ÿåº¦è®¾è®¡çš„ï¼ˆæŒ‰ç…§å½“å‰ç¼–å†™æ—¶ï¼Œæœ€å¤§è¯»å–é€Ÿåº¦çº¦ä¸º3.5GB / sï¼Œå†™å…¥é€Ÿåº¦çº¦ä¸º3GB / sï¼‰ã€‚

è¦æ‰¾å‡ºæœ€ä½³çš„`aio`é…ç½®å—ï¼Œæ‚¨å¿…é¡»åœ¨ç›®æ ‡è®¾ç½®ä¸Šè¿è¡ŒåŸºå‡†æµ‹è¯•ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚è§[æ­¤å¤„](https://github.com/microsoft/DeepSpeed/issues/998)ã€‚

#### ZeRO-2ä¸ZeRO-3æ€§èƒ½è¿›è¡Œæ¯”è¾ƒ

å¦‚æœåœ¨å…¶ä»–æ‰€æœ‰é…ç½®ä¿æŒä¸å˜çš„æƒ…å†µä¸‹ï¼ŒZeRO-3å¯èƒ½æ¯”ZeRO-2æ…¢ï¼Œå› ä¸ºå‰è€…éœ€è¦æ”¶é›†æ¨¡å‹æƒé‡ï¼Œå¹¶ä¸”æ¯”ZeRO-2æ‰§è¡Œçš„æ“ä½œæ›´å¤šã€‚å¦‚æœZeRO-2æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼Œå¹¶ä¸”æ‚¨ä¸éœ€è¦åœ¨å‡ ä¸ªGPUä¹‹é—´æ‰©å±•ï¼Œé‚£ä¹ˆå¯ä»¥é€‰æ‹©ä½¿ç”¨ZeRO-2ã€‚é‡è¦çš„æ˜¯è¦äº†è§£ï¼ŒZeRO-3å¯ä»¥ä»¥æ›´é«˜çš„å¯æ‰©å±•æ€§ä¸ºä»£ä»·æä¾›æ›´é«˜çš„æ€§èƒ½ã€‚

å¯ä»¥è°ƒæ•´ZeRO-3é…ç½®ï¼Œä½¿å…¶æ€§èƒ½æ›´æ¥è¿‘äºZeRO-2ï¼š

- å°†`stage3_param_persistence_threshold`è®¾ç½®ä¸ºä¸€ä¸ªéå¸¸å¤§çš„å€¼-å¤§äºæœ€å¤§çš„å‚æ•°å€¼ï¼Œä¾‹å¦‚`6 * hidden_size * hidden_size`ã€‚è¿™å°†ä½¿å‚æ•°ä¿ç•™åœ¨GPUä¸Šã€‚
- å…³é—­`offload_params`ï¼Œå› ä¸ºZeRO-2æ²¡æœ‰è¯¥é€‰é¡¹ã€‚

å³ä½¿æ‚¨ä¸æ›´æ”¹`stage3_param_persistence_threshold`ï¼Œåªè¦å°†`offload_params`å…³é—­ï¼Œæ€§èƒ½å¯èƒ½ä¼šæ˜¾ç€æé«˜ã€‚å½“ç„¶ï¼Œè¿™äº›æ›´æ”¹å°†å½±å“æ‚¨å¯ä»¥è®­ç»ƒçš„æ¨¡å‹çš„å¤§å°ã€‚å› æ­¤ï¼Œè¿™äº›æ›´æ”¹å¯è®©æ‚¨åœ¨å¯æ‰©å±•æ€§å’Œé€Ÿåº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œå…·ä½“å–å†³äºæ‚¨çš„éœ€æ±‚ã€‚

#### ZeRO-2ç¤ºä¾‹

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ZeRO-2è‡ªåŠ¨é…ç½®æ–‡ä»¶`ds_config_zero2.json`ï¼š

```json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ‰‹åŠ¨è®¾ç½®çš„ZeRO-2é…ç½®æ–‡ä»¶ï¼Œä¸»è¦æ˜¯ä¸ºäº†è®©æ‚¨çœ‹åˆ°å…¸å‹å€¼çš„å¤–è§‚ï¼Œä½†æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨å…¶ä¸­å…·æœ‰å¤šä¸ª`auto`è®¾ç½®çš„å€¼ã€‚

```json
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 3e-5,
            "betas": [0.8, 0.999],
            "eps": 1e-8,
            "weight_decay": 3e-7
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 3e-5,
            "warmup_num_steps": 500
        }
    },

    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },

    "steps_per_print": 2000,
    "wall_clock_breakdown": false
}
```

#### ZeRO-3ç¤ºä¾‹

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ZeRO-3è‡ªåŠ¨é…ç½®æ–‡ä»¶`ds_config_zero3.json`ï¼š

```json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": "auto",
            "betas": "auto",
            "eps": "auto",
            "weight_decay": "auto"
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": "auto",
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto"
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "gradient_accumulation_steps": "auto",
    "gradient_clipping": "auto",
    "steps_per_print": 2000,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto",
    "wall_clock_breakdown": false
}
```

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æ‰‹åŠ¨è®¾ç½®çš„ZeRO-3é…ç½®æ–‡ä»¶ï¼Œä¸»è¦æ˜¯ä¸ºäº†è®©æ‚¨çœ‹åˆ°å…¸å‹å€¼çš„å¤–è§‚ï¼Œä½†æˆ‘ä»¬å¼ºçƒˆå»ºè®®ä½¿ç”¨å…¶ä¸­å…·æœ‰å¤šä¸ª`auto`è®¾ç½®çš„å€¼ã€‚

```json
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    },

    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 3e-5,
            "betas": [0.8, 0.999],
            "eps": 1e-8,
            "weight_decay": 3e-7
        }
    },

    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 3e-5,
            "warmup_num_steps": 500
        }
    },

    "zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": 1e6,
        "stage3_prefetch_bucket_size": 0.94e6,
        "stage3_param_persistence_threshold": 1e4,
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },

    "steps_per_print": 2000,
    "wall_clock_breakdown": false
}
```

#### å¦‚ä½•é€‰æ‹©æœ€ä½³æ€§èƒ½çš„ZeROé˜¶æ®µå’Œå¸è½½æ–¹å¼

ç°åœ¨æ‚¨çŸ¥é“æœ‰æ‰€æœ‰è¿™äº›ä¸åŒçš„é˜¶æ®µäº†ã€‚å¦‚ä½•å†³å®šè¦ä½¿ç”¨å…¶ä¸­å“ªä¸ªé˜¶æ®µå‘¢ï¼Ÿæœ¬éƒ¨åˆ†å°†å°è¯•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚

é€šå¸¸ï¼Œä»¥ä¸‹æƒ…å†µé€‚ç”¨ï¼š

- ä»é€Ÿåº¦è§’åº¦æ¥çœ‹ï¼ˆå·¦è¾¹æ¯”å³è¾¹å¿«ï¼‰

é˜¶æ®µ0ï¼ˆDDPï¼‰> é˜¶æ®µ1 > é˜¶æ®µ2 > é˜¶æ®µ2 + å¸è½½ > é˜¶æ®µ3 > é˜¶æ®µ3 + å¸è½½

- ä»GPUå†…å­˜ä½¿ç”¨ç‡æ¥çœ‹ï¼ˆå³è¾¹æ¯”å·¦è¾¹æ›´é«˜æ•ˆï¼‰

é˜¶æ®µ0ï¼ˆDDPï¼‰< é˜¶æ®µ1 < é˜¶æ®µ2 < é˜¶æ®µ2 + å¸è½½ < é˜¶æ®µ3 < é˜¶æ®µ3 + å¸è½½

å› æ­¤ï¼Œå½“æ‚¨å¸Œæœ›è·å¾—æœ€å¿«çš„æ‰§è¡Œé€Ÿåº¦ï¼ŒåŒæ—¶é€‚åº”æœ€å°æ•°é‡çš„GPUæ—¶ï¼Œå¯ä»¥æŒ‰ç…§ä»¥ä¸‹æµç¨‹è¿›è¡Œæ“ä½œã€‚æˆ‘ä»¬ä»æœ€å¿«çš„æ–¹æ³•å¼€å§‹ï¼Œå¦‚æœå‘ç”ŸGPU OOMï¼Œç„¶åè½¬åˆ°æ›´ä½é€Ÿçš„æ–¹æ³•ï¼Œä½†ä½¿ç”¨æ›´å°‘çš„GPUå†…å­˜ã€‚ä¾æ­¤ç±»æ¨ã€‚

é¦–å…ˆå°†æ‰¹æ¬¡å¤§å°è®¾ç½®ä¸º1ï¼ˆæ‚¨å§‹ç»ˆå¯ä»¥ä½¿ç”¨æ¸è¿›ç´¯ç§¯è¿›è¡Œä»»ä½•æ‰€éœ€çš„æœ‰æ•ˆæ‰¹æ¬¡å¤§å°ï¼‰ã€‚

1. å¯ç”¨`--gradient_checkpointing 1`ï¼ˆHF Trainerï¼‰æˆ–ç›´æ¥`model.gradient_checkpointing_enable()`- å¦‚æœå‘ç”ŸOOMï¼Œåˆ™
2. å°è¯•é¦–å…ˆä½¿ç”¨ZeROé˜¶æ®µ2ã€‚å¦‚æœå‘ç”ŸOOMï¼Œåˆ™
3. å°è¯•ä½¿ç”¨ZeROé˜¶æ®µ2 + `offload_optimizer`ã€‚å¦‚æœå‘ç”ŸOOMï¼Œåˆ™
4. åˆ‡æ¢åˆ°ZeROé˜¶æ®µ3ã€‚å¦‚æœå‘ç”ŸOOMï¼Œåˆ™
5. å°†`offload_param`è®¾ç½®ä¸º`cpu`ã€‚å¦‚æœå‘ç”ŸOOMï¼Œåˆ™
6. å°†`offload_optimizer`è®¾ç½®ä¸º`cpu`ã€‚å¦‚æœå‘ç”ŸOOMï¼Œåˆ™

7. å¦‚æœä»ç„¶æ— æ³•é€‚åº”æ‰¹æ¬¡å¤§å°ä¸º1ï¼Œè¯·æ£€æŸ¥å„ç§é»˜è®¤å€¼ï¼Œå¹¶åœ¨å¯èƒ½çš„æƒ…å†µä¸‹å°†å…¶é™ä½ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½¿ç”¨`generate`å¹¶ä¸”ä¸ä½¿ç”¨å®½çš„æœç´¢æŸï¼Œå°†å…¶å˜ä¸ºæ›´çª„ï¼Œå› ä¸ºå®ƒä¼šæ¶ˆè€—å¤§é‡å†…å­˜ã€‚

8. ç»å¯¹ä½¿ç”¨åŠç²¾åº¦è€Œä¸æ˜¯fp32 - å› æ­¤åœ¨AmpereåŠæ›´é«˜çš„GPUä¸Šä½¿ç”¨bf16ï¼Œåœ¨è¾ƒæ—§çš„GPUæ¶æ„ä¸Šä½¿ç”¨fp16ã€‚

9. å¦‚æœä»ç„¶å‘ç”ŸOOMï¼Œå¯ä»¥æ·»åŠ æ›´å¤šç¡¬ä»¶æˆ–å¯ç”¨ZeRO-Infinity-å°†`offload_param`å’Œ`offload_optimizer`åˆ‡æ¢åˆ°`nvme`ã€‚æ‚¨éœ€è¦ç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªéå¸¸å¿«é€Ÿçš„nvmeã€‚ä½œä¸ºä¸€ä¸ªè½¶äº‹ï¼Œæˆ‘æ›¾ç»èƒ½å¤Ÿåœ¨ä¸€ä¸ªå°å‹GPUä¸Šæ¨æ–­BLOOM-176Bï¼Œä½†é€Ÿåº¦éå¸¸æ…¢ã€‚ä½†å®ƒç¡®å®å¯ä»¥å·¥ä½œï¼

å½“æ‚¨çš„æ‰¹æ¬¡å¤§å°ä¸º1æ—¶ï¼Œæ²¡æœ‰å‘ç”ŸOOMï¼Œè¯·æµ‹é‡æœ‰æ•ˆååé‡ã€‚

æ¥ä¸‹æ¥ï¼Œå°è¯•å¢åŠ æ‰¹æ¬¡å¤§å°ï¼Œå°½å¯èƒ½å¤§ï¼Œå› ä¸ºæ‰¹æ¬¡å¤§å°è¶Šå¤§ï¼ŒGPUæ‰§è¡Œçš„æ•ˆç‡è¶Šé«˜ï¼Œå› ä¸ºå®ƒä»¬åœ¨ä¹˜ä»¥çŸ©é˜µæ—¶è¡¨ç°æœ€ä½³ï¼Œè€Œè¿™äº›çŸ©é˜µéƒ½éå¸¸å¤§ã€‚

ç°åœ¨æ€§èƒ½ä¼˜åŒ–æ¸¸æˆå¼€å§‹ã€‚æ‚¨å¯ä»¥å…³é—­ä¸€äº›å¸è½½åŠŸèƒ½æˆ–è€…é™ä½ ZeRO é˜¶æ®µï¼Œå¹¶å¢åŠ /å‡å°‘æ‰¹å¤§å°ï¼Œç„¶åå†æµ‹é‡æœ‰æ•ˆååé‡ã€‚åå¤æ´—æ¶¤ç›´åˆ°æ»¡æ„ã€‚

ä¸è¦èŠ±å¤ªå¤šæ—¶é—´åœ¨ä¸Šé¢ï¼Œä½†æ˜¯å¦‚æœæ‚¨è¦å¼€å§‹ä¸€ä¸ªä¸ºæœŸ 3 ä¸ªæœˆçš„è®­ç»ƒï¼Œç¡®ä¿åœ¨æ­¤è¿‡ç¨‹ä¸­èŠ±å‡ å¤©æ—¶é—´æ‰¾åˆ°æœ€æœ‰æ•ˆçš„ååé‡è®¾ç½®ã€‚è¿™æ ·ä½ çš„è®­ç»ƒæˆæœ¬å°†æ˜¯æœ€ä½çš„ï¼Œè®­ç»ƒé€Ÿåº¦ä¹Ÿä¼šæ›´å¿«ã€‚åœ¨å½“å‰å¿«èŠ‚å¥çš„æœºå™¨å­¦ä¹ ä¸–ç•Œä¸­ï¼Œå¦‚æœä½ å¤šèŠ±ä¸€ä¸ªæœˆçš„æ—¶é—´æ¥è®­ç»ƒæŸä¸ªä¸œè¥¿ï¼Œå¾ˆå¯èƒ½å°±ä¼šé”™è¿‡ä¸€ä¸ªç»ä½³çš„æœºä¼šã€‚å½“ç„¶ï¼Œè¿™åªæ˜¯æˆ‘çš„è§‚å¯Ÿåˆ†äº«ï¼Œæ— è®ºå¦‚ä½•ï¼Œæˆ‘éƒ½ä¸æƒ³å‚¬ä¿ƒä½ ã€‚åœ¨å¼€å§‹è®­ç»ƒ BLOOM-176B ä¹‹å‰ï¼Œæˆ‘èŠ±äº† 2 å¤©æ—¶é—´è¿›è¡Œäº†è¿™ä¸ªè¿‡ç¨‹ï¼Œå¹¶ä¸”èƒ½å¤Ÿå°†ååé‡ä» 90 æé«˜åˆ° 150 TFLOPsï¼è¿™ä¸ªåŠªåŠ›å¸®åŠ©æˆ‘ä»¬èŠ‚çº¦äº†ä¸€ä¸ªå¤šæœˆçš„è®­ç»ƒæ—¶é—´ã€‚

è¿™äº›æ³¨æ„äº‹é¡¹ä¸»è¦æ˜¯ä¸ºè®­ç»ƒæ¨¡å¼ç¼–å†™çš„ï¼Œä½†å¤§éƒ¨åˆ†é€‚ç”¨äºæ¨ç†æ¨¡å¼ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¨ç†æœŸé—´ï¼Œæ¸å˜æ£€æŸ¥ç‚¹æ˜¯æ— æ•ˆæ“ä½œï¼Œå› ä¸ºå®ƒåªåœ¨è®­ç»ƒæœŸé—´æœ‰ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ï¼Œå¦‚æœæ‚¨æ­£åœ¨è¿›è¡Œå¤š GPU æ¨ç†ï¼Œå¹¶ä¸”æœªä½¿ç”¨ [DeepSpeed-Inference](https://www.deepspeed.ai/tutorials/inference-tutorial/)ï¼Œ[Accelerate](https://huggingface.co/blog/bloom-inference-pytorch-scripts)åº”è¯¥æä¾›æ›´ä¼˜ç§€çš„æ€§èƒ½ã€‚

å…¶ä»–ä¸æ€§èƒ½ç›¸å…³çš„å¿«é€Ÿæ³¨é‡Š:
- å¦‚æœæ‚¨ä»å¤´å¼€å§‹è®­ç»ƒæŸä¸ªä¸œè¥¿ï¼Œè¯·å°è¯•ä½¿å¼ é‡çš„å½¢çŠ¶å¯è¢« 16 æ•´é™¤ï¼ˆä¾‹å¦‚éšè—å¤§å°ï¼‰ã€‚å¯¹äºæ‰¹å¤§å°ï¼Œè¯·è‡³å°‘å°è¯•ä½¿å…¶å¯è¢« 2 æ•´é™¤ã€‚å¦‚æœè¦ä» GPU ä¸­è·å¾—æ›´é«˜çš„æ€§èƒ½ï¼Œå¯ä»¥å°è¯•ç¡¬ä»¶ç‰¹å®šçš„[æ³¢å’Œç“·ç –é‡åŒ–](https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/)æ•´é™¤æ–¹å¼ã€‚

### æ¿€æ´»æ£€æŸ¥ç‚¹æˆ–æ¸å˜æ£€æŸ¥ç‚¹

æ¿€æ´»æ£€æŸ¥ç‚¹å’Œæ¸å˜æ£€æŸ¥ç‚¹æ˜¯ä¸¤ä¸ªç›¸äº’ç‹¬ç«‹çš„æœ¯è¯­ï¼ŒæŒ‡çš„æ˜¯åŒä¸€æ–¹æ³•ã€‚è¿™éå¸¸ä»¤äººå›°æƒ‘ï¼Œä½†æƒ…å†µå°±æ˜¯è¿™æ ·ã€‚

æ¸å˜æ£€æŸ¥ç‚¹å…è®¸æ‚¨åœ¨ GPU å†…å­˜å’Œé€Ÿåº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œå®ƒå¯ä»¥å…‹æœ GPU OOM æˆ–å¢åŠ æ‰¹å¤§å°ï¼Œä»è€Œé€šå¸¸å¯ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚

HF å˜æ¢å™¨æ¨¡å‹ä¸çŸ¥é“ DeepSpeed çš„æ¿€æ´»æ£€æŸ¥ç‚¹ï¼Œå› æ­¤ï¼Œå¦‚æœæ‚¨å°è¯•åœ¨ DeepSpeed é…ç½®æ–‡ä»¶ä¸­å¯ç”¨è¯¥åŠŸèƒ½ï¼Œå°†ä¸ä¼šå‘ç”Ÿä»»ä½•äº‹æƒ…ã€‚

å› æ­¤ï¼Œæ‚¨æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥åˆ©ç”¨æ­¤éå¸¸æœ‰ç›Šçš„åŠŸèƒ½ï¼š

1. å¦‚æœè¦ä½¿ç”¨ HF å˜æ¢å™¨æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ `model.gradient_checkpointing_enable()` æˆ–åœ¨ HF Trainer ä¸­ä½¿ç”¨ `--gradient_checkpointing`ï¼Œå®ƒå°†è‡ªåŠ¨ä¸ºæ‚¨å¯ç”¨æ­¤åŠŸèƒ½ã€‚åœ¨é‚£é‡Œä½¿ç”¨äº† `torch.utils.checkpoint`ã€‚
2. å¦‚æœæ‚¨è‡ªå·±ç¼–å†™äº†æ¨¡å‹ï¼Œå¹¶ä¸”æƒ³ä½¿ç”¨ DeepSpeed çš„æ¿€æ´»æ£€æŸ¥ç‚¹ï¼Œåˆ™å¯ä»¥ä½¿ç”¨[æ­¤å¤„](https://deepspeed.readthedocs.io/en/latest/activation-checkpointing.html)è§„å®šçš„ APIã€‚æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ HF å˜æ¢å™¨å»ºæ¨¡ä»£ç å¹¶å°†`torch.utils.checkpoint` æ›¿æ¢ä¸º DeepSpeed çš„ APIã€‚åè€…æ›´åŠ çµæ´»ï¼Œå› ä¸ºå®ƒå…è®¸æ‚¨å°†å‰å‘æ¿€æ´»å¸è½½åˆ° CPU å†…å­˜ï¼Œè€Œä¸æ˜¯é‡æ–°è®¡ç®—å®ƒä»¬ã€‚

### ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨

åªè¦ä¸å¯ç”¨ `offload_optimizer`ï¼Œå°±å¯ä»¥æ··åˆä½¿ç”¨ DeepSpeed å’Œ HuggingFace çš„è°ƒåº¦å™¨å’Œä¼˜åŒ–å™¨ï¼Œé™¤äº†ä½¿ç”¨ HuggingFace è°ƒåº¦å™¨å’Œ DeepSpeed ä¼˜åŒ–å™¨çš„ç»„åˆä¹‹å¤–:

| ç»„åˆ       | HF è°ƒåº¦å™¨ | DS è°ƒåº¦å™¨ |
| HF ä¼˜åŒ–å™¨ | æ˜¯          | æ˜¯          |
| DS ä¼˜åŒ–å™¨ | å¦           | æ˜¯          |

å¯ä»¥ä½¿ç”¨é DeepSpeed ä¼˜åŒ–å™¨ï¼Œåªè¦å®ƒå…·æœ‰ CPU å’Œ GPU å®ç°ï¼ˆä¸åŒ…æ‹¬ LAMBï¼‰ã€‚

ä¼˜åŒ–å™¨å¿…é¡»é€šè¿‡[æ­¤å¤„](https://www.deepspeed.ai/docs/config-json/#optimizer-parameters)è¿›è¡Œé…ç½®ã€‚DeepSpeed çš„ä¸»è¦ä¼˜åŒ–å™¨æ˜¯ Adamã€AdamWã€OneBitAdam å’Œ Lambã€‚è¿™äº›ä¼˜åŒ–å™¨å·²ç»ç»è¿‡å…¨é¢æµ‹è¯•ï¼Œå› æ­¤å»ºè®®ä½¿ç”¨ã€‚å®ƒè¿˜å¯ä»¥ä» `torch` å¯¼å…¥å…¶ä»–ä¼˜åŒ–å™¨ã€‚å¦‚æœä¸åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½® `optimizer` æ¡ç›®ï¼Œåˆ™ [`Trainer`] å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º `AdamW`ï¼Œå¹¶ä½¿ç”¨æä¾›çš„å€¼æˆ–é»˜è®¤å€¼è®¾ç½®ä»¥ä¸‹å‘½ä»¤è¡Œå‚æ•°: `--learning_rate`ã€`--adam_beta1`ã€`--adam_beta2`ã€`--adam_epsilon` å’Œ `--weight_decay`ã€‚

ä»¥ä¸‹æ˜¯è‡ªåŠ¨é…ç½®çš„ `AdamW` çš„ç¤ºä¾‹:

```json
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": "auto",
         "betas": "auto",
         "eps": "auto",
         "weight_decay": "auto"
       }
   }
}
```

è¯·æ³¨æ„ï¼Œå‘½ä»¤è¡Œå‚æ•°å°†è®¾ç½®é…ç½®æ–‡ä»¶ä¸­çš„å€¼ã€‚è¿™æ ·å°±æœ‰äº†ä¸€ä¸ªå®šä¹‰å€¼çš„å”¯ä¸€æ¥æºï¼Œå¹¶ä¸”é¿å…äº†ä¾‹å¦‚åœ¨ä¸åŒä½ç½®è®¾ç½®å­¦ä¹ ç‡ä¸ºä¸åŒå€¼æ—¶éš¾ä»¥æ‰¾åˆ°çš„é”™è¯¯ã€‚å‘½ä»¤è¡Œçš„è§„åˆ™ä¼˜å…ˆã€‚è¢«è¦†ç›–çš„å€¼æœ‰:

- `lr` ä½¿ç”¨ `--learning_rate` çš„å€¼
- `betas` ä½¿ç”¨ `--adam_beta1` å’Œ `--adam_beta2` çš„å€¼
- `eps` ä½¿ç”¨ `--adam_epsilon` çš„å€¼
- `weight_decay` ä½¿ç”¨ `--weight_decay` çš„å€¼

å› æ­¤ï¼Œè¯·è®°ä½åœ¨å‘½ä»¤è¡Œä¸Šè°ƒæ•´å…±äº«è¶…å‚æ•°ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼åœ°è®¾ç½®å€¼:

```json
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": 0.001,
         "betas": [0.8, 0.999],
         "eps": 1e-8,
         "weight_decay": 3e-7
       }
   }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥ [`Trainer`] å‘½ä»¤è¡Œå‚æ•°å’Œ DeepSpeed é…ç½®æ–‡ä»¶ã€‚

å¦‚æœè¦ä½¿ç”¨å…¶ä»–æœªåˆ—å‡ºçš„ä¼˜åŒ–å™¨ï¼Œå¿…é¡»å°†å…¶æ·»åŠ åˆ°é¡¶çº§é…ç½®ä¸­ã€‚

```json
{
   "zero_allow_untested_optimizer": true
}
```

ä¸ `AdamW` ç±»ä¼¼ï¼Œæ‚¨å¯ä»¥é…ç½®å…¶ä»–å®˜æ–¹æ”¯æŒçš„ä¼˜åŒ–å™¨ã€‚åªéœ€è®°ä½è¿™äº›ä¼˜åŒ–å™¨å¯èƒ½å…·æœ‰ä¸åŒçš„é…ç½®å€¼ã€‚ä¾‹å¦‚ï¼Œå¯¹äº Adamï¼Œæ‚¨å°†å¸Œæœ› `weight_decay` åœ¨`0.01` å·¦å³ã€‚

æ­¤å¤–ï¼Œå½“ä¸å¸è½½ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œä½¿ç”¨ Deepspeed çš„ CPU Adam ä¼˜åŒ–å™¨æ—¶æ•ˆæœæœ€å¥½ã€‚å¦‚æœè¦åœ¨å¸è½½æ—¶ä½¿ç”¨å…¶ä»–ä¼˜åŒ–å™¨ï¼Œè‡ª `deepspeed==0.8.3` ä»¥æ¥ï¼Œæ‚¨è¿˜éœ€è¦æ·»åŠ :

```json
{
   "zero_force_ds_cpu_optimizer": false
}
```
åˆ°é¡¶çº§é…ç½®ã€‚

#### ä¼˜åŒ–å™¨

DeepSpeed çš„ä¸»è¦ä¼˜åŒ–å™¨æ˜¯ Adamã€AdamWã€OneBitAdam å’Œ Lambã€‚è¿™äº›å·²ç»ä¸ ZeRO è¿›è¡Œäº†å½»åº•æµ‹è¯•ï¼Œå› æ­¤å»ºè®®ä½¿ç”¨ã€‚å®ƒä¹Ÿå¯ä»¥ä» `torch` å¯¼å…¥å…¶ä»–ä¼˜åŒ–å™¨ã€‚å®Œæ•´çš„æ–‡æ¡£åœ¨[è¿™é‡Œ](https://www.deepspeed.ai/docs/config-json/#optimizer-parameters)ã€‚

å¦‚æœæœªåœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½® `optimizer` æ¡ç›®ï¼Œåˆ™ [`Trainer`] å°†è‡ªåŠ¨å°†å…¶è®¾ç½®ä¸º `AdamW`ï¼Œå¹¶ä½¿ç”¨æä¾›çš„å€¼æˆ–é»˜è®¤å€¼è®¾ç½®ä»¥ä¸‹å‘½ä»¤è¡Œå‚æ•°: `--learning_rate`ã€`--adam_beta1`ã€`--adam_beta2`ã€`--adam_epsilon` å’Œ `--weight_decay`ã€‚

ä»¥ä¸‹æ˜¯è‡ªåŠ¨é…ç½®çš„ `AdamW` çš„ç¤ºä¾‹:

```json
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": "auto",
         "betas": "auto",
         "eps": "auto",
         "weight_decay": "auto"
       }
   }
}
```

è¯·æ³¨æ„ï¼Œ[`Trainer`] å‚æ•°å°†è®¾ç½®é…ç½®æ–‡ä»¶ä¸­çš„å€¼ã€‚è¿™æ ·å°±æœ‰äº†ä¸€ä¸ªå®šä¹‰å€¼çš„å”¯ä¸€æ¥æºï¼Œå¹¶ä¸”é¿å…äº†ä¾‹å¦‚åœ¨ä¸åŒä½ç½®è®¾ç½®å­¦ä¹ ç‡ä¸ºä¸åŒå€¼æ—¶éš¾ä»¥æ‰¾åˆ°çš„é”™è¯¯ã€‚å‘½ä»¤è¡Œä¼˜å…ˆã€‚è¢«è¦†ç›–çš„å€¼ä¸ºï¼š

- `lr` çš„å€¼ä¸º `--learning_rate`
- `betas` çš„å€¼ä¸º `--adam_beta1 --adam_beta2`
- `eps` çš„å€¼ä¸º `--adam_epsilon`
- `weight_decay` çš„å€¼ä¸º `--weight_decay`

å› æ­¤ï¼Œè¯·è®°ä½åœ¨å‘½ä»¤è¡Œä¸Šè°ƒæ•´å…±äº«è¶…å‚æ•°ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼è®¾ç½®è¿™äº›å€¼ï¼š

```json
{
   "optimizer": {
       "type": "AdamW",
       "params": {
         "lr": 0.001,
         "betas": [0.8, 0.999],
         "eps": 1e-8,
         "weight_decay": 3e-7
       }
   }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥ [`Trainer`] å‘½ä»¤è¡Œå‚æ•°å’Œ DeepSpeed é…ç½®æ–‡ä»¶ã€‚

å¦‚æœè¦ä½¿ç”¨å…¶ä»–æœªåˆ—å‡ºçš„ä¼˜åŒ–å™¨ï¼Œåˆ™å¿…é¡»å°†å®ƒä»¬æ·»åŠ åˆ°é¡¶çº§é…ç½®ä¸­ï¼š

```json
{
   "zero_allow_untested_optimizer": true
}
```

ç±»ä¼¼äº `AdamW`ï¼Œæ‚¨å¯ä»¥é…ç½®å…¶ä»–å®˜æ–¹æ”¯æŒçš„ä¼˜åŒ–å™¨ã€‚åªéœ€è®°ä½è¿™äº›ä¼˜åŒ–å™¨å¯èƒ½å…·æœ‰ä¸åŒçš„é…ç½®å€¼ã€‚ä¾‹å¦‚ï¼Œå¯¹äº Adamï¼Œæ‚¨å¯èƒ½å¸Œæœ› `weight_decay` åœ¨ `0.01` é™„è¿‘ã€‚

å¦å¤–ï¼Œå½“ä¸å¸è½½ä¸€èµ·ä½¿ç”¨æ—¶ï¼Œä½¿ç”¨ Deepspeed çš„ CPU Adam ä¼˜åŒ–å™¨æ•ˆæœæœ€å¥½ã€‚å¦‚æœæƒ³è¦ä½¿ç”¨å…¶ä»–çš„å¸è½½å™¨ï¼Œä¾‹å¦‚ `deepspeed==0.8.3` æ—¶ï¼Œè¿˜éœ€è¦æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```json
{
   "zero_force_ds_cpu_optimizer": false
}
```

#### è°ƒåº¦å™¨

DeepSpeed æ”¯æŒ `LRRangeTest`ã€`OneCycle`ã€`WarmupLR` å’Œ `WarmupDecayLR` å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚å®Œæ•´æ–‡æ¡£åœ¨[è¿™é‡Œ](https://www.deepspeed.ai/docs/config-json/#scheduler-parameters)ã€‚

ä»¥ä¸‹æ˜¯ DeepSpeed å’Œ ğŸ¤— Transformers ä¹‹é—´è°ƒåº¦å™¨çš„é‡å éƒ¨åˆ†ï¼š

- `WarmupLR` é€šè¿‡ `--lr_scheduler_type constant_with_warmup`ã€‚
- `WarmupDecayLR` é€šè¿‡ `--lr_scheduler_type linear`ã€‚è¿™ä¹Ÿæ˜¯ `--lr_scheduler_type` çš„é»˜è®¤å€¼ï¼Œå› æ­¤ï¼Œå¦‚æœä¸é…ç½®è°ƒåº¦å™¨ï¼Œè¿™æ˜¯é»˜è®¤çš„é…ç½®ã€‚

å¦‚æœä¸åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½® `scheduler` æ¡ç›®ï¼Œåˆ™ [`Trainer`] å°†ä½¿ç”¨ `--lr_scheduler_type`ã€`--learning_rate` å’Œ `--warmup_steps` æˆ– `--warmup_ratio` çš„å€¼é…ç½® ğŸ¤— Transformers ç‰ˆæœ¬ã€‚

ä»¥ä¸‹æ˜¯è‡ªåŠ¨é…ç½®çš„ `WarmupLR` çš„ç¤ºä¾‹:

```json
{
   "scheduler": {
         "type": "WarmupLR",
         "params": {
             "warmup_min_lr": "auto",
             "warmup_max_lr": "auto",
             "warmup_num_steps": "auto"
         }
     }
}
```

ç”±äºä½¿ç”¨äº† "auto"ï¼Œ[`Trainer`] å‚æ•°å°†åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„å€¼ã€‚è¿™æ ·å°±æœ‰äº†ä¸€ä¸ªå®šä¹‰å€¼çš„å”¯ä¸€æ¥æºï¼Œå¹¶ä¸”é¿å…äº†ä¾‹å¦‚åœ¨ä¸åŒä½ç½®è®¾ç½®å­¦ä¹ ç‡ä¸ºä¸åŒå€¼æ—¶éš¾ä»¥æ‰¾åˆ°çš„é”™è¯¯ã€‚å‘½ä»¤è¡Œä¼˜å…ˆã€‚è®¾ç½®çš„å€¼ä¸ºï¼š

- `warmup_min_lr` çš„å€¼ä¸º `0`ã€‚
- `warmup_max_lr` çš„å€¼ä¸º `--learning_rate`ã€‚
- `warmup_num_steps` çš„å€¼ä¸ºå¦‚æœæä¾›äº† `--warmup_steps`ï¼Œåˆ™ä½¿ç”¨è¯¥å€¼ã€‚å¦åˆ™ï¼Œå°†ä½¿ç”¨ `--warmup_ratio` ä¹˜ä»¥è®­ç»ƒæ­¥éª¤çš„æ•°é‡ï¼Œå¹¶å‘ä¸Šå–æ•´ã€‚
- `total_num_steps` çš„å€¼ä¸º `--max_steps` çš„å€¼ï¼Œå¦åˆ™åœ¨è¿è¡Œæ—¶æ ¹æ®ç¯å¢ƒã€æ•°æ®é›†çš„å¤§å°å’Œå…¶ä»–å‘½ä»¤è¡Œå‚æ•°è‡ªåŠ¨æ¨å¯¼å‡ºæ¥ï¼ˆ`WarmupDecayLR` éœ€è¦ï¼‰ã€‚

å½“ç„¶ï¼Œæ‚¨å¯ä»¥æ¥ç®¡é…ç½®å€¼ä¸­çš„ä»»ä½•ä¸€ä¸ªæˆ–å¤šä¸ªï¼Œå¹¶è‡ªè¡Œè®¾ç½®ï¼š

```json
{
   "scheduler": {
         "type": "WarmupLR",
         "params": {
             "warmup_min_lr": 0,
             "warmup_max_lr": 0.001,
             "warmup_num_steps": 1000
         }
     }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥ [`Trainer`] å‘½ä»¤è¡Œå‚æ•°å’Œ DeepSpeed é…ç½®ã€‚

ä¾‹å¦‚ï¼Œå¯¹äº `WarmupDecayLR`ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ¡ç›®:

```json
{
   "scheduler": {
         "type": "WarmupDecayLR",
         "params": {
             "last_batch_iteration": -1,
             "total_num_steps": "auto",
             "warmup_min_lr": "auto",
             "warmup_max_lr": "auto",
             "warmup_num_steps": "auto"
         }
     }
}
```

å®ƒå°†åœ¨åŠ è½½æ—¶è®¾ç½® `total_num_steps`ã€`warmup_max_lr`ã€`warmup_num_steps` å’Œ `total_num_steps`ã€‚

### fp32 ç²¾åº¦

Deepspeed æ”¯æŒå®Œå…¨çš„ fp32 å’Œ fp16 æ··åˆç²¾åº¦ã€‚

ç”±äº fp16 æ··åˆç²¾åº¦éœ€è¦çš„å†…å­˜æ›´å°‘ï¼Œé€Ÿåº¦æ›´å¿«ï¼Œæ‰€ä»¥æ‚¨å”¯ä¸€ä¸å¸Œæœ›ä½¿ç”¨çš„æƒ…å†µæ˜¯å½“æ‚¨ä½¿ç”¨çš„æ¨¡å‹åœ¨æ­¤è®­ç»ƒæ¨¡å¼ä¸‹è¡¨ç°ä¸ä½³æ—¶ã€‚é€šå¸¸ï¼Œå½“æ¨¡å‹æ²¡æœ‰åœ¨ fp16 æ··åˆç²¾åº¦ä¸‹è¿›è¡Œé¢„è®­ç»ƒæ—¶ï¼Œå°±ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼ˆä¾‹å¦‚ï¼Œbf16 é¢„è®­ç»ƒæ¨¡å‹é€šå¸¸ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼‰ã€‚è¿™æ ·çš„æ¨¡å‹å¯èƒ½ä¼šæº¢å‡ºæˆ–ä¸‹æº¢ï¼Œå¯¼è‡´æŸå¤±ä¸º `NaN`ã€‚å¦‚æœæ˜¯è¿™ç§æƒ…å†µï¼Œæ‚¨å°†å¸Œæœ›ä½¿ç”¨å®Œå…¨çš„ fp32 æ¨¡å¼ï¼Œå¹¶é€šè¿‡æ˜¾å¼ç¦ç”¨é»˜è®¤çš„ fp16 æ··åˆç²¾åº¦æ¨¡å¼æ¥ç¦ç”¨å®ƒ:

```json
{
    "fp16": {
        "enabled": false,
    }
}
```

å¦‚æœä½¿ç”¨ Ampere æ¶æ„çš„ GPUï¼Œä» pytorch 1.7 ç‰ˆæœ¬å¼€å§‹ï¼Œé»˜è®¤æƒ…å†µä¸‹ä¼šè‡ªåŠ¨åˆ‡æ¢ä¸ºä½¿ç”¨æ›´é«˜æ•ˆçš„ tf32 æ ¼å¼è¿›è¡ŒæŸäº›æ“ä½œï¼Œä½†ç»“æœä»ç„¶æ˜¯ fp32ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯å’ŒåŸºå‡†æµ‹è¯•ï¼Œè¯·å‚è§[TensorFloat-32(TF32) on Ampere devices](https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)ã€‚æ–‡æ¡£ä¸­åŒ…å«æœ‰å…³å¦‚ä½•ç¦ç”¨æ­¤è‡ªåŠ¨è½¬æ¢çš„è¯´æ˜ï¼Œå¦‚æœå‡ºäºæŸç§åŸå› ä½ ä¸æƒ³ä½¿ç”¨å®ƒã€‚

ä½¿ç”¨ ğŸ¤— Trainerï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ `--tf32` å¯ç”¨å®ƒï¼Œæˆ–ä½¿ç”¨ `--tf32 0` æˆ– `--no_tf32` ç¦ç”¨å®ƒã€‚é»˜è®¤æƒ…å†µä¸‹ï¼ŒPyTorch ä½¿ç”¨é»˜è®¤å€¼ã€‚

```json
{
    "bf16": {
        "enabled": "auto"
    }
}
```

bf16 çš„åŠ¨æ€èŒƒå›´ä¸ fp32 ç›¸åŒï¼Œå› æ­¤ä¸éœ€è¦æœ‰æŸå¤±åŒºã€‚

å½“ä½¿ç”¨ `--bf16` æˆ– `--bf16_full_eval` å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œå¯ç”¨æ­¤æ¨¡å¼ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼å¯ç”¨/ç¦ç”¨æ­¤æ¨¡å¼ï¼š

```json
{
    "bf16": {
        "enabled": true
    }
}
```

æç¤º:

æˆªè‡³ `deepspeed==0.6.0`ï¼Œbf16 æ”¯æŒæ˜¯æ–°çš„å’Œå®éªŒæ€§çš„ã€‚

å¦‚æœæ‚¨åœ¨è®­ç»ƒæ—¶ä½¿ç”¨[æ¢¯åº¦ç´¯ç§¯](#gradient-accumulation)ï¼Œå¹¶å¯ç”¨äº† bf16ï¼Œæ‚¨éœ€è¦æ³¨æ„ï¼Œå®ƒå°†ä»¥ bf16 ç´¯ç§¯æ¢¯åº¦ï¼Œè¿™å¯èƒ½ä¸æ˜¯æ‚¨æƒ³è¦çš„ï¼Œå› ä¸ºæ­¤æ ¼å¼çš„ç²¾åº¦è¾ƒä½ï¼Œå¯èƒ½ä¼šå¯¼è‡´æœ‰æŸç´¯ç§¯ã€‚

æ­£åœ¨åŠªåŠ›è§£å†³æ­¤é—®é¢˜ï¼Œå¹¶æä¾›ä¸€ä¸ªé€‰é¡¹æ¥ä½¿ç”¨æ›´é«˜ç²¾åº¦çš„ `dtype`ï¼ˆfp16 æˆ– fp32ï¼‰ã€‚

### NCCL é›†åˆ

æœ‰ä¸€ä¸ª `dtype` æ˜¯è®­ç»ƒåˆ¶åº¦ï¼Œè¿˜æœ‰ä¸€ä¸ªå•ç‹¬çš„ `dtype` ç”¨äºé€šä¿¡é›†åˆï¼Œå¦‚å„ç§ç¼©å‡å’Œæ”¶é›†/åˆ†æ•£æ“ä½œã€‚

æ‰€æœ‰æ”¶é›†/åˆ†æ•£æ“ä½œéƒ½ä½¿ç”¨ä¸æ•°æ®ç›¸åŒçš„ `dtype`ï¼Œå› æ­¤ï¼Œå¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨ bf16 è®­ç»ƒåˆ¶åº¦ï¼Œåˆ™ä»¥ bf16 è¿›è¡Œæ”¶é›†ã€‚æ”¶é›†æ˜¯ä¸€ä¸ªéæŸå¤±æ“ä½œã€‚

å„ç§ç¼©å‡æ“ä½œå¯èƒ½ä¼šéå¸¸æœ‰æŸï¼Œä¾‹å¦‚å½“æ¢¯åº¦åœ¨å¤šä¸ª GPU ä¸Šè¿›è¡Œå¹³å‡æ—¶ï¼Œå¦‚æœé€šä¿¡æ˜¯åœ¨ fp16 æˆ– bf16 ä¸Šæ‰§è¡Œçš„ï¼Œåˆ™ç»“æœå¾ˆå¯èƒ½ä¼šæœ‰æŸ-å› ä¸ºåœ¨ä½ç²¾åº¦ä¸‹æ·»åŠ å¤šä¸ªæ•°å­—æ—¶ï¼Œç»“æœä¸æ˜¯ç²¾ç¡®çš„ã€‚ç‰¹åˆ«æ˜¯åœ¨ä½¿ç”¨ bf16 æ—¶æ›´åŠ å¦‚æ­¤ï¼Œå› ä¸ºå®ƒçš„ç²¾åº¦ä½äº fp16ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œfp16 å·²ç»è¶³å¤Ÿå¥½ï¼Œå› ä¸ºå¹³å‡æ¢¯åº¦é€šå¸¸éå¸¸å°ã€‚å› æ­¤ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œåœ¨åŠç²¾åº¦è®­ç»ƒä¸­ä½¿ç”¨ fp16 ä½œä¸ºç¼©å‡æ“ä½œçš„é»˜è®¤å€¼ã€‚ä½†æ˜¯ï¼Œæ‚¨å¯¹æ­¤åŠŸèƒ½æœ‰å®Œå…¨çš„æ§åˆ¶ï¼Œå¹¶ä¸”å¦‚æœé€‰æ‹©ï¼Œå¯ä»¥æ·»åŠ ä¸€äº›é¢å¤–çš„å¼€é”€ï¼Œå¹¶ç¡®ä¿åœ¨ç´¯è®¡å®Œæˆåå°†å…¶ç´¯ç§¯åˆ°åŠç²¾åº¦ `dtype` ä¸­ï¼Œç›´åˆ°ç»“æœå‡†å¤‡å¥½åæ‰é™çº§åˆ°æ‚¨æ­£åœ¨è®­ç»ƒçš„åŠç²¾åº¦â€œdtypeâ€ã€‚

ä¸ºäº†è¦†ç›–é»˜è®¤å€¼ï¼Œæ‚¨åªéœ€æ·»åŠ ä¸€ä¸ªæ–°çš„é…ç½®æ¡ç›®ï¼š

```json
{
    "communication_data_type": "fp32"
}
```

æˆªè‡³æ’°å†™æœ¬æ–‡æ—¶ï¼Œæœ‰æ•ˆå€¼æ˜¯ "fp16"ã€"bfp16" å’Œ "fp32"ã€‚

æ³¨æ„ï¼šstage zero 3 ä¸­æœ‰ä¸€ä¸ªä¸ bf16 comm dtype ç›¸å…³çš„é”™è¯¯ï¼Œåœ¨ `deepspeed==0.8.1` ä¸­å·²ç»ä¿®å¤ã€‚

### è‡ªåŠ¨æ··åˆç²¾åº¦

æ‚¨å¯ä»¥ä½¿ç”¨ pytorch-like AMP æ–¹æ³•æˆ– apex-like æ–¹æ³•æ¥ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼š

### fp16

è¦é…ç½®å¸¦æœ‰ fp16ï¼ˆfloat16ï¼‰çš„ pytorch-like AMP æ¨¡å¼ï¼Œè¯·è®¾ç½®ï¼š

```json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

[`Trainer`] å°†æ ¹æ® `args.fp16_backend` çš„å€¼å’Œ `args.fp16_opt_level` çš„å€¼è‡ªåŠ¨å¯ç”¨æˆ–ç¦ç”¨æ­¤æ¨¡å¼ã€‚

å½“ä¼ é€’ `--fp16 --fp16_backend amp --fp16_opt_level 01` å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œå°†å¯ç”¨æ­¤æ¨¡å¼ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼é…ç½®æ­¤æ¨¡å¼ï¼š

```json
{
    "fp16": {
        "enabled": true,
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

ä½†æ˜¯ï¼Œæ‚¨éœ€è¦è‡ªå·±åŒæ­¥ [`Trainer`] çš„å‘½ä»¤è¡Œå‚æ•°å’Œ DeepSpeed çš„é…ç½®æ–‡ä»¶ã€‚

åœ¨[è¿™é‡Œ](https://www.deepspeed.ai/docs/config-json/#fp16-training-options)è¿›è¡Œäº†æ›´è¯¦ç»†çš„è¯´æ˜ã€‚

### bf16

å¦‚æœå¸Œæœ›ä½¿ç”¨ bf16ï¼ˆbfloat16ï¼‰è€Œä¸æ˜¯ fp16ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ä»¥ä¸‹é…ç½®éƒ¨åˆ†ï¼š

```json
{
    "bf16": {
        "enabled": "auto"
    }
}
```

bf16 ä¸ fp32 å…·æœ‰ç›¸åŒçš„åŠ¨æ€èŒƒå›´ï¼Œå› æ­¤ä¸éœ€è¦æœ‰æŸè¡¥ã€‚

å½“ä¼ é€’ `--bf16` æˆ– `--bf16_full_eval` å‘½ä»¤è¡Œå‚æ•°æ—¶ï¼Œå¯ç”¨æ­¤æ¨¡å¼ã€‚

æ‚¨è¿˜å¯ä»¥æ˜¾å¼å¯ç”¨/ç¦ç”¨æ­¤æ¨¡å¼ï¼š

```json
{
    "bf16": {
        "enabled": true
    }
}
```

æç¤ºï¼š

æˆªè‡³ `deepspeed==0.6.0`ï¼Œbf16 æ”¯æŒæ˜¯æ–°çš„å’Œå®éªŒæ€§çš„ã€‚

å¦‚æœæ‚¨åœ¨è®­ç»ƒæ—¶ä½¿ç”¨[æ¢¯åº¦ç´¯ç§¯](#gradient-accumulation)ï¼Œå¹¶å¯ç”¨äº† bf16ï¼Œæ‚¨éœ€è¦æ³¨æ„ï¼Œå®ƒå°†ä»¥ bf16 ç´¯ç§¯æ¢¯åº¦ï¼Œè¿™å¯èƒ½ä¸æ˜¯æ‚¨æƒ³è¦çš„ï¼Œå› ä¸ºæ­¤æ ¼å¼çš„ç²¾åº¦è¾ƒä½ï¼Œå¯èƒ½ä¼šå¯¼è‡´æœ‰æŸç´¯ç§¯ã€‚

æ­£åœ¨åŠªåŠ›è§£å†³æ­¤é—®é¢˜ï¼Œå¹¶æä¾›ä¸€ä¸ªé€‰é¡¹æ¥ä½¿ç”¨æ›´é«˜ç²¾åº¦çš„ `dtype`ï¼ˆfp16 æˆ– fp32ï¼‰ã€‚

### NCCL é›†åˆ

æœ‰ä¸€ä¸ª `dtype` æ˜¯è®­ç»ƒåˆ¶åº¦ï¼Œè¿˜æœ‰ä¸€ä¸ªå•ç‹¬çš„ `dtype` ç”¨äºé€šä¿¡é›†åˆï¼Œå¦‚å„ç§ç¼©å‡å’Œæ”¶é›†/åˆ†æ•£æ“ä½œã€‚

æ‰€æœ‰æ”¶é›†/åˆ†æ•£æ“ä½œéƒ½ä½¿ç”¨ä¸æ•°æ®ç›¸åŒçš„ `dtype`ï¼Œå› æ­¤ï¼Œå¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨ bf16 è®­ç»ƒåˆ¶åº¦ï¼Œåˆ™ä»¥ bf16 è¿›è¡Œæ”¶é›†-æ”¶é›†æ˜¯ä¸€ä¸ªéæŸå¤±æ“ä½œã€‚

å„ç§ç¼©å‡æ“ä½œå¯èƒ½ä¼šéå¸¸æœ‰æŸï¼Œä¾‹å¦‚å½“æ¢¯åº¦åœ¨å¤šä¸ª GPU ä¸Šè¿›è¡Œå¹³å‡æ—¶ï¼Œå¦‚æœé€šä¿¡æ˜¯åœ¨ fp16 æˆ– bf16 ä¸Šæ‰§è¡Œçš„ï¼Œåˆ™ç»“æœå¾ˆå¯èƒ½ä¼šæœ‰æŸã€‚å› ä¸ºå½“ä»¥ä½ç²¾åº¦ç›¸åŠ å¤šä¸ªæ•°å­—æ—¶ï¼Œç»“æœä¸æ˜¯ç²¾ç¡®çš„ã€‚æ›´é‡è¦çš„æ˜¯åœ¨ä½¿ç”¨ bf16 æ—¶ã€‚å› ä¸º bf16 çš„ç²¾åº¦ä½äº fp16ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œfp16 å·²ç»è¶³å¤Ÿå¥½ï¼Œå› ä¸ºå¹³å±€æ¢¯åº¦é€šå¸¸éå¸¸å°ã€‚å› æ­¤ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼ŒåŠç²¾åº¦è®­ç»ƒä½¿ç”¨ fp16 ä½œä¸ºç¼©å‡æ“ä½œçš„é»˜è®¤è®¾ç½®ã€‚<button>ä½†æ˜¯æ‚¨å¯¹æ­¤åŠŸèƒ½æœ‰å®Œå…¨çš„æ§åˆ¶ï¼Œå¹¶ä¸”å¦‚æœæ‚¨é€‰æ‹©ï¼Œæ‚¨å¯ä»¥æ·»åŠ ä¸€äº›é¢å¤–çš„å¼€é”€å¹¶ç¡®ä¿åœ¨ç´¯ç§¯å®Œæˆåå°†å…¶ç´¯ç§¯åˆ°æ‚¨æ­£åœ¨è®­ç»ƒçš„åŠç²¾åº¦â€œdtypeâ€ã€‚``

è¦è¦†ç›–é»˜è®¤å€¼ï¼Œåªéœ€æ·»åŠ ä¸€ä¸ªæ–°çš„é…ç½®æ¡ç›®ï¼š

```json
{
    "communication_data_type": "fp32"
}
```

åœ¨æ’°å†™æœ¬æ–‡æ—¶ï¼Œæœ‰æ•ˆå€¼ä¸º "fp16"ã€"bfp16" å’Œ "fp32"ã€‚

æ³¨æ„:è‡ª`deepspeed==0.8.1` ä»¥æ¥ä¿®å¤äº† bf16 comm dtype çš„é”™è¯¯ã€‚



```bash
$ python -c 'from transformers import AutoModel; \
from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \
model = AutoModel.from_pretrained("bigscience/T0_3B"); \
estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=2, num_nodes=1)'
[...]
Estimated memory needed for params, optim states and gradients for a:
HW: Setup with 1 node, 2 GPUs per node.
SW: Model with 2783M total params, 65M largest layer params.
  per CPU  |  per GPU |   Options
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
   76.74GB |   2.71GB | offload_param=none, offload_optimizer=cpu , zero_init=1
   76.74GB |   2.71GB | offload_param=none, offload_optimizer=cpu , zero_init=0
   52.29GB |  43.46GB | offload_param=none, offload_optimizer=none, zero_init=1
  133.57GB |  43.46GB | offload_param=none, offload_optimizer=none, zero_init=0
```

You can see with 2 GPUs, you need around 2.7GB for each GPU. That increases to around 43.5GB when offloading to GPUs and no CPU offload is performed.

Again, this is just an estimate and you should experiment with different settings to find the best tradeoff between cost and speed for your specific use case.

```bash
$ python -c 'from transformers import AutoModel; \
from deepspeed.runtime.zero.stage3 import estimate_zero3_model_states_mem_needs_all_live; \
model = AutoModel.from_pretrained("bigscience/T0_3B"); \
estimate_zero3_model_states_mem_needs_all_live(model, num_gpus_per_node=2, num_nodes=1)'
[...]
ä¼°è®¡ä¸ºparamsã€optimçŠ¶æ€å’Œgradientséœ€è¦å†…å­˜çš„å‚æ•°ï¼š
HW:è®¾ç½®ä¸º1ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹2ä¸ªGPUã€‚
SW:æ¨¡å‹æ€»å‚æ•°æ•°ä¸º2783Mï¼Œæœ€å¤§å±‚å‚æ•°ä¸º65Mã€‚
  per CPU  |  per GPU |   Options
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=1
   70.00GB |   0.25GB | offload_param=cpu , offload_optimizer=cpu , zero_init=0
   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=1
   62.23GB |   2.84GB | offload_param=none, offload_optimizer=cpu , zero_init=0
    0.74GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=1
   31.11GB |  23.58GB | offload_param=none, offload_optimizer=none, zero_init=0
```

å› æ­¤ï¼Œæ‚¨éœ€è¦ä½¿ç”¨2ä¸ª32GBæˆ–æ›´é«˜çš„GPUæ¥è¿è¡Œæ­¤æ¨¡å‹ï¼Œä¸”ä¸è¿›è¡ŒCPUå¸è½½ã€‚

æœ‰å…³å®Œæ•´ä¿¡æ¯ï¼Œè¯·å‚é˜…[memory estimators](https://deepspeed.readthedocs.io/en/latest/memory.html)ã€‚

### æäº¤é—®é¢˜

åœ¨æŠ¥å‘Šä¸­ï¼Œè¯·å§‹ç»ˆåŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š

1. å®Œæ•´çš„Deepspeedé…ç½®æ–‡ä»¶
2. å¦‚æœæ‚¨ä½¿ç”¨[`Trainer`]ï¼Œè¯·åŒ…æ‹¬å‘½ä»¤è¡Œå‚æ•°ï¼›å¦‚æœæ‚¨ä½¿ç”¨[`TrainingArguments`]è‡ªå·±è¿›è¡ŒTrainerè®¾ç½®ï¼Œè¯·ä¸è¦åŒ…æ‹¬[`TrainingArguments`]çš„dumpï¼Œå› ä¸ºå…¶ä¸­æœ‰æ•°åä¸ªä¸é—®é¢˜æ— å…³çš„æ¡ç›®ã€‚
3. è¿è¡Œä»¥ä¸‹å‘½ä»¤åçš„è¾“å‡ºï¼š
```bash
python -c 'import torch; print(f"torch: {torch.__version__}")'
python -c 'import transformers; print(f"transformers: {transformers.__version__}")'
python -c 'import deepspeed; print(f"deepspeed: {deepspeed.__version__}")'
```
4. å¦‚æœå¯èƒ½ï¼Œæä¾›ä¸€ä¸ªå¯ä»¥åœ¨å…¶ä¸Šé‡ç°è¯¥é—®é¢˜çš„Google Colabç¬”è®°æœ¬çš„é“¾æ¥ã€‚
5. é™¤éæ— æ³•ï¼Œå¦åˆ™è¯·å§‹ç»ˆä½¿ç”¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„æ ‡å‡†æ•°æ®é›†è€Œä¸æ˜¯è‡ªå®šä¹‰æ•°æ®é›†ã€‚

6. å¦‚æœå¯èƒ½ï¼Œè¯·å°è¯•ä½¿ç”¨ç°æœ‰çš„[ç¤ºä¾‹](https://github.com/huggingface/transformers/tree/main/examples/pytorch)ä¹‹ä¸€é‡ç°è¯¥é—®é¢˜ã€‚

éœ€è¦è€ƒè™‘çš„é—®é¢˜ï¼š

- Deepspeedå¾€å¾€ä¸æ˜¯é—®é¢˜çš„åŸå› ã€‚

  ä¸€äº›å·²å½’æ¡£çš„é—®é¢˜è¯æ˜ä¸Deepspeedæ— å…³ã€‚å³ï¼Œä¸€æ—¦å°†Deepspeedä»è®¾ç½®ä¸­åˆ é™¤ï¼Œé—®é¢˜ä»ç„¶å­˜åœ¨ã€‚

  å› æ­¤ï¼Œå¦‚æœä¸æ˜¯ç»å¯¹æ˜æ˜¾æ˜¯Deepspeedç›¸å…³çš„é—®é¢˜ï¼Œå³æ‚¨å¯ä»¥çœ‹åˆ°å­˜åœ¨å¼‚å¸¸å’ŒDeepSpeedæ¨¡å—æ¶‰åŠåˆ°çš„é—®é¢˜ï¼Œè¯·é¦–å…ˆåœ¨æ²¡æœ‰Deepspeedçš„è®¾ç½®ä¸­é‡æ–°æµ‹è¯•æ‚¨çš„è®¾ç½®ã€‚åªæœ‰åœ¨é—®é¢˜ä»ç„¶å­˜åœ¨çš„æƒ…å†µä¸‹æ‰æåˆ°Deepspeedå¹¶æä¾›æ‰€æœ‰æ‰€éœ€çš„è¯¦ç»†ä¿¡æ¯ã€‚

- å¦‚æœæ‚¨ç¡®å®šé—®é¢˜æ˜¯DeepSpeedæ ¸å¿ƒä¸­çš„é—®é¢˜è€Œä¸æ˜¯é›†æˆéƒ¨åˆ†ï¼Œè¯·ç›´æ¥åœ¨[Deepspeed](https://github.com/microsoft/DeepSpeed/)ä¸Šæäº¤Issueã€‚å¦‚æœæ‚¨ä¸ç¡®å®šï¼Œè¯·ä¸è¦æ‹…å¿ƒï¼Œä»»ä½•ä¸€ä¸ªIssueè·Ÿè¸ªå™¨éƒ½å¯ä»¥ï¼Œä¸€æ—¦æ‚¨å‘å¸ƒé—®é¢˜ï¼Œæˆ‘ä»¬å°†æ‰¾åˆ°è§£å†³æ–¹æ³•å¹¶å°†æ‚¨é‡å®šå‘åˆ°å¦ä¸€ä¸ªIssueè·Ÿè¸ªå™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰ã€‚

### æ•…éšœæ’é™¤

#### åœ¨å¯åŠ¨æ—¶ï¼Œ`deepspeed`è¿›ç¨‹æ— å›æº¯åœ°è¢«æ€æ­»

å¦‚æœ`deepspeed`è¿›ç¨‹åœ¨å¯åŠ¨æ—¶è¢«æ— å›æº¯åœ°æ€æ­»ï¼Œè¿™é€šå¸¸æ„å‘³ç€ç¨‹åºå°è¯•åˆ†é…çš„CPUå†…å­˜è¶…è¿‡äº†ç³»ç»Ÿæˆ–è¿›ç¨‹å…è®¸åˆ†é…çš„CPUå†…å­˜ï¼Œå› æ­¤æ“ä½œç³»ç»Ÿå†…æ ¸æ€æ­»äº†è¯¥è¿›ç¨‹ã€‚è¿™æ˜¯å› ä¸ºæ‚¨çš„é…ç½®æ–‡ä»¶å¾ˆå¯èƒ½åŒæ—¶é…ç½®äº†`offload_optimizer`å’Œ`offload_param`å°†å…¶è½¬ç§»åˆ°äº†`cpu`ã€‚å¦‚æœæ‚¨æœ‰NVMeï¼Œå¦‚æœåœ¨ZeRO-3ä¸‹è¿è¡Œï¼Œå¯ä»¥å°è¯•å°†å…¶åˆ†æµåˆ°NVMeã€‚å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ¥[ä¼°è®¡ä¸ºç‰¹å®šæ¨¡å‹éœ€è¦å¤šå°‘å†…å­˜](https://deepspeed.readthedocs.io/en/latest/memory.html)ã€‚

#### è®­ç»ƒå’Œ/æˆ–è¯„ä¼°/é¢„æµ‹æŸå¤±ä¸ºNaN

åœ¨å°†ä»¥bf16æ··åˆç²¾åº¦æ¨¡å¼é¢„è®­ç»ƒçš„æ¨¡å‹ç”¨äºä¸å¸¦æ··åˆç²¾åº¦çš„fp16ä¸‹æ—¶ï¼Œç»å¸¸ä¼šå‘ç”ŸæŸå¤±ä¸ºNaNçš„æƒ…å†µã€‚å¤§å¤šæ•°åŸºäºTPUå¹¶ä¸”é€šå¸¸æ˜¯è°·æ­Œå‘å¸ƒçš„æ¨¡å‹éƒ½å±äºæ­¤ç±»åˆ«ï¼ˆä¾‹å¦‚ï¼Œå‡ ä¹æ‰€æœ‰åŸºäºt5çš„æ¨¡å‹ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè§£å†³æ–¹æ¡ˆæ˜¯è¦ä¹ˆä½¿ç”¨fp32ï¼Œè¦ä¹ˆä½¿ç”¨å¦‚æœæ‚¨çš„ç¡¬ä»¶æ”¯æŒï¼ˆTPUã€Ampere GPUæˆ–æ›´æ–°ç‰ˆæœ¬ï¼‰æ—¶ä½¿ç”¨bf16ã€‚

å¦ä¸€ä¸ªé—®é¢˜å¯èƒ½ä¸ä½¿ç”¨fp16æœ‰å…³ã€‚å½“é…ç½®ä»¥ä¸‹éƒ¨åˆ†æ—¶ï¼š

```json
{
    "fp16": {
        "enabled": "auto",
        "loss_scale": 0,
        "loss_scale_window": 1000,
        "initial_scale_power": 16,
        "hysteresis": 2,
        "min_loss_scale": 1
    }
}
```

å¹¶ä¸”æ‚¨åœ¨æ—¥å¿—ä¸­çœ‹åˆ°DeepspeedæŠ¥å‘Šå¦‚ä¸‹`OVERFLOW!`çš„æƒ…å†µï¼š

```
0%|                                                                                                                             | 0/189 [00:00<?, ?it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 262144
  1%|â–Œ                                                                                                                    | 1/189 [00:00<01:26,  2.17it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 262144, reducing to 131072.0
  1%|â–ˆâ–
 [...]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                                   | 27/189 [00:14<01:13,  2.21it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                  | 28/189 [00:14<01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
 15%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                  | 29/189 [00:15<01:13,  2.18it/s]
 [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1, reducing to 1
[...]
```

è¿™æ„å‘³ç€DeepspeedæŸå¤±ç¼©æ”¾å™¨æ— æ³•æ‰¾åˆ°ä¸€ä¸ªå¯ä»¥å…‹æœæŸå¤±æº¢å‡ºçš„ç¼©æ”¾ç³»æ•°ã€‚

ï¼ˆæ­¤æ—¥å¿—å·²è¿›è¡Œä¼˜åŒ–ï¼Œä»¥ä¾¿æ›´æ˜“è¯»ï¼‰

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨é€šå¸¸éœ€è¦æé«˜`initial_scale_power`çš„å€¼ã€‚å°†å…¶è®¾ç½®ä¸º`"initial_scale_power": 32`é€šå¸¸å¯ä»¥è§£å†³è¯¥é—®é¢˜ã€‚

### æ³¨æ„äº‹é¡¹

- Deepspeedå¯ä»¥ä¸PyTorch [`Trainer`]ä¸€èµ·å·¥ä½œï¼Œä½†æ— æ³•ä¸TF [`TFTrainer`]ä¸€èµ·å·¥ä½œã€‚
- è™½ç„¶DeepSpeedæœ‰ä¸€ä¸ªå¯pipå®‰è£…çš„PyPIè½¯ä»¶åŒ…ï¼Œä½†å¼ºçƒˆå»ºè®®ä»[æºä»£ç ](https://github.com/microsoft/deepspeed#installation)è¿›è¡Œå®‰è£…ï¼Œä»¥ä¾¿æœ€å¥½åœ°åŒ¹é…æ‚¨çš„ç¡¬ä»¶ï¼Œå¹¶ä¸”å¦‚æœæ‚¨éœ€è¦å¯ç”¨æŸäº›åŠŸèƒ½ï¼ˆå¦‚1-bit Adamï¼‰ï¼Œåœ¨pypiåˆ†å‘ä¸­æ— æ³•ä½¿ç”¨ã€‚
- æ‚¨ä¸å¿…ä½¿ç”¨[`Trainer`]æ¥ä¸Deepspeedå’ŒğŸ¤— Transformersä¸€èµ·ä½¿ç”¨-æ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•æ¨¡å‹ä¸è‡ªå·±çš„è®­ç»ƒå™¨ï¼Œå¹¶ä¸”æ‚¨å°†ä¸å¾—ä¸æ ¹æ®[Deepspeedé›†æˆè¯´æ˜](https://www.deepspeed.ai/getting-started/#writing-deepspeed-models)æ¥è°ƒæ•´åè€…çš„è®¾ç½®ã€‚

## ä½¿ç”¨éTrainerçš„Deepspeedé›†æˆ

å½“ä¸ä½¿ç”¨[`Trainer`]æ—¶ï¼Œ[`~integrations.HfDeepSpeedConfig`]ç”¨äºå°†Deepspeedé›†æˆåˆ°ğŸ¤— Transformersæ ¸å¿ƒåŠŸèƒ½ä¸­ã€‚å”¯ä¸€çš„éœ€è¦æ˜¯å¤„ç†Deepspeed ZeRO-3å‚æ•°èšåˆå¹¶åœ¨`from_pretrained`è°ƒç”¨æœŸé—´è‡ªåŠ¨å°†æ¨¡å‹åˆ†å‰²åˆ°å¤šä¸ªGPUä¸Šã€‚å…¶ä»–æ‰€æœ‰æ“ä½œéƒ½éœ€è¦æ‚¨è‡ªå·±å®Œæˆã€‚

å½“ä½¿ç”¨[`Trainer`]æ—¶ï¼Œæ‰€æœ‰æ“ä½œéƒ½ä¼šè‡ªåŠ¨å¤„ç†ã€‚

å½“ä¸ä½¿ç”¨[`Trainer`]æ—¶ï¼Œä¸ºäº†æœ‰æ•ˆåœ°éƒ¨ç½²DeepSpeed ZeRO-3ï¼Œæ‚¨å¿…é¡»åœ¨å®ä¾‹åŒ–æ¨¡å‹ä¹‹å‰å®ä¾‹åŒ–[`~integrations.HfDeepSpeedConfig`]å¯¹è±¡ï¼Œå¹¶å°†è¯¥å¯¹è±¡ä¿æŒæ´»åŠ¨çŠ¶æ€ã€‚

å¦‚æœæ‚¨ä½¿ç”¨Deepspeed ZeRO-1æˆ–ZeRO-2ï¼Œåˆ™æ ¹æœ¬ä¸éœ€è¦ä½¿ç”¨`HfDeepSpeedConfig`ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºé¢„è®­ç»ƒæ¨¡å‹ï¼š

```python
from transformers.integrations import HfDeepSpeedConfig
from transformers import AutoModel
import deepspeed

ds_config = {...}  # deepspeedé…ç½®å¯¹è±¡æˆ–æ–‡ä»¶çš„è·¯å¾„
# å¿…é¡»åœ¨å®ä¾‹åŒ–æ¨¡å‹ä¹‹å‰è¿è¡Œä»¥æ£€æµ‹zero 3
dschf = HfDeepSpeedConfig(ds_config)  # ä¿æŒæ­¤å¯¹è±¡çš„æ´»åŠ¨çŠ¶æ€
model = AutoModel.from_pretrained("gpt2")
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)
```

æˆ–è€…å¯¹äºéé¢„è®­ç»ƒæ¨¡å‹ï¼š

```python
from transformers.integrations import HfDeepSpeedConfig
from transformers import AutoModel, AutoConfig
import deepspeed

ds_config = {...}  # deepspeedé…ç½®å¯¹è±¡æˆ–æ–‡ä»¶çš„è·¯å¾„
# å¿…é¡»åœ¨å®ä¾‹åŒ–æ¨¡å‹ä¹‹å‰è¿è¡Œä»¥æ£€æµ‹zero 3
dschf = HfDeepSpeedConfig(ds_config)  # ä¿æŒæ­¤å¯¹è±¡çš„æ´»åŠ¨çŠ¶æ€
config = AutoConfig.from_pretrained("gpt2")
model = AutoModel.from_config(config)
engine = deepspeed.initialize(model=model, config_params=ds_config, ...)
```

è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨ä¸ä½¿ç”¨[`Trainer`]é›†æˆï¼Œåˆ™å®Œå…¨ç”±æ‚¨è‡ªå·±è´Ÿè´£ã€‚åŸºæœ¬ä¸ŠæŒ‰ç…§[Deepspeed](https://www.deepspeed.ai/)ç½‘ç«™ä¸Šçš„æ–‡æ¡£æ“ä½œã€‚æ­¤å¤–ï¼Œå¿…é¡»æ˜¾å¼é…ç½®é…ç½®æ–‡ä»¶-æ— æ³•ä½¿ç”¨`"auto"`å€¼ï¼Œå¿…é¡»ä½¿ç”¨å®é™…å€¼ã€‚

## HfDeepSpeedConfig

[[autodoc]] integrations.HfDeepSpeedConfig
    - all

### è‡ªå®šä¹‰Deepspeed ZeROæ¨ç†

ä»¥ä¸‹ç¤ºä¾‹æ¼”ç¤ºäº†å¦‚ä½•åœ¨ä¸ä½¿ç”¨[`Trainer`]æ—¶è¿›è¡ŒDeepspeed ZeROæ¨ç†ï¼Œå½“æ— æ³•å°†æ¨¡å‹è£…å…¥å•ä¸ªGPUä¸­æ—¶ã€‚è¯¥è§£å†³æ–¹æ¡ˆåŒ…æ‹¬ä½¿ç”¨é¢å¤–çš„GPUå’Œ/æˆ–å°†GPUå†…å­˜å¸è½½åˆ°CPUå†…å­˜ä¸­ã€‚

éœ€è¦äº†è§£çš„é‡è¦ç»†å¾®ä¹‹å¤„æ˜¯ï¼ŒZeROçš„è®¾è®¡æ–¹å¼å…è®¸åœ¨æ¯ä¸ªGPUä¸Šå¹¶è¡Œå¤„ç†ä¸åŒçš„è¾“å…¥ã€‚

ç¤ºä¾‹å…·æœ‰å¤§é‡æ³¨é‡Šï¼Œå¹¶ä»¥è‡ªæˆ‘è®°å½•æ–¹å¼è¿›è¡Œäº†è¯´æ˜ã€‚

ç¡®ä¿ï¼š

1. å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼Œè¯·ç¦ç”¨CPUå¸è½½ï¼ˆå› ä¸ºä¼šå‡æ…¢å¤„ç†é€Ÿåº¦ï¼‰
2. å¦‚æœæ‚¨æ‹¥æœ‰Ampereæˆ–æ›´é«˜ç‰ˆæœ¬çš„GPUï¼Œè¯·å¯ç”¨bf16ä»¥åŠ å¿«é€Ÿåº¦ã€‚å¦‚æœæ‚¨æ²¡æœ‰è¿™æ ·çš„ç¡¬ä»¶ï¼Œåªè¦ä¸ä½¿ç”¨ä»¥bf16æ··åˆç²¾åº¦é¢„è®­ç»ƒçš„ä»»ä½•æ¨¡å‹ï¼ˆä¾‹å¦‚å¤§å¤šæ•°t5æ¨¡å‹ï¼‰ï¼Œæ‚¨å¯ä»¥å¯ç”¨fp16ã€‚è¿™äº›æ¨¡å‹é€šå¸¸åœ¨fp16ä¸­æº¢å‡ºï¼Œå¹¶æ˜¾ç¤ºåƒåœ¾è¾“å‡ºã€‚

```python
#!/usr/bin/env python

# æ­¤è„šæœ¬æ¼”ç¤ºäº†åœ¨æ— æ³•å°†æ¨¡å‹è£…å…¥å•ä¸ªGPUä¸­æ—¶å¦‚ä½•åœ¨æ¨ç†æ¨¡å¼ä¸‹ä½¿ç”¨Deepspeed ZeROã€‚
#
# 1. ä½¿ç”¨1ä¸ªå¸¦CPUå¸è½½çš„GPU
# 2. æˆ–è€…ä½¿ç”¨å¤šä¸ªGPU
#
# é¦–å…ˆæ‚¨éœ€è¦å®‰è£…deepspeedï¼špip install deepspeed
#
# è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨3B "bigscience/T0_3B"æ¨¡å‹ï¼Œå®ƒéœ€è¦å¤§çº¦15GBçš„GPU RAM-å› æ­¤å¯ä»¥ä½¿ç”¨1ä¸ªè¾ƒå¤§çš„æˆ–2ä¸ªè¾ƒå°çš„GPUæ¥å¤„ç†å®ƒã€‚æˆ–è€…ï¼Œä¸€ä¸ªå°å‹çš„GPUå’Œå¤§é‡çš„CPUå†…å­˜ã€‚
#
# è¦ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼Œæ¯”å¦‚éœ€è¦å¤§çº¦50GBçš„"bigscience/T0"ï¼Œé™¤éæ‚¨æ‹¥æœ‰ä¸€ä¸ª80GBçš„GPUï¼Œå¦åˆ™éœ€è¦ä½¿ç”¨2-4ä¸ªGPUã€‚ç„¶åæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´è¯¥è„šæœ¬ä»¥å¤„ç†æ›´å¤šçš„GPUã€‚
#
# æä¾›çš„deepspeedé…ç½®è¿˜æ¿€æ´»äº†CPUå†…å­˜å¸è½½ï¼Œå› æ­¤ï¼Œå¦‚æœæ‚¨æœ‰å¤§é‡å¯ç”¨çš„CPUå†…å­˜ï¼Œå¹¶ä¸”ä¸ä»‹æ„å‡æ…¢é€Ÿåº¦ï¼Œåº”è¯¥å¯ä»¥åŠ è½½é€šå¸¸ä¸é€‚åº”å•ä¸ªGPUçš„æ¨¡å‹ã€‚å¦‚æœæ‚¨æœ‰è¶³å¤Ÿçš„GPUå†…å­˜ï¼Œå¦‚æœæ‚¨ä¸æƒ³è¿›è¡ŒCPUå¸è½½ï¼Œé‚£ä¹ˆç¨‹åºå°†è¿è¡Œå¾—æ›´å¿«-å› æ­¤ç¦ç”¨è¯¥éƒ¨åˆ†ã€‚
#
# è¦åœ¨1ä¸ªgpuä¸Šéƒ¨ç½²ï¼š
#
# deepspeed --num_gpus 1 t0.py
# or:
# python -m torch.distributed.run --nproc_per_node=1 t0.py
#
# è¦åœ¨2ä¸ªgpuä¸Šéƒ¨ç½²ï¼š
#
# deepspeed --num_gpus 2 t0.py
# or:
# python -m torch.distributed.run --nproc_per_node=2 t0.py


from transformers import AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM
from transformers.integrations import HfDeepSpeedConfig
import deepspeed
import os
import torch

os.environ["TOKENIZERS_PARALLELISM"] = "false"  # é¿å…å…³äºtokenizerså¹¶è¡Œæ€§çš„è­¦å‘Š

# åˆ†å¸ƒå¼è®¾ç½®
local_rank = int(os.getenv("LOCAL_RANK", "0"))
world_size = int(os.getenv("WORLD_SIZE", "1"))
torch.cuda.set_device(local_rank)
deepspeed.init_distributed()

model_name = "bigscience/T0_3B"

config = AutoConfig.from_pretrained(model_name)
model_hidden_size = config.d_model

# æ‰¹å¤„ç†å¤§å°å¿…é¡»å¯è¢«world_sizeæ•´é™¤ï¼Œä½†å¯ä»¥å¤§äºworld_size
train_batch_size = 1 * world_size

# ds_config æ³¨é‡Šï¼š
#
# - å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯Ampereæˆ–æ›´é«˜ç‰ˆæœ¬çš„GPUï¼Œè¯·å¯ç”¨bf16-è¿™å°†ä»¥æ··åˆç²¾åº¦è¿è¡Œå¹¶ä¸”é€Ÿåº¦æ›´å¿«ã€‚
#
# - å¯¹äºæ—§ä¸€äº›çš„GPUï¼Œæ‚¨å¯ä»¥å¯ç”¨fp16ï¼Œä½†ä»…ä½¿ç”¨æœªç»bf16é¢„è®­ç»ƒçš„æ¨¡å‹-ä¾‹å¦‚ï¼Œæ‰€æœ‰å®˜æ–¹çš„t5æ¨¡å‹éƒ½æ˜¯ç»è¿‡bf16é¢„è®­ç»ƒçš„ã€‚
#
# - å°†offload_param.deviceè®¾ç½®ä¸º"none"æˆ–å®Œå…¨åˆ é™¤`offload_param`éƒ¨åˆ†ï¼Œå¦‚æœæ‚¨ä¸- æƒ³è¿›è¡ŒCPUå¸è½½
#
# - å¦‚æœä½¿ç”¨`offload_param`ï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨å¾®è°ƒstage3_param_persistence_thresholdä»¥æ§åˆ¶åº”ä¿ç•™åœ¨GPUä¸Šçš„å‚æ•°æ•°é‡- å€¼è¶Šå¤§ï¼Œå¸è½½çš„å°ºå¯¸è¶Šå°
#
# æœ‰å…³Deepspeedé…ç½®çš„è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§
# https://huggingface.co/docs/transformers/main/main_classes/deepspeed

# ä¸ºäº†ä¿æŒä¸.jsonçš„ä¸€è‡´æ€§ä½¿ç”¨ç›¸åŒçš„æ ¼å¼ï¼Œåªæ˜¯å®ƒåœ¨true/falseä¸Šä½¿ç”¨å°å†™
# fmt: off
ds_config = {
    "fp16": {
        "enabled": False
    },
    "bf16": {
        "enabled": False
    },
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu",
            "pin_memory": True
        },
        "overlap_comm": True,
        "contiguous_gradients": True,
        "reduce_bucket_size": model_hidden_size * model_hidden_size,
        "stage3_prefetch_bucket_size": 0.9 * model_hidden_size * model_hidden_size,
        "stage3_param_persistence_threshold": 10 * model_hidden_size
    },
    "steps_per_print": 2000,
    "train_batch_size": train_batch_size,
    "train_micro_batch_size_per_gpu": 1,
    "wall_clock_breakdown": False
}
# fmt: on

# ä¸‹ä¸€è¡ŒæŒ‡ç¤ºtransformersåœ¨è°ƒç”¨æ¨¡å‹çš„`from_pretrained`æ–¹æ³•æ—¶ï¼Œä½¿ç”¨deepspeed.zero.Initç›´æ¥åœ¨å¤šä¸ªgpuä¸Šå¯¹æ¨¡å‹è¿›è¡Œåˆ†åŒºã€‚
#
# **å¿…é¡»åœ¨åŠ è½½æ¨¡å‹AutoModelForSeq2SeqLM.from_pretrained(model_name)ä¹‹å‰è¿è¡Œæ­¤è¡Œ**
#
# å¦åˆ™ï¼Œæ¨¡å‹å°†é¦–å…ˆä»¥å¸¸è§„æ–¹å¼åŠ è½½ï¼Œä»…åœ¨å‰å‘æ—¶åˆ†åŒºï¼Œè¿™æ ·ä¼šæ›´ä½æ•ˆï¼Œå¹¶ä¸”åœ¨CPUå†…å­˜å¾ˆå°‘çš„æƒ…å†µä¸‹å¯èƒ½ä¼šå¤±è´¥
dschf = HfDeepSpeedConfig(ds_config)  # ä¿æŒæ­¤å¯¹è±¡çš„æ´»åŠ¨çŠ¶æ€

# ç°åœ¨å¯ä»¥åŠ è½½æ¨¡å‹ã€‚
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# åˆå§‹åŒ–Deepspeed ZeROå¹¶ä»…å­˜å‚¨å¼•æ“å¯¹è±¡
ds_engine = deepspeed.initialize(model=model, config_params=ds_config)[0]
ds_engine.module.eval()  # æ¨ç†æ¨¡å¼

# Deepspeed ZeROå¯ä»¥åœ¨æ¯ä¸ªGPUä¸Šå¤„ç†ä¸ç›¸å…³çš„è¾“å…¥ã€‚å› æ­¤ï¼Œå¯¹äº2ä¸ªgpuï¼Œæ‚¨å¯ä»¥åŒæ—¶å¤„ç†2ä¸ªè¾“å…¥ã€‚
# å¦‚æœåªæœ‰ä¸€ä¸ªè¦å¤„ç†çš„è¾“å…¥ï¼Œåˆ™éœ€è¦åŒæ—¶å°†ç›¸åŒçš„å­—ç¬¦ä¸²ä¼ é€’ç»™ä¸¤ä¸ªgpu
# å¦‚æœåªæœ‰ä¸€ä¸ªGPUï¼Œé‚£ä¹ˆæ‚¨åªæœ‰rank 0ã€‚
rank = torch.distributed.get_rank()
if rank == 0:
    text_in = "Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy"
elif rank == 1:
    text_in = "Is this review positive or negative? Review: this is the worst restaurant ever"

å°†ä¸‹é¢è¿™å¥è¯ç¿»è¯‘æˆä¸­æ–‡ï¼Œæ ¼å¼æ˜¯markdownï¼Œ<>é‡Œé¢çš„ä¿ç•™åŸæ–‡ï¼Œä¹Ÿä¸è¦æ·»åŠ é¢å¤–çš„å†…å®¹ï¼š

```python
tokenizer = AutoTokenizer.from_pretrained(model_name)
inputs = tokenizer.encode(text_in, return_tensors="pt").to(device=local_rank)
with torch.no_grad():
    outputs = ds_engine.module.generate(inputs, synced_gpus=True)
text_out = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(f"rank{rank}:\n   in={text_in}\n  out={text_out}")
```

å°†å…¶ä¿å­˜ä¸º`t0.py`å¹¶è¿è¡Œï¼š

```
$ deepspeed --num_gpus 2 t0.py
rank0:
   in=Is this review positive or negative? Review: this is the best cast iron skillet you will ever buy
  out=Positive
rank1:
   in=Is this review positive or negative? Review: this is the worst restaurant ever
  out=negative
```

è¿™æ˜¯ä¸€ä¸ªéå¸¸åŸºæœ¬çš„ç¤ºä¾‹ï¼Œä½ éœ€è¦æ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œè°ƒæ•´ã€‚

### `generate`ç»†å¾®å·®åˆ«

ä½¿ç”¨ZeRO Stage-3å’Œå¤šä¸ªGPUæ—¶ï¼Œå¿…é¡»é€šè¿‡è°ƒç”¨`generate(..., synced_gpus=True)`æ¥åŒæ­¥GPUã€‚å¦‚æœä¸è¿™æ ·åšï¼Œå¦‚æœæŸä¸ªGPUåœ¨å…¶ä»–GPUä¹‹å‰å®Œæˆç”Ÿæˆï¼Œåˆ™æ•´ä¸ªç³»ç»Ÿå°†å‘ç”ŸæŒ‚èµ·ï¼Œå› ä¸ºå…¶ä»–GPUå°†æ— æ³•ä»åœæ­¢ç”Ÿæˆçš„GPUæ¥æ”¶æƒé‡åˆ†ç‰‡ã€‚

ä»`transformers>=4.28`å¼€å§‹ï¼Œå¦‚æœæœªæ˜¾å¼æŒ‡å®š`synced_gpus`ï¼Œåˆ™å¦‚æœæ£€æµ‹åˆ°ä»¥ä¸‹æ¡ä»¶ï¼Œå®ƒå°†è‡ªåŠ¨è®¾ç½®ä¸º`True`ã€‚ä½†æ˜¯ï¼Œå¦‚æœéœ€è¦ï¼Œä»ç„¶å¯ä»¥è¦†ç›–`synced_gpus`çš„å€¼ã€‚

## æµ‹è¯•Deepspeedé›†æˆ

å¦‚æœæ‚¨æäº¤çš„PRæ¶‰åŠDeepSpeedé›†æˆï¼Œè¯·æ³¨æ„æˆ‘ä»¬çš„CircleCI PR CIè®¾ç½®æ²¡æœ‰GPUï¼Œå› æ­¤æˆ‘ä»¬åªåœ¨å¦ä¸€ä¸ªCIå¤œé—´è¿è¡Œéœ€è¦GPUçš„æµ‹è¯•ã€‚å› æ­¤ï¼Œå¦‚æœæ‚¨åœ¨PRä¸­å¾—åˆ°ä¸€ä¸ªç»¿è‰²çš„CIæŠ¥å‘Šï¼Œå¹¶ä¸æ„å‘³ç€DeepSpeedæµ‹è¯•é€šè¿‡ã€‚

è¦è¿è¡ŒDeepSpeedæµ‹è¯•ï¼Œè¯·è‡³å°‘è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```
RUN_SLOW=1 pytest tests/deepspeed/test_deepspeed.py
```

å¦‚æœæ›´æ”¹äº†ä»»ä½•å»ºæ¨¡æˆ–pytorchç¤ºä¾‹ä»£ç ï¼Œè¯·è¿è¡Œæ¨¡å‹åº“æµ‹è¯•ã€‚ä»¥ä¸‹å‘½ä»¤å°†è¿è¡Œæ‰€æœ‰DeepSpeedæµ‹è¯•ï¼š

```
RUN_SLOW=1 pytest tests/deepspeed
```

## ä¸»è¦DeepSpeedèµ„æº

- [é¡¹ç›®çš„GitHub](https://github.com/microsoft/deepspeed)
- [ä½¿ç”¨æ–‡æ¡£](https://www.deepspeed.ai/getting-started/)
- [APIæ–‡æ¡£](https://deepspeed.readthedocs.io/en/latest/index.html)
- [åšå®¢æ–‡ç« ](https://www.microsoft.com/en-us/research/search/?q=deepspeed)

è®ºæ–‡ï¼š

- [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](https://arxiv.org/abs/1910.02054)
- [ZeRO-Offload: Democratizing Billion-Scale Model Training](https://arxiv.org/abs/2101.06840)
- [ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning](https://arxiv.org/abs/2104.07857)

æœ€åï¼Œè¯·è®°ä½ï¼ŒHuggingFaceçš„[`Trainer`]åªé›†æˆäº†DeepSpeedï¼Œå› æ­¤å¦‚æœæ‚¨åœ¨ä½¿ç”¨DeepSpeedæ—¶é‡åˆ°ä»»ä½•é—®é¢˜æˆ–ç–‘é—®ï¼Œè¯·åœ¨[DeepSpeed GitHub](https://github.com/microsoft/DeepSpeed/issues)ä¸Šæäº¤é—®é¢˜ã€‚