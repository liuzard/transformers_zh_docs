<!--ç‰ˆæƒæ‰€æœ‰2022å¹´HuggingFaceå›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apacheè®¸å¯è¯2.0ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰è®¸å¯ï¼›é™¤ééµå®ˆè®¸å¯è¯ï¼Œå¦åˆ™æ‚¨ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚
æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è·å–è®¸å¯è¯çš„å‰¯æœ¬ï¼š

http://www.apache.org/licenses/LICENSE-2.0

è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯Markdownæ ¼å¼ï¼Œä½†åŒ…å«æˆ‘ä»¬doc-builderï¼ˆç±»ä¼¼äºMDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½æ— æ³•åœ¨æ‚¨çš„MarkdownæŸ¥çœ‹å™¨ä¸­æ­£ç¡®å‘ˆç°ã€‚
-->

# ä½¿ç”¨ğŸ¤— Accelerateè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ

éšç€æ¨¡å‹è¶Šæ¥è¶Šå¤§ï¼Œä½¿ç”¨å¹¶è¡Œè®¡ç®—å·²æˆä¸ºåœ¨æœ‰é™ç¡¬ä»¶ä¸Šè®­ç»ƒæ›´å¤§æ¨¡å‹å’ŒåŠ é€Ÿè®­ç»ƒé€Ÿåº¦çš„ç­–ç•¥ã€‚åœ¨Hugging Faceï¼Œæˆ‘ä»¬åˆ›å»ºäº†[ğŸ¤— Accelerate](https://huggingface.co/docs/accelerate)åº“ï¼Œå¸®åŠ©ç”¨æˆ·è½»æ¾åœ°åœ¨ä»»ä½•ç±»å‹çš„åˆ†å¸ƒå¼è®¾ç½®ä¸­è®­ç»ƒğŸ¤— Transformersæ¨¡å‹ï¼Œæ— è®ºæ˜¯åœ¨ä¸€å°æœºå™¨ä¸Šçš„å¤šä¸ªGPUè¿˜æ˜¯è·¨å¤šå°æœºå™¨çš„å¤šä¸ªGPUã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•è‡ªå®šä¹‰åŸç”ŸPyTorchè®­ç»ƒå¾ªç¯ä»¥åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒã€‚

## è®¾ç½®

é¦–å…ˆï¼Œå®‰è£…ğŸ¤— Accelerateï¼š

```bash
pip install accelerate
```

ç„¶åå¯¼å…¥å¹¶åˆ›å»ºä¸€ä¸ª[`~accelerate.Accelerator`]å¯¹è±¡ã€‚[`~accelerate.Accelerator`]ä¼šè‡ªåŠ¨æ£€æµ‹æ‚¨çš„åˆ†å¸ƒå¼è®¾ç½®ç±»å‹ï¼Œå¹¶åˆå§‹åŒ–æ‰€æœ‰å¿…è¦çš„ç»„ä»¶è¿›è¡Œè®­ç»ƒã€‚æ‚¨ä¸éœ€è¦æ˜¾å¼åœ°å°†æ¨¡å‹æ”¾ç½®åœ¨è®¾å¤‡ä¸Šã€‚

```py
>>> from accelerate import Accelerator

>>> accelerator = Accelerator()
```

## å‡†å¤‡åŠ é€Ÿ

ä¸‹ä¸€æ­¥æ˜¯å°†æ‰€æœ‰ç›¸å…³çš„è®­ç»ƒå¯¹è±¡ä¼ é€’ç»™[`~accelerate.Accelerator.prepare`]æ–¹æ³•ã€‚è¿™åŒ…æ‹¬æ‚¨çš„è®­ç»ƒå’Œè¯„ä¼°DataLoaderã€ä¸€ä¸ªæ¨¡å‹å’Œä¸€ä¸ªä¼˜åŒ–å™¨ï¼š

```py
>>> train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
...     train_dataloader, eval_dataloader, model, optimizer
... )
```

## åå‘ä¼ æ’­

æœ€åä¸€ä¸ªä¿®æ”¹æ˜¯å°†è®­ç»ƒå¾ªç¯ä¸­å…¸å‹çš„`loss.backward()`æ›¿æ¢ä¸ºğŸ¤— Accelerateçš„[`~accelerate.Accelerator.backward`]æ–¹æ³•ï¼š

```py
>>> for epoch in range(num_epochs):
...     for batch in train_dataloader:
...         outputs = model(**batch)
...         loss = outputs.loss
...         accelerator.backward(loss)

...         optimizer.step()
...         lr_scheduler.step()
...         optimizer.zero_grad()
...         progress_bar.update(1)
```

æ­£å¦‚æ‚¨åœ¨ä¸‹é¢çš„ä»£ç ä¸­æ‰€çœ‹åˆ°çš„ï¼Œæ‚¨åªéœ€è¦æ·»åŠ å››è¡Œé¢å¤–çš„ä»£ç åˆ°æ‚¨çš„è®­ç»ƒå¾ªç¯ä¸­å°±å¯ä»¥å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒï¼

```diff
+ from accelerate import Accelerator
  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

+ accelerator = Accelerator()

  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
  optimizer = AdamW(model.parameters(), lr=3e-5)

- device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
- model.to(device)

+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(
+     train_dataloader, eval_dataloader, model, optimizer
+ )

  num_epochs = 3
  num_training_steps = num_epochs * len(train_dataloader)
  lr_scheduler = get_scheduler(
      "linear",
      optimizer=optimizer,
      num_warmup_steps=0,
      num_training_steps=num_training_steps
  )

  progress_bar = tqdm(range(num_training_steps))

  model.train()
  for epoch in range(num_epochs):
      for batch in train_dataloader:
-         batch = {k: v.to(device) for k, v in batch.items()}
          outputs = model(**batch)
          loss = outputs.loss
-         loss.backward()
+         accelerator.backward(loss)

          optimizer.step()
          lr_scheduler.step()
          optimizer.zero_grad()
          progress_bar.update(1)
```

## è®­ç»ƒ

ä¸€æ—¦æ‚¨æ·»åŠ äº†ç›¸å…³çš„ä»£ç è¡Œï¼Œå°±å¯ä»¥åœ¨è„šæœ¬æˆ–ç¬”è®°æœ¬ï¼ˆä¾‹å¦‚Colaboratoryï¼‰ä¸­å¯åŠ¨è®­ç»ƒã€‚

### ä½¿ç”¨è„šæœ¬è¿›è¡Œè®­ç»ƒ

å¦‚æœæ‚¨ä»è„šæœ¬ä¸­è¿è¡Œè®­ç»ƒï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤åˆ›å»ºå¹¶ä¿å­˜ä¸€ä¸ªé…ç½®æ–‡ä»¶ï¼š

```bash
accelerate config
```

ç„¶åä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨è®­ç»ƒï¼š

```bash
accelerate launch train.py
```

### ä½¿ç”¨ç¬”è®°æœ¬è¿›è¡Œè®­ç»ƒ

ğŸ¤— Accelerateä¹Ÿå¯ä»¥åœ¨ç¬”è®°æœ¬ä¸­è¿è¡Œï¼Œå¦‚æœæ‚¨è®¡åˆ’ä½¿ç”¨Colaboratoryçš„TPUã€‚å°†è´Ÿè´£è®­ç»ƒçš„æ‰€æœ‰ä»£ç å°è£…åœ¨ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™[`~accelerate.notebook_launcher`]ï¼š

```py
>>> from accelerate import notebook_launcher

>>> notebook_launcher(training_function)
```

æœ‰å…³ğŸ¤— AccelerateåŠå…¶ä¸°å¯ŒåŠŸèƒ½çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…[æ–‡æ¡£](https://huggingface.co/docs/accelerate)ã€‚