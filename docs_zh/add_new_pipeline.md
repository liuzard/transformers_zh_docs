<!--ç‰ˆæƒæ‰€æœ‰2020å¹´The HuggingFaceå›¢é˜Ÿã€‚ ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apacheè®¸å¯è¯ï¼Œç‰ˆæœ¬2.0ï¼ˆâ€œè®¸å¯â€ï¼‰æˆæƒ;é™¤éä½ éµå®ˆè®¸å¯ï¼Œå¦åˆ™ä½ ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶
è®¸å¯è¯ã€‚ ä½ å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è·å–è®¸å¯çš„å‰¯æœ¬

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™åœ¨è®¸å¯ä¸‹åˆ†å‘çš„è½¯ä»¶æ˜¯æ ¹æ®
â€œåŸæ ·â€ BASISï¼Œä¸é™„å¸¦ä»»ä½•å½¢å¼çš„ä¿è¯æˆ–æ¡ä»¶ï¼Œæ— è®ºæ˜¯æ˜ç¤ºçš„è¿˜æ˜¯æš—ç¤ºçš„ã€‚æœ‰å…³è®¸å¯çš„æ¡ä»¶

âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶é‡‡ç”¨Markdownæ ¼å¼ï¼Œä½†åŒ…å«ä¸“ç”¨äºdoc-builderï¼ˆç±»ä¼¼äºMDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½æ— æ³•

åœ¨ä½ çš„MarkdownæŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ¸²æŸ“ã€‚-->

# å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰pipelineï¼Ÿ

åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰pipelineå¹¶å°†å…¶ä¸[Hub](hf.co/models)å…±äº«æˆ–æ·»åŠ åˆ°
ğŸ¤—Transformåº“ã€‚

é¦–å…ˆï¼Œä½ éœ€è¦ç¡®å®šæµæ°´çº¿èƒ½å¤Ÿæ¥å—çš„åŸå§‹è¾“å…¥ã€‚å®ƒå¯ä»¥æ˜¯å­—ç¬¦ä¸²ï¼ŒåŸå§‹å­—èŠ‚ï¼Œ
å­—å…¸æˆ–å…¶ä»–çœ‹èµ·æ¥æœ€å¯èƒ½çš„æ‰€éœ€è¾“å…¥ã€‚å°½é‡ä¿æŒè¿™äº›è¾“å…¥å°½å¯èƒ½ç®€å•
å› ä¸ºå®ƒä½¿å…¼å®¹æ€§æ›´å®¹æ˜“ï¼ˆç”šè‡³é€šè¿‡JSONåœ¨å…¶ä»–è¯­è¨€ä¸­å®ç°ï¼‰ã€‚è¿™äº›å°†æ˜¯
æµæ°´çº¿ï¼ˆ`preprocess`ï¼‰çš„â€œinputsâ€ã€‚

ç„¶åå®šä¹‰`outputs`ã€‚ä¸`inputs`åŸåˆ™ç›¸åŒã€‚ç®€åŒ–å¤„ç†è¶Šå¥½ã€‚è¿™äº›å°†æ˜¯
`postprocess`æ–¹æ³•çš„è¾“å‡ºã€‚

é¦–å…ˆä»ç»§æ‰¿åŸºç±»`Pipeline`å¼€å§‹ï¼Œè¯¥åŸºç±»åŒ…å«äº†å®ç°`preprocess`ï¼Œ`postprocess`å’Œä¸¤ä¸ªè¾…åŠ©æ–¹æ³•`_forward`å’Œ`_sanitize_parameters`æ‰€éœ€çš„å››ä¸ªæ–¹æ³•ã€‚

```Python
from transformers import Pipeline


class MyPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "maybe_arg" in kwargs:
            preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, inputs, maybe_arg=2):
        model_input = Tensor(inputs["input_ids"])
        return {"model_input": model_input}

    def _forward(self, model_inputs):
        # model_inputs == {"model_input": model_input}
        outputs = self.model(**model_inputs)
        # Maybe {"logits": Tensor(...)}
        return outputs

    def postprocess(self, model_outputs):
        best_class = model_outputs["logits"].softmax(-1)
        return best_class
```

æ ‡å‡†çš„åˆ†è§£ç»“æ„æ”¯æŒç›¸å¯¹å¹³æ»‘çš„CPU / GPUæ”¯æŒï¼ŒåŒæ—¶æ”¯æŒåœ¨ä¸åŒçº¿ç¨‹çš„CPUä¸Šè¿›è¡Œé¢„å¤„ç†/åå¤„ç†

`preprocess`å°†é‡‡ç”¨æœ€åˆå®šä¹‰çš„è¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºå¯ä»¥ä¾›æ¨¡å‹å–‚é£Ÿçš„å†…å®¹ã€‚å®ƒå¯èƒ½
åŒ…å«æ›´å¤šä¿¡æ¯ï¼Œé€šå¸¸æ˜¯ä¸€ä¸ªå­—å…¸ã€‚

`_forward`æ˜¯å®ç°ç»†èŠ‚ï¼Œä¸åº”ç›´æ¥è°ƒç”¨ã€‚`forward`æ˜¯é¦–é€‰
è°ƒç”¨æ–¹æ³•ï¼Œå› ä¸ºå®ƒåŒ…å«äº†ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½åœ¨é¢„æœŸè®¾å¤‡ä¸Šå·¥ä½œçš„ä¿æŠ¤æªæ–½ã€‚å¦‚æœä»»ä½•ä¸œè¥¿æ˜¯
ä¸çœŸå®æ¨¡å‹å…³è”çš„ï¼Œåˆ™å±äº`_forward`æ–¹æ³•ä¸­ï¼Œå…¶ä»–ä»»ä½•å†…å®¹éƒ½åœ¨preprocess /postprocessä¸­ã€‚

`postprocess`æ–¹æ³•å°†é‡‡ç”¨`_forward`çš„è¾“å‡ºï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¹‹å‰å†³å®šçš„æœ€ç»ˆè¾“å‡ºã€‚

`_sanitize_parameters`å­˜åœ¨çš„ç›®çš„æ˜¯å…è®¸ç”¨æˆ·éšæ—¶ä¼ é€’ä»»ä½•å‚æ•°ï¼Œæ— è®ºæ˜¯åœ¨åˆå§‹åŒ–æ—¶`pipeline(...., maybe_arg=4)`è¿˜æ˜¯åœ¨è°ƒç”¨æ—¶`pipe = pipeline(...); output = pipe(...., maybe_arg=4)`ã€‚

`_sanitize_parameters`çš„è¿”å›å€¼æ˜¯3ä¸ªkwargså­—å…¸ï¼Œå°†ç›´æ¥ä¼ é€’ç»™`preprocess`ï¼Œ`_forward`å’Œ`postprocess`ã€‚å¦‚æœè°ƒç”¨è€…æ²¡æœ‰ç”¨ä»»ä½•é¢å¤–å‚æ•°è°ƒç”¨ï¼Œè¯·ä¸è¦å¡«å†™ä»»ä½•å†…å®¹ã€‚è¿™
å¯ä»¥åœ¨å‡½æ•°å®šä¹‰ä¸­ä¿ç•™é»˜è®¤å‚æ•°ï¼Œè¿™æ€»æ˜¯æ›´åŠ â€œè‡ªç„¶â€ã€‚

åœ¨åˆ†ç±»ä»»åŠ¡çš„åå¤„ç†ä¸­ï¼Œå…¸å‹çš„ç¤ºä¾‹æ˜¯`top_k`å‚æ•°ã€‚

```python
>>> pipe = pipeline("my-new-task")
>>> pipe("This is a test")
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}, {"label": "3-star", "score": 0.05}
{"label": "4-star", "score": 0.025}, {"label": "5-star", "score": 0.025}]

>>> pipe("This is a test", top_k=2)
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}]
```

ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªé»˜è®¤å‚æ•°`5`æ›´æ–°æˆ‘ä»¬çš„`postprocess`æ–¹æ³•ï¼Œå¹¶ç¼–è¾‘
`_sanitize_parameters`ä»¥å…è®¸æ­¤æ–°å‚æ•°ã€‚

```python
def postprocess(self, model_outputs, top_k=5):
    best_class = model_outputs["logits"].softmax(-1)
    # æ·»åŠ å¤„ç†top_kçš„é€»è¾‘
    return best_class


def _sanitize_parameters(self, **kwargs):
    preprocess_kwargs = {}
    if "maybe_arg" in kwargs:
        preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]
    
    postprocess_kwargs = {}
    if "top_k" in kwargs:
        postprocess_kwargs["top_k"] = kwargs["top_k"]
    return preprocess_kwargs, {}, postprocess_kwargs
```

å°½é‡ä¿æŒè¾“å…¥/è¾“å‡ºéå¸¸ç®€å•ï¼Œæœ€å¥½æ˜¯JSONåºåˆ—åŒ–ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥å¾ˆå®¹æ˜“åœ°ä½¿ç”¨pipelineè€Œæ— éœ€ç”¨æˆ·äº†è§£æ–°ç±»å‹çš„å¯¹è±¡ã€‚ä¸ºäº†æ–¹ä¾¿ä½¿ç”¨ï¼ˆéŸ³é¢‘æ–‡ä»¶ï¼Œå¯ä»¥æ˜¯æ–‡ä»¶åï¼ŒURLæˆ–çº¯å­—èŠ‚ï¼‰ï¼Œ
æ”¯æŒè®¸å¤šä¸åŒç±»å‹çš„å‚æ•°ç›¸å¯¹è¾ƒå¸¸è§ã€‚



## å°†å…¶æ·»åŠ åˆ°å—æ”¯æŒä»»åŠ¡çš„åˆ—è¡¨ä¸­

è¦å°†`new-task`æ³¨å†Œåˆ°å—æ”¯æŒä»»åŠ¡åˆ—è¡¨ä¸­ï¼Œä½ éœ€è¦å°†å…¶æ·»åŠ åˆ°`PIPELINE_REGISTRY`ä¸­ï¼š

```python
from transformers.pipelines import PIPELINE_REGISTRY

PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
)
```

å¦‚æœéœ€è¦ï¼Œä½ å¯ä»¥æŒ‡å®šé»˜è®¤æ¨¡å‹ï¼Œæ­¤æ—¶æ¨¡å‹åº”è¯¥å…·æœ‰ç‰¹å®šçš„ä¿®è®¢ç‰ˆï¼ˆå¯ä»¥æ˜¯åˆ†æ”¯åç§°æˆ–æäº¤å“ˆå¸Œï¼‰ï¼Œä»¥åŠç±»å‹ï¼š

```python
PIPELINE_REGISTRY.register_pipeline(
    "new-task",
    pipeline_class=MyPipeline,
    pt_model=AutoModelForSequenceClassification,
    default={"pt": ("user/awesome_model", "abcdef")},
    type="text",  # å½“å‰æ”¯æŒç±»å‹ï¼štextã€audioã€imageã€multimodal
)
```

## åœ¨Hubä¸Šå…±äº«ä½ çš„pipeline

è¦åœ¨Hubä¸Šå…±äº«ä½ çš„è‡ªå®šä¹‰pipelineï¼Œä½ åªéœ€è¦å°†`Pipeline`å­ç±»çš„è‡ªå®šä¹‰ä»£ç ä¿å­˜åœ¨ä¸€ä¸ª
Pythonæ–‡ä»¶ä¸­ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬æƒ³ä¸ºå¥å­å¯¹åˆ†ç±»ä½¿ç”¨è‡ªå®šä¹‰pipelineï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
import numpy as np

from transformers import Pipeline


def softmax(outputs):
    maxes = np.max(outputs, axis=-1, keepdims=True)
    shifted_exp = np.exp(outputs - maxes)
    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)


class PairClassificationPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "second_text" in kwargs:
            preprocess_kwargs["second_text"] = kwargs["second_text"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, text, second_text=None):
        return self.tokenizer(text, text_pair=second_text, return_tensors=self.framework)

    def _forward(self, model_inputs):
        return self.model(**model_inputs)

    def postprocess(self, model_outputs):
        logits = model_outputs.logits[0].numpy()
        probabilities = softmax(logits)

        best_class = np.argmax(probabilities)
        label = self.model.config.id2label[best_class]
        score = probabilities[best_class].item()
        logits = logits.tolist()
        return {"label": label, "score": score, "logits": logits}
```

è¯¥å®ç°ä¸æ¡†æ¶æ— å…³ï¼Œé€‚ç”¨äºPyTorchå’ŒTensorFlowæ¨¡å‹ã€‚å¦‚æœæˆ‘ä»¬å°†å…¶ä¿å­˜åœ¨
åä¸º`pair_classification.py`çš„æ–‡ä»¶ä¸­ï¼Œç„¶åå¯ä»¥å¯¼å…¥å¹¶åƒè¿™æ ·æ³¨å†Œå®ƒï¼š

```py
from pair_classification import PairClassificationPipeline
from transformers.pipelines import PIPELINE_REGISTRY
from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification

PIPELINE_REGISTRY.register_pipeline(
    "pair-classification",
    pipeline_class=PairClassificationPipeline,
    pt_model=AutoModelForSequenceClassification,
    tf_model=TFAutoModelForSequenceClassification,
)
```

æ³¨å†Œå®Œæˆåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ä½¿ç”¨å®ƒã€‚ä¾‹å¦‚ï¼Œ`sgugger/finetuned-bert-mrpc`å·²ç»
åœ¨MRPCæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œç”¨äºå°†å¥å­å¯¹åˆ†ç±»ä¸ºæ˜¯å¦æ˜¯é‡Šä¹‰å¤è¿°ã€‚

```py
from transformers import pipeline

classifier = pipeline("pair-classification", model="sgugger/finetuned-bert-mrpc")
```

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`save_pretrained`æ–¹æ³•å°†å…¶å…±äº«åˆ°Hubä¸­ä½¿ç”¨`Repository`ï¼š

```py
from huggingface_hub import Repository

repo = Repository("test-dynamic-pipeline", clone_from="{your_username}/test-dynamic-pipeline")
classifier.save_pretrained("test-dynamic-pipeline")
repo.push_to_hub()
```

è¿™å°†æŠŠå®šä¹‰`PairClassificationPipeline`çš„æ–‡ä»¶å¤åˆ¶åˆ°æ–‡ä»¶å¤¹â€œtest-dynamic-pipelineâ€ä¸­ï¼Œ
å¹¶å°†æµæ°´çº¿çš„æ¨¡å‹å’Œåˆ†è¯å¤„ç†å™¨ä¿å­˜èµ·æ¥ï¼Œç„¶åå°†æ‰€æœ‰å†…å®¹æ¨é€åˆ°å­˜å‚¨åº“
`{your_username}/test-dynamic-pipeline`ã€‚ä¹‹åï¼Œä»»ä½•äººåªè¦æä¾›é€‰é¡¹`trust_remote_code=True`å°±å¯ä»¥ä½¿ç”¨å®ƒï¼š

```py
from transformers import pipeline

classifier = pipeline(model="{your_username}/test-dynamic-pipeline", trust_remote_code=True)
```

## å°†pipelineæ·»åŠ åˆ°ğŸ¤—Transformers

å¦‚æœæƒ³è¦å°†pipelineè´¡çŒ®ç»™ğŸ¤—Transformersï¼Œä½ éœ€è¦åœ¨`pipelines`æ¨¡å—ä¸­çš„`pipelines`å­æ¨¡å—ä¸­æ·»åŠ ä¸€ä¸ªæ–°æ¨¡å—ï¼Œå…¶ä¸­åŒ…å«ä½ çš„æµæ°´çº¿ä»£ç ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°`pipelines/__init__`ä¸­å®šä¹‰çš„ä»»åŠ¡åˆ—è¡¨ä¸­ã€‚

ç„¶åéœ€è¦æ·»åŠ æµ‹è¯•ã€‚åˆ›å»ºä¸€ä¸ªåä¸º`tests/test_pipelines_MY_PIPELINE.py`çš„æ–°æ–‡ä»¶ï¼Œå¹¶åŒ…å«å…¶ä»–æµ‹è¯•çš„ç¤ºä¾‹ã€‚

`run_pipeline_test`å‡½æ•°å°†éå¸¸é€šç”¨ï¼Œå¹¶åœ¨`model_mapping`å’Œ`tf_model_mapping`å®šä¹‰çš„æ¯ç§å¯èƒ½çš„æ¶æ„ä¸Šè¿è¡Œï¼Œè¿™æ˜¯éå¸¸é‡è¦çš„ã€‚

è¿™å¯¹äºå°†æ¥çš„å…¼å®¹æ€§æµ‹è¯•éå¸¸é‡è¦ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœæœ‰äººä¸º
`XXXForQuestionAnswering`æ·»åŠ äº†ä¸€ä¸ªæ–°æ¨¡å‹ï¼Œé‚£ä¹ˆpipelineæµ‹è¯•å°†å°è¯•åœ¨æ–°æ¨¡å‹ä¸Šè¿è¡Œã€‚å› ä¸ºæ¨¡å‹æ˜¯éšæœºçš„ï¼Œæ‰€ä»¥æ— æ³•æ£€æŸ¥å®é™…å€¼ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰ä¸€ä¸ªå¸®åŠ©å™¨`ANY`ï¼Œå®ƒå°†å°è¯•åŒ¹é…pipelineç±»å‹çš„è¾“å‡ºã€‚

ä½ è¿˜*éœ€è¦*ç¼–å†™2ï¼ˆç†æƒ³æƒ…å†µä¸‹æ˜¯4ï¼‰ä¸ªæµ‹è¯•ã€‚

- `test_small_model_pt`ï¼šä¸ºè¯¥pipelineå®šä¹‰ä¸€ä¸ªå°å‹æ¨¡å‹ï¼ˆç»“æœæ— æ‰€è°“ï¼‰ï¼Œå¹¶æµ‹è¯•pipelineçš„è¾“å‡ºã€‚ç»“æœåº”ä¸`test_small_model_tf`ç›¸åŒã€‚
- `test_small_model_tf`ï¼šä¸ºè¯¥pipelineå®šä¹‰ä¸€ä¸ªå°å‹æ¨¡å‹ï¼ˆç»“æœæ— æ‰€è°“ï¼‰ï¼Œå¹¶æµ‹è¯•pipelineçš„è¾“å‡ºã€‚ç»“æœåº”ä¸`test_small_model_pt`ç›¸åŒã€‚
- `test_large_model_pt`ï¼ˆ`å¯é€‰`ï¼‰ï¼šåœ¨ä¸€ä¸ªçœŸæ­£çš„æµæ°´çº¿ä¸Šæµ‹è¯•pipelineï¼Œå…¶ä¸­ç»“æœåº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„ã€‚è¿™äº›æµ‹è¯•å¾ˆæ…¢ï¼Œåº”æ ‡è®°ä¸ºè¿™æ ·ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯å±•ç¤ºpipelineï¼Œå¹¶ç¡®ä¿åœ¨æœªæ¥çš„å‘å¸ƒä¸­æ²¡æœ‰æ¼‚ç§»ã€‚
- `test_large_model_tf`ï¼ˆ`å¯é€‰`ï¼‰ï¼šåœ¨ä¸€ä¸ªçœŸæ­£çš„æµæ°´çº¿ä¸Šæµ‹è¯•pipelineï¼Œå…¶ä¸­ç»“æœåº”è¯¥æ˜¯æœ‰æ„ä¹‰çš„ã€‚è¿™äº›æµ‹è¯•å¾ˆæ…¢ï¼Œåº”æ ‡è®°ä¸ºè¿™æ ·ã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯å±•ç¤ºpipelineï¼Œå¹¶ç¡®ä¿åœ¨æœªæ¥çš„å‘å¸ƒä¸­æ²¡æœ‰æ¼‚ç§»ã€‚
