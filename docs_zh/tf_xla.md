<!--ç‰ˆæƒæ‰€æœ‰2023 HuggingFaceå›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apacheè®¸å¯è¯ç¬¬2.0ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰è®¸å¯ï¼›é™¤éç¬¦åˆæ¡ä»¶ï¼Œå¦åˆ™ä½ ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚
ä½ å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®è·å–è®¸å¯è¯çš„å‰¯æœ¬ï¼š

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯æŒ‰â€œåŸæ ·â€åˆ†å‘çš„ï¼Œ
æ²¡æœ‰ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚æœ‰å…³ç‰¹å®šè¯­è¨€ä¸‹çš„æƒé™å’Œé™åˆ¶ï¼Œè¯¦è§è®¸å¯è¯ã€‚

âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶é‡‡ç”¨Markdownæ ¼å¼ï¼Œä½†åŒ…å«ç‰¹å®šäºæˆ‘ä»¬doc-builderï¼ˆç±»ä¼¼äºMDXï¼‰çš„è¯­æ³•ï¼Œä½ çš„MarkdownæŸ¥çœ‹å™¨å¯èƒ½æ— æ³•æ­£ç¡®å‘ˆç°ã€‚

-->

# TensorFlowæ¨¡å‹çš„XLAé›†æˆ

[[open-in-colab]]

åŠ é€Ÿçº¿æ€§ä»£æ•°ï¼ˆAccelerated Linear Algebraï¼Œç®€ç§°XLAï¼‰æ˜¯ä¸€ç§ç”¨äºåŠ é€ŸTensorFlowæ¨¡å‹è¿è¡Œæ—¶çš„ç¼–è¯‘å™¨ã€‚æ ¹æ®[å®˜æ–¹æ–‡æ¡£](https://www.tensorflow.org/xla)ï¼š

XLAï¼ˆåŠ é€Ÿçº¿æ€§ä»£æ•°ï¼‰æ˜¯ä¸€ç§ä¸“ä¸ºçº¿æ€§ä»£æ•°è€Œè®¾è®¡çš„é¢†åŸŸç‰¹å®šç¼–è¯‘å™¨ï¼Œå¯åŠ é€ŸTensorFlowæ¨¡å‹ï¼Œè€Œæ— éœ€è¿›è¡Œæºä»£ç æ›´æ”¹ã€‚

åœ¨TensorFlowä¸­ä½¿ç”¨XLAå¾ˆç®€å•-å®ƒå·²æ‰“åŒ…åœ¨`tensorflow`åº“ä¸­ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡ä»»ä½•å›¾åˆ›å»ºå‡½æ•°çš„`jit_compile`å‚æ•°è§¦å‘ï¼Œä¾‹å¦‚[`tf.function`](https://www.tensorflow.org/guide/intro_to_graphs)ã€‚å½“ä½¿ç”¨`fit()`å’Œ`predict()`ç­‰Kerasæ–¹æ³•æ—¶ï¼Œä½ åªéœ€å°†`jit_compile`å‚æ•°ä¼ é€’ç»™`model.compile()`å³å¯å¯ç”¨XLAã€‚ä½†æ˜¯ï¼ŒXLAå¹¶ä¸é™äºè¿™äº›æ–¹æ³•-å®ƒä¹Ÿå¯ç”¨äºåŠ é€Ÿä»»ä½•ä»»æ„çš„`tf.function`ã€‚

ğŸ¤—Transformersä¸­çš„å‡ ç§TensorFlowæ–¹æ³•å·²è¢«é‡å†™ä¸ºä¸XLAå…¼å®¹ï¼ŒåŒ…æ‹¬[GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)ã€[T5](https://huggingface.co/docs/transformers/model_doc/t5)å’Œ[OPT](https://huggingface.co/docs/transformers/model_doc/opt)ç­‰æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆï¼Œä»¥åŠ[Whisper](https://huggingface.co/docs/transformers/model_doc/whisper)ç­‰æ¨¡å‹çš„è¯­éŸ³å¤„ç†ã€‚

è™½ç„¶ç¡®åˆ‡çš„åŠ é€Ÿåº¦å› æ¨¡å‹è€Œå¼‚ï¼Œä½†å¯¹äºğŸ¤—Transformersä¸­çš„TensorFlowæ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°äº†å¤§çº¦100å€çš„åŠ é€Ÿåº¦ã€‚æœ¬æ–‡æ¡£å°†è§£é‡Šå¦‚ä½•ä½¿ç”¨XLAæ¥å®ç°è¿™äº›æ¨¡å‹çš„æœ€å¤§æ€§èƒ½ã€‚å¦‚æœä½ å¯¹åŸºå‡†æµ‹è¯•å’Œæˆ‘ä»¬çš„XLAé›†æˆè®¾è®¡å“²å­¦æ„Ÿå…´è¶£ï¼Œæˆ‘ä»¬è¿˜å°†æä¾›å…¶ä»–èµ„æºçš„é“¾æ¥ã€‚

## ä½¿ç”¨XLAè¿è¡ŒTFå‡½æ•°

è®©æˆ‘ä»¬è€ƒè™‘ä»¥ä¸‹TensorFlowä¸­çš„æ¨¡å‹ï¼š

```py
import tensorflow as tf

model = tf.keras.Sequential(
    [tf.keras.layers.Dense(10, input_shape=(10,), activation="relu"), tf.keras.layers.Dense(5, activation="softmax")]
)
```

ä¸Šè¿°æ¨¡å‹æ¥å—ç»´åº¦ä¸º`(10,)`çš„è¾“å…¥ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è¿è¡Œæ¨¡å‹çš„å‰å‘ä¼ é€’ï¼š

```py
# ä¸ºæ¨¡å‹ç”Ÿæˆéšæœºè¾“å…¥ã€‚
batch_size = 16
input_vector_dim = 10
random_inputs = tf.random.normal((batch_size, input_vector_dim))

# æ‰§è¡Œå‰å‘ä¼ é€’ã€‚
_ = model(random_inputs)
```

è¦ä½¿ç”¨XLAç¼–è¯‘å‡½æ•°è¿è¡Œå‰å‘ä¼ é€’ï¼Œéœ€è¦æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

```py
xla_fn = tf.function(model, jit_compile=True)
_ = xla_fn(random_inputs)
```

`model`çš„é»˜è®¤`call()`å‡½æ•°ç”¨äºç¼–è¯‘XLAå›¾ã€‚ä½†æ˜¯ï¼Œå¦‚æœè¿˜æœ‰å…¶ä»–è¦ç¼–è¯‘ä¸ºXLAçš„æ¨¡å‹å‡½æ•°ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š

```py
my_xla_fn = tf.function(model.my_xla_fn, jit_compile=True)
```

## ä½¿ç”¨ğŸ¤—Transformersä¸­çš„XLAè¿è¡ŒTFæ–‡æœ¬ç”Ÿæˆæ¨¡å‹

è¦åœ¨ğŸ¤—Transformersä¸­å¯ç”¨XLAåŠ é€Ÿçš„ç”ŸæˆåŠŸèƒ½ï¼Œä½ éœ€è¦å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„`transformers`ã€‚å¯é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥å®‰è£…ï¼š

```bash
pip install transformers --upgrade
```

ç„¶åï¼Œä½ å¯ä»¥è¿è¡Œä»¥ä¸‹ä»£ç ï¼š

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

# å¦‚æœæœªå®‰è£…Transformersçš„æœ€ä½ç‰ˆæœ¬ï¼Œåˆ™ä¼šå‡ºé”™ã€‚
from transformers.utils import check_min_version

check_min_version("4.21.0")


tokenizer = AutoTokenizer.from_pretrained("gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("gpt2")
input_string = ["TensorFlow is"]

# ä¸€è¡Œä»£ç åˆ›å»ºäº†ä¸€ä¸ªXLAç”Ÿæˆå‡½æ•°
xla_generate = tf.function(model.generate, jit_compile=True)

tokenized_input = tokenizer(input_string, return_tensors="tf")
generated_tokens = xla_generate(**tokenized_input, num_beams=2)

decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
# Generated -- TensorFlow is an open-source, open-source, distributed-source application # framework for the
```

æ­£å¦‚ä½ æ³¨æ„åˆ°çš„é‚£æ ·ï¼Œåœ¨`generate()`ä¸Šå¯ç”¨XLAåªéœ€ä¸€è¡Œä»£ç ã€‚å…¶ä½™çš„ä»£ç ä¿æŒä¸å˜ã€‚ä½†æ˜¯ï¼Œä¸Šè¿°ä»£ç ç‰‡æ®µä¸­ä¹Ÿæœ‰ä¸€äº›ç‰¹å®šäºXLAçš„è¦æ³¨æ„çš„é—®é¢˜ã€‚ä½ éœ€è¦äº†è§£è¿™äº›é—®é¢˜ä»¥å®ç°XLAå¸¦æ¥çš„åŠ é€Ÿã€‚æˆ‘ä»¬åœ¨ä¸‹ä¸€èŠ‚ä¸­è®¨è®ºè¿™äº›é—®é¢˜ã€‚

## æ³¨æ„äº‹é¡¹

å½“ä½ é¦–æ¬¡æ‰§è¡Œå¯ç”¨äº†XLAçš„å‡½æ•°ï¼ˆä¾‹å¦‚ä¸Šé¢çš„`xla_generate()`ï¼‰æ—¶ï¼Œå®ƒå°†åœ¨å†…éƒ¨å°è¯•æ¨æ–­è®¡ç®—å›¾ï¼Œè¿™æ˜¯ä¸€ä¸ªè€—æ—¶çš„è¿‡ç¨‹ã€‚è¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºâ€œè¿½è¸ªâ€ã€‚

ä½ å¯èƒ½ä¼šæ³¨æ„åˆ°ç”Ÿæˆæ—¶é—´ä¸å¿«ã€‚ç»™`xla_generate()`ï¼ˆæˆ–ä»»ä½•å…¶ä»–å¯ç”¨XLAçš„å‡½æ•°ï¼‰è¿ç»­è°ƒç”¨ä¸éœ€è¦æ¨æ–­è®¡ç®—å›¾ï¼Œå‰ææ˜¯å‡½æ•°çš„è¾“å…¥ä¸æœ€åˆæ„å»ºè®¡ç®—å›¾æ—¶çš„å½¢çŠ¶ç›¸åŒã€‚è™½ç„¶å¯¹äºå…·æœ‰å›ºå®šè¾“å…¥å½¢çŠ¶ï¼ˆä¾‹å¦‚å›¾åƒï¼‰çš„æ¨¡æ€æ€§æ¥è¯´è¿™ä¸æ˜¯é—®é¢˜ï¼Œä½†å¦‚æœä½ æ­£åœ¨å¤„ç†å˜é‡è¾“å…¥å½¢çŠ¶ï¼ˆä¾‹å¦‚æ–‡æœ¬ï¼‰ï¼Œåˆ™éœ€è¦æ³¨æ„ã€‚

ä¸ºäº†ç¡®ä¿`xla_generate()`å§‹ç»ˆä½¿ç”¨ç›¸åŒçš„è¾“å…¥å½¢çŠ¶è¿›è¡Œæ“ä½œï¼Œå¯ä»¥åœ¨è°ƒç”¨tokenizeræ—¶æŒ‡å®š`padding`å‚æ•°ã€‚

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("gpt2")
input_string = ["TensorFlow is"]

xla_generate = tf.function(model.generate, jit_compile=True)

# è¿™é‡Œï¼Œæˆ‘ä»¬ä½¿ç”¨å¡«å……é€‰é¡¹è°ƒç”¨tokenizerã€‚
tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")

generated_tokens = xla_generate(**tokenized_input, num_beams=2)
decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
```

è¿™æ ·ï¼Œä½ å¯ä»¥ç¡®ä¿`xla_generate()`å§‹ç»ˆæ¥æ”¶ä¸å…¶è¿½è¸ªæ—¶ç›¸åŒå½¢çŠ¶çš„è¾“å…¥ï¼Œå¹¶å¯¼è‡´ç”Ÿæˆæ—¶é—´çš„åŠ é€Ÿã€‚ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç éªŒè¯è¿™ä¸€ç‚¹ï¼š

```py
import time
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("gpt2")

xla_generate = tf.function(model.generate, jit_compile=True)

for input_string in ["TensorFlow is", "TensorFlow is a", "TFLite is a"]:
    tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")
    start = time.time_ns()
    generated_tokens = xla_generate(**tokenized_input, num_beams=2)
    end = time.time_ns()
    print(f"Execution time -- {(end - start) / 1e6:.1f} ms\n")
```

åœ¨Tesla T4 GPUä¸Šï¼Œä½ å¯ä»¥æœŸæœ›å¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š

```bash
Execution time -- 30819.6 ms

Execution time -- 79.0 ms

Execution time -- 78.9 ms
```

`xla_generate()`çš„ç¬¬ä¸€æ¬¡è°ƒç”¨ç”±äºè¿½è¸ªè€Œè€—æ—¶ï¼Œä½†æ˜¯åç»­è°ƒç”¨çš„é€Ÿåº¦å¿«äº†å‡ ä¸ªæ•°é‡çº§ã€‚è¯·è®°ä½ï¼Œä»»ä½•æ—¶å€™æ›´æ”¹ç”Ÿæˆé€‰é¡¹éƒ½å°†è§¦å‘é‡æ–°è¿½è¸ªï¼Œä»è€Œå¯¼è‡´ç”Ÿæˆæ—¶é—´å˜æ…¢ã€‚

æˆ‘ä»¬åœ¨æœ¬æ–‡æ¡£ä¸­å¹¶æœªæ¶µç›–ğŸ¤—Transformersåœ¨æ–‡æœ¬ç”Ÿæˆæ–¹é¢æä¾›çš„æ‰€æœ‰é€‰é¡¹ã€‚æˆ‘ä»¬é¼“åŠ±ä½ é˜…è¯»æ–‡æ¡£ä»¥è·å–æ›´å¤šé«˜çº§ç”¨ä¾‹ã€‚

## å…¶ä»–èµ„æº

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸ºä½ æä¾›ä¸€äº›å…¶ä»–èµ„æºï¼Œå¦‚æœä½ æƒ³æ·±å…¥äº†è§£ğŸ¤—Transformersä¸­çš„XLAä»¥åŠå…¶ä»–æ–¹é¢ï¼š

* [æ­¤Colabç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/91_tf_xla_generate.ipynb)æä¾›äº†ä¸€ä¸ªäº¤äº’å¼æ¼”ç¤ºï¼Œä¾›ä½ å°è¯•ä½¿ç”¨ä¸XLAå…¼å®¹çš„ç¼–ç å™¨-è§£ç å™¨ï¼ˆä¾‹å¦‚[T5](https://huggingface.co/docs/transformers/model_doc/t5)ï¼‰å’Œä»…è§£ç å™¨ï¼ˆä¾‹å¦‚[GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)ï¼‰æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ã€‚
* [æ­¤åšå®¢æ–‡ç« ](https://huggingface.co/blog/tf-xla-generate)æä¾›äº†ä¸XLAå…¼å®¹æ¨¡å‹çš„æ¯”è¾ƒåŸºå‡†çš„æ¦‚è¿°ï¼Œä»¥åŠå¯¹TensorFlowä¸­XLAçš„å‹å¥½ä»‹ç»ã€‚
* [æ­¤åšå®¢æ–‡ç« ](https://blog.tensorflow.org/2022/11/how-hugging-face-improved-text-generation-performance-with-xla.html)è®¨è®ºäº†æˆ‘ä»¬åœ¨ğŸ¤—Transformersä¸­æ·»åŠ å¯¹TensorFlowæ¨¡å‹çš„XLAæ”¯æŒçš„è®¾è®¡å“²å­¦ã€‚
* äº†è§£æœ‰å…³XLAå’ŒTensorFlowå›¾çš„æ›´å¤šä¿¡æ¯çš„æ¨èå¸–å­ï¼š
    * [XLAï¼šç”¨äºæœºå™¨å­¦ä¹ çš„ä¼˜åŒ–ç¼–è¯‘å™¨](https://www.tensorflow.org/xla)
    * [å›¾è¡¨å’Œtf.functionç®€ä»‹](https://www.tensorflow.org/guide/intro_to_graphs)
    * [ä½¿ç”¨tf.functionè·å¾—æ›´å¥½çš„æ€§èƒ½](https://www.tensorflow.org/guide/function) 