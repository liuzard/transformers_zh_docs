```python
>>> model.compile(optimizer=optimizer, loss=SparseCategoricalCrossentropy(from_logits=True), metrics=["accuracy"])
```

Setup callbacks and use the `fit()` method to run the training:

```py
>>> callbacks = [keras.callbacks.EarlyStopping(monitor="val_loss", patience=2)]

>>> model.fit(
...     tf_train_dataset,
...     validation_data=tf_eval_dataset,
...     epochs=num_epochs,
...     callbacks=callbacks,
... )
```

Once training is completed, share your model to the Hub using [`hub` module] so that everyone can use your model:

```py
>>> model.save_pretrained("my_awesome_food_model")
```

</tf>
</frameworkcontent>

Congratulations! You have successfully fine-tuned an image classification model using ViT and evaluated its performance.

```md
>>> loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
>>> model.compile(optimizer=optimizer, loss=loss)
```

è¦è®¡ç®—ä»é¢„æµ‹ä¸­è·å¾—çš„å‡†ç¡®ç‡å¹¶å°†æ‚¨çš„æ¨¡å‹æ¨é€åˆ°ğŸ¤— Hubï¼Œè¯·ä½¿ç”¨[Keraså›è°ƒ](../main_classes/keras_callbacks)ã€‚
å°†æ‚¨çš„`compute_metrics`å‡½æ•°ä¼ é€’ç»™[KerasMetricCallback](../main_classes/keras_callbacks#transformers.KerasMetricCallback)ï¼Œ
å¹¶ä½¿ç”¨[PushToHubCallback](../main_classes/keras_callbacks#transformers.PushToHubCallback)ä¸Šä¼ æ¨¡å‹ï¼š

```py
>>> from transformers.keras_callbacks import KerasMetricCallback, PushToHubCallback

>>> metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)
>>> push_to_hub_callback = PushToHubCallback(
...     output_dir="food_classifier",
...     tokenizer=image_processor,
...     save_strategy="no",
... )
>>> callbacks = [metric_callback, push_to_hub_callback]
```

æœ€åï¼Œæ‚¨å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ï¼ä½¿ç”¨æ‚¨çš„è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ã€epochsçš„æ•°é‡å’Œå›è°ƒå‡½æ•°è°ƒç”¨`fit()`ä»¥å¾®è°ƒæ¨¡å‹ï¼š

```py
>>> model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)
Epoch 1/5
250/250 [==============================] - 313s 1s/step - loss: 2.5623 - val_loss: 1.4161 - accuracy: 0.9290
Epoch 2/5
250/250 [==============================] - 265s 1s/step - loss: 0.9181 - val_loss: 0.6808 - accuracy: 0.9690
Epoch 3/5
250/250 [==============================] - 252s 1s/step - loss: 0.3910 - val_loss: 0.4303 - accuracy: 0.9820
Epoch 4/5
250/250 [==============================] - 251s 1s/step - loss: 0.2028 - val_loss: 0.3191 - accuracy: 0.9900
Epoch 5/5
250/250 [==============================] - 238s 949ms/step - loss: 0.1232 - val_loss: 0.3259 - accuracy: 0.9890
```

æ­å–œï¼æ‚¨å·²ç»å¯¹æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œå¹¶åœ¨ğŸ¤— Hubä¸Šåˆ†äº«äº†å®ƒã€‚ç°åœ¨æ‚¨å¯ä»¥ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼
</tf>
</frameworkcontent>


<Tip>

æœ‰å…³å¦‚ä½•å¯¹å›¾åƒåˆ†ç±»æ¨¡å‹è¿›è¡Œå¾®è°ƒçš„æ›´è¯¦ç»†ç¤ºä¾‹ï¼Œè¯·å‚é˜…ç›¸åº”çš„[PyTorchç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb)ã€‚

</Tip>

## æ¨ç†

å¾ˆå¥½ï¼Œç°åœ¨æ‚¨å·²ç»å¯¹æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œå¯ä»¥ä½¿ç”¨å®ƒè¿›è¡Œæ¨ç†äº†ï¼

åŠ è½½è¦è¿›è¡Œæ¨ç†çš„å›¾åƒï¼š

```py
>>> ds = load_dataset("food101", split="validation[:10]")
>>> image = ds["image"][0]
```

<div class="flex justify-center">
    <img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png" alt="image of beignets"/>
</div>

å°è¯•ä½¿ç”¨[`pipeline`]å¯¹å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œæ¨ç†æ˜¯æœ€ç®€å•çš„æ–¹æ³•ã€‚ä½¿ç”¨æ‚¨çš„æ¨¡å‹å®ä¾‹åŒ–ä¸€ä¸ªå›¾åƒåˆ†ç±»çš„`pipeline`ï¼Œå¹¶å°†å›¾åƒä¼ é€’ç»™å®ƒï¼š

```py
>>> from transformers import pipeline

>>> classifier = pipeline("image-classification", model="my_awesome_food_model")
>>> classifier(image)
[{'score': 0.31856709718704224, 'label': 'beignets'},
 {'score': 0.015232225880026817, 'label': 'bruschetta'},
 {'score': 0.01519392803311348, 'label': 'chicken_wings'},
 {'score': 0.013022331520915031, 'label': 'pork_chop'},
 {'score': 0.012728818692266941, 'label': 'prime_rib'}]
```

å¦‚æœå¸Œæœ›ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¤åˆ¶`pipeline`çš„ç»“æœï¼š

<frameworkcontent>
<pt>
åŠ è½½å›¾åƒå¤„ç†å™¨å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶å°†`input`è¿”å›ä¸ºPyTorchå¼ é‡ï¼š

```py
>>> from transformers import AutoImageProcessor
>>> import torch

>>> image_processor = AutoImageProcessor.from_pretrained("my_awesome_food_model")
>>> inputs = image_processor(image, return_tensors="pt")
```

å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å¹¶è¿”å›logitsï¼š

```py
>>> from transformers import AutoModelForImageClassification

>>> model = AutoModelForImageClassification.from_pretrained("my_awesome_food_model")
>>> with torch.no_grad():
...     logits = model(**inputs).logits
```

ä½¿ç”¨æœ€é«˜æ¦‚ç‡çš„é¢„æµ‹æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨æ¨¡å‹çš„`id2label`æ˜ å°„å°†å…¶è½¬æ¢ä¸ºæ ‡ç­¾ï¼š

```py
>>> predicted_label = logits.argmax(-1).item()
>>> model.config.id2label[predicted_label]
'beignets'
```
</pt>
</frameworkcontent>

<frameworkcontent>
<tf>
åŠ è½½å›¾åƒå¤„ç†å™¨å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†å¹¶å°†`input`è¿”å›ä¸ºTensorFlowå¼ é‡ï¼š

```py
>>> from transformers import AutoImageProcessor

>>> image_processor = AutoImageProcessor.from_pretrained("MariaK/food_classifier")
>>> inputs = image_processor(image, return_tensors="tf")
```

å°†è¾“å…¥ä¼ é€’ç»™æ¨¡å‹å¹¶è¿”å›logitsï¼š

```py
>>> from transformers import TFAutoModelForImageClassification

>>> model = TFAutoModelForImageClassification.from_pretrained("MariaK/food_classifier")
>>> logits = model(**inputs).logits
```

ä½¿ç”¨æœ€é«˜æ¦‚ç‡çš„é¢„æµ‹æ ‡ç­¾ï¼Œå¹¶ä½¿ç”¨æ¨¡å‹çš„`id2label`æ˜ å°„å°†å…¶è½¬æ¢ä¸ºæ ‡ç­¾ï¼š

```py
>>> predicted_class_id = int(tf.math.argmax(logits, axis=-1)[0])
>>> model.config.id2label[predicted_class_id]
'beignets'
```

</tf>
</frameworkcontent>