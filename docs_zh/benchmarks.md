<!--ç‰ˆæƒæ‰€æœ‰ 2020 å¹´ HuggingFace å›¢é˜Ÿ. ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

åŸºäº Apache è®¸å¯è¯ç¬¬ 2 ç‰ˆ ("è®¸å¯è¯")ï¼›åœ¨ç¬¦åˆè®¸å¯çš„å‰æä¸‹ï¼Œä½ ä¸å¾—ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚ä½ å¯ä»¥è·å–æ­¤è®¸å¯çš„å‰¯æœ¬ï¼Œç½‘å€ä¸º

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨çš„æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æŒ‰"åŸæ ·"åˆ†å‘æœ¬è½¯ä»¶ã€‚æœ¬è®¸å¯ä¸å…è®¸ä½ ä»¥ä»»ä½•æ–¹å¼é¢†å–ã€ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆ†å‘ã€å‡ºå”®ã€è®¸å¯æˆ–è½¬è®©æœ¬è½¯ä»¶ä¸­çš„ä»»ä½•æƒåˆ©æˆ–è½¯ä»¶æ–‡æ¡£çš„ä»»ä½•å‰¯æœ¬ã€‚æœ¬è½¯ä»¶ç”±ç‰ˆæƒæ‰€æœ‰äººæŒ‰"åŸæ ·"æä¾›ï¼Œæ²¡æœ‰æ˜ç¤ºæˆ–æš—ç¤ºçš„ä»»ä½•ä¿è¯æˆ–æ¡ä»¶ï¼Œæ— è®ºæ˜¯æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯ã€æ¡ä»¶æˆ–å…¶ä»–ï¼ŒåŒ…æ‹¬éä¾µæƒã€é€‚é”€æ€§æˆ–å…¶ä»–ç‰¹å®šç”¨é€”çš„é€‚ç”¨æ€§ã€‚æœ‰å…³é™åˆ¶åœ¨ç‰¹å®šæ³•å¾‹ä¸‹çš„è´£ä»»ï¼Œè¯·å‚é˜…è®¸å¯è¯ã€‚

è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶ä½äº Markdown ä¸­ï¼Œä½†åŒ…å«å¯¹æˆ‘ä»¬çš„æ–‡æ¡£æ„å»ºç¨‹åºï¼ˆç±»ä¼¼äº MDXï¼‰çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½æ— æ³•åœ¨ä½ çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ¸²æŸ“ã€‚

-->

# åŸºå‡†æµ‹è¯•

<Tip warning={true}>

Hugging Face çš„åŸºå‡†æµ‹è¯•å·¥å…·å·²ç»è¢«å¼ƒç”¨ï¼Œå»ºè®®ä½¿ç”¨å¤–éƒ¨çš„åŸºå‡†æµ‹è¯•åº“æ¥æµ‹é‡ Transformer æ¨¡å‹çš„é€Ÿåº¦å’Œå†…å­˜å¤æ‚åº¦ã€‚

</Tip>

[[open-in-colab]]

è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹å¦‚ä½•å¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæœ€ä½³å®è·µä»¥åŠå·²æœ‰çš„åŸºå‡†æµ‹è¯•ã€‚

å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/huggingface/notebooks/tree/main/examples/benchmark.ipynb)æ‰¾åˆ°ä¸€ä¸ªæ›´è¯¦ç»†è§£é‡Šå¦‚ä½•å¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„ç¬”è®°æœ¬ã€‚

## å¦‚ä½•å¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•

[`PyTorchBenchmark`] å’Œ [`TensorFlowBenchmark`] ç±»å…è®¸çµæ´»åœ°å¯¹ğŸ¤— Transformersæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚åŸºå‡†æµ‹è¯•ç±»å…è®¸æˆ‘ä»¬æµ‹é‡æ¨æ–­å’Œè®­ç»ƒçš„ *å³°å€¼å†…å­˜ä½¿ç”¨é‡* å’Œ *æ‰€éœ€æ—¶é—´*ã€‚

<Tip>

è¿™é‡Œï¼Œæ¨æ–­å®šä¹‰ä¸ºå•æ¬¡å‰å‘ä¼ é€’ï¼Œè®­ç»ƒå®šä¹‰ä¸ºå•æ¬¡å‰å‘ä¼ é€’å’Œåå‘ä¼ é€’ã€‚

</Tip>

[`PyTorchBenchmark`] å’Œ [`TensorFlowBenchmark`] ç±»éœ€è¦ç›¸åº”çš„ [`PyTorchBenchmarkArguments`] å’Œ [`TensorFlowBenchmarkArguments`] ç±»å‹çš„å¯¹è±¡è¿›è¡Œå®ä¾‹åŒ–ã€‚[`PyTorchBenchmarkArguments`] å’Œ [`TensorFlowBenchmarkArguments`] æ˜¯æ•°æ®ç±»ï¼ŒåŒ…å«å…¶ç›¸åº”åŸºå‡†æµ‹è¯•ç±»æ‰€éœ€çš„æ‰€æœ‰ç›¸å…³é…ç½®ã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•å¯¹ç±»å‹ä¸º *bert-base-cased* çš„BERTæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚

<frameworkcontent>
<pt>
```py
>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments

>>> args = PyTorchBenchmarkArguments(models=["bert-base-uncased"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512])
>>> benchmark = PyTorchBenchmark(args)
```
</pt>
<tf>
```py
>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments

>>> args = TensorFlowBenchmarkArguments(
...     models=["bert-base-uncased"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> benchmark = TensorFlowBenchmark(args)
```
</tf>
</frameworkcontent>

è¿™é‡Œï¼ŒåŸºå‡†æµ‹è¯•å‚æ•°æ•°æ®ç±»ä¼ å…¥äº†ä¸‰ä¸ªå‚æ•°ï¼Œå³ `models`ã€`batch_sizes` å’Œ `sequence_lengths`ã€‚`models` å‚æ•°æ˜¯å¿…éœ€çš„ï¼Œå¹¶ä¸”éœ€è¦ä¸€ä¸ªæ¥è‡ª[model hub](https://huggingface.co/models) çš„æ¨¡å‹æ ‡è¯†ç¬¦åˆ—è¡¨ã€‚`batch_sizes` å’Œ `sequence_lengths` æ˜¯åˆ—è¡¨å‚æ•°ï¼Œå®šä¹‰äº†å¯¹æ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•æ—¶çš„ `input_ids` çš„å¤§å°ã€‚è¿˜æœ‰è®¸å¤šå…¶ä»–å¯ä»¥é€šè¿‡åŸºå‡†æµ‹è¯•å‚æ•°æ•°æ®ç±»è¿›è¡Œé…ç½®çš„å‚æ•°ã€‚è¦è·å–æœ‰å…³è¿™äº›å‚æ•°çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥æŸ¥é˜…æ–‡ä»¶ `src/transformers/benchmark/benchmark_args_utils.py`ã€`src/transformers/benchmark/benchmark_args.py`ï¼ˆç”¨äºPyTorchï¼‰å’Œ `src/transformers/benchmark/benchmark_args_tf.py`ï¼ˆç”¨äºTensorFlowï¼‰ã€‚æˆ–è€…ï¼Œå¯ä»¥ä»æ ¹ç›®å½•è¿è¡Œä»¥ä¸‹ Shell å‘½ä»¤ï¼Œåˆ†åˆ«æ‰“å°å‡ºPyTorchå’ŒTensorflowçš„æ‰€æœ‰å¯é…ç½®å‚æ•°çš„æè¿°æ€§åˆ—è¡¨ã€‚

<frameworkcontent>
<pt>
```bash
python examples/pytorch/benchmarking/run_benchmark.py --help
```

ç„¶åï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨ `benchmark.run()` æ¥è¿è¡Œå·²å®ä¾‹åŒ–çš„åŸºå‡†æµ‹è¯•å¯¹è±¡ã€‚

```py
>>> results = benchmark.run()
>>> print(results)
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length     Time in s                  
--------------------------------------------------------------------------------
bert-base-uncased          8               8             0.006     
bert-base-uncased          8               32            0.006     
bert-base-uncased          8              128            0.018     
bert-base-uncased          8              512            0.088     
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length    Memory in MB 
--------------------------------------------------------------------------------
bert-base-uncased          8               8             1227
bert-base-uncased          8               32            1281
bert-base-uncased          8              128            1307
bert-base-uncased          8              512            1539
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: PyTorch
- use_torchscript: False
- framework_version: 1.4.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 08:58:43.371351
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</pt>
<tf>
```bash
python examples/tensorflow/benchmarking/run_benchmark_tf.py --help
```

ç„¶åå¯ä»¥é€šè¿‡è°ƒç”¨ `benchmark.run()` æ¥è¿è¡Œå·²å®ä¾‹åŒ–çš„åŸºå‡†æµ‹è¯•å¯¹è±¡ã€‚

```py
>>> results = benchmark.run()
>>> print(results)
>>> results = benchmark.run()
>>> print(results)
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length     Time in s                  
--------------------------------------------------------------------------------
bert-base-uncased          8               8             0.005
bert-base-uncased          8               32            0.008
bert-base-uncased          8              128            0.022
bert-base-uncased          8              512            0.105
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length    Memory in MB 
--------------------------------------------------------------------------------
bert-base-uncased          8               8             1330
bert-base-uncased          8               32            1330
bert-base-uncased          8              128            1330
bert-base-uncased          8              512            1770
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: Tensorflow
- use_xla: False
- framework_version: 2.2.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:26:35.617317
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</tf>
</frameworkcontent>

é»˜è®¤æƒ…å†µä¸‹ï¼Œå¯¹æ¨æ–­è¿›è¡ŒåŸºå‡†æµ‹è¯•å¹¶æµ‹é‡æ‰€éœ€æ—¶é—´å’Œå†…å­˜ã€‚åœ¨ä¸Šé¢çš„ç¤ºä¾‹è¾“å‡ºä¸­ï¼Œå‰ä¸¤ä¸ªéƒ¨åˆ†æ˜¾ç¤ºäº†ä¸æ¨æ–­æ—¶é—´å’Œæ¨æ–­å†…å­˜ç›¸å¯¹åº”çš„ç»“æœã€‚æ­¤å¤–ï¼Œåœ¨â€œç¯å¢ƒä¿¡æ¯â€ä¸‹çš„ç¬¬ä¸‰ä¸ªéƒ¨åˆ†æ‰“å°å‡ºæœ‰å…³è®¡ç®—ç¯å¢ƒçš„æ‰€æœ‰ç›¸å…³ä¿¡æ¯ï¼Œä¾‹å¦‚GPUç±»å‹ã€ç³»ç»Ÿã€åº“ç‰ˆæœ¬ç­‰ã€‚å½“åœ¨[`PyTorchBenchmarkArguments`]å’Œ[`TensorFlowBenchmarkArguments`]ä¸­æ·»åŠ `save_to_csv=True`å‚æ•°æ—¶ï¼Œè¿™äº›ä¿¡æ¯å¯ä»¥é€‰æ‹©ä¿å­˜åˆ°ä¸€ä¸ª_.csv_æ–‡ä»¶ä¸­ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½ä¿å­˜åœ¨ä¸€ä¸ªå•ç‹¬çš„_.csv_æ–‡ä»¶ä¸­ã€‚æ¯ä¸ª_.csv_æ–‡ä»¶çš„è·¯å¾„å¯ä»¥é€šè¿‡å‚æ•°æ•°æ®ç±»è¿›è¡Œå®šä¹‰ã€‚

é™¤äº†é€šè¿‡æ¨¡å‹æ ‡è¯†ç¬¦ï¼ˆä¾‹å¦‚ `bert-base-uncased`ï¼‰å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡ŒåŸºå‡†æµ‹è¯•ä¹‹å¤–ï¼Œç”¨æˆ·è¿˜å¯ä»¥é€šè¿‡ä»»ä½•å¯ç”¨çš„æ¨¡å‹ç±»å¯¹ä»»æ„é…ç½®è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¿…é¡»åœ¨åŸºå‡†æµ‹è¯•å‚æ•°ä¸­æ’å…¥ä¸€ç³»åˆ—é…ç½®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

<frameworkcontent>
<pt>
```py
>>> from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments, BertConfig

>>> args = PyTorchBenchmarkArguments(
...     models=["bert-base", "bert-384-hid", "bert-6-lay"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> config_base = BertConfig()
>>> config_384_hid = BertConfig(hidden_size=384)
>>> config_6_lay = BertConfig(num_hidden_layers=6)

>>> benchmark = PyTorchBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])
>>> benchmark.run()
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length       Time in s                  
--------------------------------------------------------------------------------
bert-base                  8              128            0.006
bert-base                  8              512            0.006
bert-base                  8              128            0.018     
bert-base                  8              512            0.088     
bert-384-hid              8               8             0.006     
bert-384-hid              8               32            0.006     
bert-384-hid              8              128            0.011     
bert-384-hid              8              512            0.054     
bert-6-lay                 8               8             0.003     
bert-6-lay                 8               32            0.004     
bert-6-lay                 8              128            0.009     
bert-6-lay                 8              512            0.044
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length      Memory in MB 
--------------------------------------------------------------------------------
bert-base                  8               8             1277
bert-base                  8               32            1281
bert-base                  8              128            1307     
bert-base                  8              512            1539     
bert-384-hid              8               8             1005     
bert-384-hid              8               32            1027     
bert-384-hid              8              128            1035     
bert-384-hid              8              512            1255     
bert-6-lay                 8               8             1097     
bert-6-lay                 8               32            1101     
bert-6-lay                 8              128            1127     
bert-6-lay                 8              512            1359
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: PyTorch
- use_torchscript: False
- framework_version: 1.4.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:35:25.143267
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</pt>
<tf>
```py
>>> from transformers import TensorFlowBenchmark, TensorFlowBenchmarkArguments, BertConfig

>>> args = TensorFlowBenchmarkArguments(
...     models=["bert-base", "bert-384-hid", "bert-6-lay"], batch_sizes=[8], sequence_lengths=[8, 32, 128, 512]
... )
>>> config_base = BertConfig()
>>> config_384_hid = BertConfig(hidden_size=384)
>>> config_6_lay = BertConfig(num_hidden_layers=6)

>>> benchmark = TensorFlowBenchmark(args, configs=[config_base, config_384_hid, config_6_lay])
>>> benchmark.run()
====================       INFERENCE - SPEED - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length       Time in s                  
--------------------------------------------------------------------------------
bert-base                  8               8             0.005
bert-base                  8               32            0.008
bert-base                  8              128            0.022
bert-base                  8              512            0.106
bert-384-hid              8               8             0.005
bert-384-hid              8               32            0.007
bert-384-hid              8              128            0.018
bert-384-hid              8              512            0.064
bert-6-lay                 8               8             0.002
bert-6-lay                 8               32            0.003
bert-6-lay                 8              128            0.0011
bert-6-lay                 8              512            0.074
--------------------------------------------------------------------------------

====================      INFERENCE - MEMORY - RESULT       ====================
--------------------------------------------------------------------------------
Model Name             Batch Size     Seq Length      Memory in MB 
--------------------------------------------------------------------------------
bert-base                  8               8             1330
bert-base                  8               32            1330
bert-base                  8              128            1330
bert-base                  8              512            1770
bert-384-hid              8               8             1330
bert-384-hid              8               32            1330
bert-384-hid              8              128            1330
bert-384-hid              8              512            1540
bert-6-lay                 8               8             1330
bert-6-lay                 8               32            1330
bert-6-lay                 8              128            1330
bert-6-lay                 8              512            1540
--------------------------------------------------------------------------------

====================        ENVIRONMENT INFORMATION         ====================

- transformers_version: 2.11.0
- framework: Tensorflow
- use_xla: False
- framework_version: 2.2.0
- python_version: 3.6.10
- system: Linux
- cpu: x86_64
- architecture: 64bit
- date: 2020-06-29
- time: 09:38:15.487125
- fp16: False
- use_multiprocessing: True
- only_pretrain_model: False
- cpu_ram_mb: 32088
- use_gpu: True
- num_gpus: 1
- gpu: TITAN RTX
- gpu_ram_mb: 24217
- gpu_power_watts: 280.0
- gpu_performance_state: 2
- use_tpu: False
```
</tf>
</frameworkcontent>

- åŒæ ·ï¼Œè¿™æ¬¡æˆ‘ä»¬æµ‹é‡äº†è‡ªå®šä¹‰é…ç½®çš„`BertModel`ç±»çš„_æ¨æ–­æ—¶é—´_å’Œ_æ‰€éœ€å†…å­˜_ã€‚å½“å†³å®šå¯¹å“ªç§é…ç½®è¿›è¡Œæ¨¡å‹è®­ç»ƒæ—¶ï¼Œè¿™ä¸ªåŠŸèƒ½ç‰¹åˆ«æœ‰å¸®åŠ©ã€‚

  ## åŸºå‡†æµ‹è¯•æœ€ä½³å®è·µ

  æœ¬èŠ‚åˆ—å‡ºäº†åœ¨è¿›è¡Œæ¨¡å‹åŸºå‡†æµ‹è¯•æ—¶åº”æ³¨æ„çš„å‡ ä¸ªæœ€ä½³å®è·µã€‚

  - ç›®å‰ï¼Œä»…æ”¯æŒå•è®¾å¤‡åŸºå‡†æµ‹è¯•ã€‚åœ¨ä½¿ç”¨GPUè¿›è¡ŒåŸºå‡†æµ‹è¯•æ—¶ï¼Œå»ºè®®ç”¨æˆ·é€šè¿‡åœ¨shellä¸­è®¾ç½®`CUDA_VISIBLE_DEVICES`ç¯å¢ƒå˜é‡æ¥æŒ‡å®šä»£ç åº”åœ¨å“ªä¸ªè®¾å¤‡ä¸Šè¿è¡Œï¼Œä¾‹å¦‚åœ¨è¿è¡Œä»£ç ä¹‹å‰è®¾ç½®`export CUDA_VISIBLE_DEVICES=0`ã€‚
  - é€‰é¡¹`no_multi_processing`åªåº”åœ¨æµ‹è¯•å’Œè°ƒè¯•æ—¶è®¾ç½®ä¸º`True`ã€‚ä¸ºç¡®ä¿å‡†ç¡®çš„å†…å­˜æµ‹é‡ï¼Œå»ºè®®é€šè¿‡å°†`no_multi_processing`è®¾ç½®ä¸º`True`ï¼Œåœ¨å•ç‹¬çš„è¿›ç¨‹ä¸­è¿è¡Œæ¯ä¸ªå†…å­˜åŸºå‡†æµ‹è¯•ã€‚
  - åœ¨å…±äº«æ¨¡å‹åŸºå‡†æµ‹è¯•ç»“æœæ—¶ï¼Œåº”å§‹ç»ˆè¯´æ˜ç¯å¢ƒä¿¡æ¯ã€‚ç”±äºä¸åŒçš„GPUè®¾å¤‡ã€åº“ç‰ˆæœ¬ç­‰åŸå› ï¼Œç»“æœå¯èƒ½ä¼šæœ‰å¾ˆå¤§å·®å¼‚ï¼Œå› æ­¤ä»…ä»…æä¾›åŸºå‡†æµ‹è¯•ç»“æœå¯¹ç¤¾åŒºæ¥è¯´å¹¶æ²¡æœ‰å¤ªå¤§ç”¨å¤„ã€‚

  ## å…±äº«ä½ çš„åŸºå‡†æµ‹è¯•

  ä»¥å‰ï¼Œæ‰€æœ‰å¯ç”¨çš„æ ¸å¿ƒæ¨¡å‹ï¼ˆå½“æ—¶æ˜¯10ä¸ªï¼‰éƒ½å·²ç»è¿›è¡Œäº†_æ¨æ–­æ—¶é—´_çš„åŸºå‡†æµ‹è¯•ï¼Œæ¶‰åŠè®¸å¤šä¸åŒçš„è®¾ç½®ï¼šä½¿ç”¨PyTorchï¼Œæœ‰æ— TorchScriptï¼Œä½¿ç”¨TensorFlowï¼Œæœ‰æ— XLAã€‚æ‰€æœ‰è¿™äº›æµ‹è¯•éƒ½åœ¨CPUä¸Šè¿›è¡Œï¼ˆé™¤äº†TensorFlow XLAï¼‰å’ŒGPUä¸Šè¿›è¡Œã€‚

  ç›¸å…³æ–¹æ³•è¯¦è§[æ­¤åšå®¢æ–‡ç« ](https://medium.com/huggingface/benchmarking-transformers-pytorch-and-tensorflow-e2917fb891c2)ï¼Œç»“æœå¯åœ¨[æ­¤å¤„](https://docs.google.com/spreadsheets/d/1sryqufw2D0XlUH4sq3e9Wnxu5EAQkaohzrJbd5HdQ_w/edit?usp=sharing)æ‰¾åˆ°ã€‚

  ä½¿ç”¨æ–°çš„_åŸºå‡†æµ‹è¯•_å·¥å…·ï¼Œä¸ç¤¾åŒºå…±äº«ä½ çš„åŸºå‡†æµ‹è¯•ç»“æœå˜å¾—æ¯”ä»¥å¾€æ›´åŠ å®¹æ˜“ï¼š

- [PyTorch åŸºå‡†æµ‹è¯•ç»“æœ](https://github.com/huggingface/transformers/tree/main/examples/pytorch/benchmarking/README.md)ã€‚
  - [TensorFlow åŸºå‡†æµ‹è¯•ç»“æœ](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/benchmarking/README.md)ã€‚