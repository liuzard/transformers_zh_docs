<!--ç‰ˆæƒæ‰€æœ‰2023 The HuggingFaceå›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apacheè®¸å¯è¯2.0ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰ï¼Œä½ å°†æ— æ³•ä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œé™¤éžç¬¦åˆè®¸å¯è¯çš„è§„å®šã€‚ä½ å¯ä»¥åœ¨

http://www.apache.org/license/LICENSE-2.0

ä»Žè¯¥è®¸å¯è¯èŽ·å–è®¸å¯è¯çš„å‰¯æœ¬ã€‚

é™¤éžé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œè½¯ä»¶æ ¹æ®

â€œæŒ‰åŽŸæ ·â€åˆ†å‘ï¼Œä¸é™„å¸¦ä»»ä½•æ˜Žç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚è¯·æŸ¥çœ‹æœ‰å…³

ç‰¹å®šè¯­è¨€é™åˆ¶å’Œè®¸å¯è¯ä¸‹é™åˆ¶çš„è®¸å¯è¯ã€‚-->

# Pop2Piano

<div class="flex flex-wrap space-x-1">
<a href="https://huggingface.co/spaces/sweetcocoa/pop2piano">
<img alt="Spaces" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue">
</a>
</div>

## æ¦‚è§ˆ

Pop2Pianoæ¨¡åž‹ç”±Jongho Choiå’ŒKyogu Leeåœ¨[Pop2Pianoï¼šåŸºäºŽæµè¡ŒéŸ³é¢‘çš„é’¢ç´ç¿»å”±æ›²ç”Ÿæˆ](https://arxiv.org/abs/2211.00895)ä¸­æå‡ºã€‚

æµè¡ŒéŸ³ä¹çš„é’¢ç´ç¿»å”±å¾ˆå—æ¬¢è¿Žï¼Œä½†ä»ŽéŸ³ä¹ä¸­ç”Ÿæˆå®ƒä»¬å¹¶ä¸æ˜¯ä¸€é¡¹ç®€å•çš„ä»»åŠ¡ã€‚å®ƒéœ€è¦å¯¹å¼¹å¥é’¢ç´æœ‰å¾ˆé«˜çš„ä¸“ä¸šçŸ¥è¯†ï¼Œä»¥åŠäº†è§£æ­Œæ›²çš„ä¸åŒç‰¹ç‚¹å’Œæ—‹å¾‹ã€‚ä½¿ç”¨Pop2Pianoï¼Œä½ å¯ä»¥ç›´æŽ¥ä»Žæ­Œæ›²çš„éŸ³é¢‘æ³¢å½¢ç”Ÿæˆç¿»å”±æ›²ã€‚å®ƒæ˜¯é¦–ä¸ªä¸éœ€è¦æ—‹å¾‹å’Œå’Œå¼¦æå–æ¨¡å—ç›´æŽ¥ä»Žæµè¡ŒéŸ³é¢‘ç”Ÿæˆé’¢ç´ç¿»å”±æ›²çš„æ¨¡åž‹ã€‚

Pop2Pianoæ˜¯åŸºäºŽ[T5](https://arxiv.org/pdf/1910.10683.pdf)çš„ç¼–ç å™¨-è§£ç å™¨Transformeræ¨¡åž‹ã€‚è¾“å…¥éŸ³é¢‘è¢«è½¬æ¢ä¸ºå…¶æ³¢å½¢ï¼Œå¹¶ä¼ é€’ç»™ç¼–ç å™¨ï¼Œè¯¥ç¼–ç å™¨å°†å…¶è½¬æ¢ä¸ºæ½œåœ¨è¡¨ç¤ºã€‚è§£ç å™¨ä½¿ç”¨è¿™äº›æ½œåœ¨è¡¨ç¤ºä»¥è‡ªå›žå½’çš„æ–¹å¼ç”Ÿæˆä»¤ç‰Œidã€‚æ¯ä¸ªä»¤ç‰Œidå¯¹åº”äºŽå››ç§ä¸åŒçš„ä»¤ç‰Œç±»åž‹ï¼šæ—¶é—´ï¼Œé€Ÿåº¦ï¼ŒéŸ³ç¬¦å’Œâ€œç‰¹æ®Šâ€ã€‚ç„¶åŽå°†ä»¤ç‰Œidè§£ç ä¸ºç›¸åº”çš„MIDIæ–‡ä»¶ã€‚

è®ºæ–‡ä¸­çš„æ‘˜è¦å¦‚ä¸‹ï¼š

*è®¸å¤šäººå–œæ¬¢æµè¡ŒéŸ³ä¹çš„é’¢ç´ç¿»å”±ã€‚ä½†æ˜¯ï¼Œè‡ªåŠ¨ç”Ÿæˆæµè¡ŒéŸ³ä¹çš„é’¢ç´ç¿»å”±ä»ç„¶æ˜¯ä¸€ä¸ªä¸å¤ªç ”ç©¶çš„ä»»åŠ¡ã€‚è¿™éƒ¨åˆ†æ˜¯å› ä¸ºç¼ºä¹åŒæ­¥çš„{æµè¡ŒéŸ³ä¹ï¼Œé’¢ç´ç¿»å”±}æ•°æ®å¯¹ï¼Œè¿™ä½¿å¾—åº”ç”¨æœ€æ–°çš„æ•°æ®å¯†é›†åž‹åŸºäºŽæ·±åº¦å­¦ä¹ çš„æ–¹æ³•å˜å¾—å›°éš¾ã€‚ä¸ºäº†åˆ©ç”¨æ•°æ®é©±åŠ¨æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œæˆ‘ä»¬ä½¿ç”¨è‡ªåŠ¨åŒ–æµç¨‹åˆ›å»ºäº†å¤§é‡é…å¯¹å’ŒåŒæ­¥çš„{æµè¡ŒéŸ³ä¹ï¼Œé’¢ç´ç¿»å”±}æ•°æ®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†Pop2Pianoï¼Œè¿™æ˜¯ä¸€ç§åŸºäºŽTransformerç½‘ç»œçš„æ–¹æ³•ï¼Œå®ƒåœ¨ç»™å®šæµè¡ŒéŸ³ä¹æ³¢å½¢çš„æƒ…å†µä¸‹ç”Ÿæˆé’¢ç´ç¿»å”±ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªç›´æŽ¥ä»Žæµè¡ŒéŸ³é¢‘ç”Ÿæˆé’¢ç´ç¿»å”±è€Œä¸ä½¿ç”¨æ—‹å¾‹å’Œå’Œå¼¦æå–æ¨¡å—çš„æ¨¡åž‹ã€‚æˆ‘ä»¬å±•ç¤ºäº†é€šè¿‡æˆ‘ä»¬çš„æ•°æ®é›†è®­ç»ƒçš„Pop2Pianoèƒ½å¤Ÿç”Ÿæˆå¯ä¿¡çš„é’¢ç´ç¿»å”±ã€‚*

æç¤ºï¼š

1. è¦ä½¿ç”¨Pop2Pianoï¼Œä½ éœ€è¦å®‰è£…ðŸ¤— Transformersåº“ä»¥åŠä»¥ä¸‹ç¬¬ä¸‰æ–¹æ¨¡å—ï¼š
```python
pip install pretty-midi==0.2.9 essentia==2.1b6.dev1034 librosa scipy
```
è¯·æ³¨æ„ï¼Œå®‰è£…åŽå¯èƒ½éœ€è¦é‡æ–°å¯åŠ¨è¿è¡Œæ—¶ã€‚
2. Pop2Pianoæ˜¯åŸºäºŽT5çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡åž‹ã€‚
3. Pop2Pianoå¯ç”¨äºŽä¸ºç»™å®šçš„éŸ³é¢‘åºåˆ—ç”ŸæˆMIDIéŸ³é¢‘æ–‡ä»¶ã€‚
4. åœ¨`Pop2PianoForConditionalGeneration.generate()`ä¸­é€‰æ‹©ä¸åŒçš„ä½œæ›²å®¶ä¼šå¯¼è‡´ä¸åŒçš„ç»“æžœã€‚
5. åœ¨åŠ è½½éŸ³é¢‘æ–‡ä»¶æ—¶å°†é‡‡æ ·çŽ‡è®¾ç½®ä¸º44.1 kHzå¯ä»¥èŽ·å¾—è‰¯å¥½çš„æ€§èƒ½ã€‚
6. å°½ç®¡Pop2Pianoä¸»è¦æ˜¯åœ¨éŸ©å›½æµè¡ŒéŸ³ä¹ä¸Šè®­ç»ƒçš„ï¼Œä½†åœ¨å…¶ä»–è¥¿æ–¹æµè¡ŒéŸ³ä¹æˆ–å˜»å“ˆéŸ³ä¹ä¸Šä¹Ÿè¡¨çŽ°å¾—å¾ˆå¥½ã€‚

æ­¤æ¨¡åž‹ç”±[Susnato Dhar](https://huggingface.co/susnato)è´¡çŒ®ã€‚
åŽŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://github.com/sweetcocoa/pop2piano)æ‰¾åˆ°ã€‚

## ç¤ºä¾‹

- ä½¿ç”¨HuggingFaceæ•°æ®é›†çš„ç¤ºä¾‹ï¼š

```python
>>> from datasets import load_dataset
>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor

>>> model = Pop2PianoForConditionalGeneration.from_pretrained("sweetcocoa/pop2piano")
>>> processor = Pop2PianoProcessor.from_pretrained("sweetcocoa/pop2piano")
>>> ds = load_dataset("sweetcocoa/pop2piano_ci", split="test")

>>> inputs = processor(
...     audio=ds["audio"][0]["array"], sampling_rate=ds["audio"][0]["sampling_rate"], return_tensors="pt"
... )
>>> model_output = model.generate(input_features=inputs["input_features"], composer="composer1")
>>> tokenizer_output = processor.batch_decode(
...     token_ids=model_output, feature_extractor_output=inputs
... )["pretty_midi_objects"][0]
>>> tokenizer_output.write("./Outputs/midi_output.mid")
```

- ä½¿ç”¨ä½ è‡ªå·±çš„éŸ³é¢‘æ–‡ä»¶çš„ç¤ºä¾‹ï¼š

```python
>>> import librosa
>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor

>>> audio, sr = librosa.load("<your_audio_file_here>", sr=44100)  # éšæ„æ›´æ”¹srä¸ºé€‚å½“çš„å€¼ã€‚
>>> model = Pop2PianoForConditionalGeneration.from_pretrained("sweetcocoa/pop2piano")
>>> processor = Pop2PianoProcessor.from_pretrained("sweetcocoa/pop2piano")

>>> inputs = processor(audio=audio, sampling_rate=sr, return_tensors="pt")
>>> model_output = model.generate(input_features=inputs["input_features"], composer="composer1")
>>> tokenizer_output = processor.batch_decode(
...     token_ids=model_output, feature_extractor_output=inputs
... )["pretty_midi_objects"][0]
>>> tokenizer_output.write("./Outputs/midi_output.mid")
```

- æ‰¹å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶çš„ç¤ºä¾‹ï¼š

```python
>>> import librosa
>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor

>>> # éšæ„æ›´æ”¹srä¸ºé€‚å½“çš„å€¼ã€‚
>>> audio1, sr1 = librosa.load("<your_first_audio_file_here>", sr=44100)  
>>> audio2, sr2 = librosa.load("<your_second_audio_file_here>", sr=44100)
>>> model = Pop2PianoForConditionalGeneration.from_pretrained("sweetcocoa/pop2piano")
>>> processor = Pop2PianoProcessor.from_pretrained("sweetcocoa/pop2piano")

>>> inputs = processor(audio=[audio1, audio2], sampling_rate=[sr1, sr2], return_attention_mask=True, return_tensors="pt")
>>> # ç”±äºŽçŽ°åœ¨ç”Ÿæˆæ‰¹å¤„ç†ï¼ˆ2ä¸ªéŸ³é¢‘ï¼‰ï¼Œæˆ‘ä»¬å¿…é¡»ä¼ é€’attention_mask
>>> model_output = model.generate(
...     input_features=inputs["input_features"],
...     attention_mask=inputs["attention_mask"],
...     composer="composer1",
... )
>>> tokenizer_output = processor.batch_decode(
...     token_ids=model_output, feature_extractor_output=inputs
... )["pretty_midi_objects"]

>>> # ç”±äºŽæˆ‘ä»¬çŽ°åœ¨æœ‰2ä¸ªç”Ÿæˆçš„MIDIæ–‡ä»¶
>>> tokenizer_output[0].write("./Outputs/midi_output1.mid")
>>> tokenizer_output[1].write("./Outputs/midi_output2.mid")
```


- æ‰¹å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶çš„ç¤ºä¾‹ï¼ˆä½¿ç”¨`Pop2PianoFeatureExtractor`å’Œ`Pop2PianoTokenizer`ï¼‰ï¼š

```python
>>> import librosa
>>> from transformers import Pop2PianoForConditionalGeneration, Pop2PianoFeatureExtractor, Pop2PianoTokenizer

>>> # éšæ„æ›´æ”¹srä¸ºé€‚å½“çš„å€¼ã€‚
>>> audio1, sr1 = librosa.load("<your_first_audio_file_here>", sr=44100)  
>>> audio2, sr2 = librosa.load("<your_second_audio_file_here>", sr=44100)
>>> model = Pop2PianoForConditionalGeneration.from_pretrained("sweetcocoa/pop2piano")
>>> feature_extractor = Pop2PianoFeatureExtractor.from_pretrained("sweetcocoa/pop2piano")
>>> tokenizer = Pop2PianoTokenizer.from_pretrained("sweetcocoa/pop2piano")

>>> inputs = feature_extractor(
...     audio=[audio1, audio2], 
...     sampling_rate=[sr1, sr2], 
...     return_attention_mask=True, 
...     return_tensors="pt",
... )
>>> # ç”±äºŽçŽ°åœ¨ç”Ÿæˆæ‰¹å¤„ç†ï¼ˆ2ä¸ªéŸ³é¢‘ï¼‰ï¼Œæˆ‘ä»¬å¿…é¡»ä¼ é€’attention_mask
>>> model_output = model.generate(
...     input_features=inputs["input_features"],
...     attention_mask=inputs["attention_mask"],
...     composer="composer1",
... )
>>> tokenizer_output = tokenizer.batch_decode(
...     token_ids=model_output, feature_extractor_output=inputs
... )["pretty_midi_objects"]

>>> # ç”±äºŽæˆ‘ä»¬çŽ°åœ¨æœ‰2ä¸ªç”Ÿæˆçš„MIDIæ–‡ä»¶
>>> tokenizer_output[0].write("./Outputs/midi_output1.mid")
>>> tokenizer_output[1].write("./Outputs/midi_output2.mid")
```


## Pop2PianoConfig

[[autodoc]] Pop2PianoConfig

## Pop2PianoFeatureExtractor

[[autodoc]] Pop2PianoFeatureExtractor
    - __call__

## Pop2PianoForConditionalGeneration

[[autodoc]] Pop2PianoForConditionalGeneration
    - forward
    - generate

## Pop2PianoTokenizer

[[autodoc]] Pop2PianoTokenizer
    - __call__

## Pop2PianoProcessor

[[autodoc]] Pop2PianoProcessor
    - __call__