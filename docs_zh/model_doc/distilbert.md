<!--ç‰ˆæƒ 2020 å¹´ HuggingFace å›¢é˜Ÿã€‚ç‰ˆæƒæ‰€æœ‰ã€‚

æ ¹æ® Apache è®¸å¯è¯ç¬¬ 2.0 ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰ï¼Œé™¤éç¬¦åˆè®¸å¯è¯çš„è§„å®šï¼Œå¦åˆ™æ— æ³•ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚
ä½ å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å¾—è®¸å¯è¯çš„å‰¯æœ¬ï¼š

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è¯¥è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶æ˜¯æŒ‰
â€œåŸæ ·â€åŸºç¡€åˆ†å‘çš„ï¼Œä¸é™„å¸¦ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„æ‹…ä¿æˆ–æ¡ä»¶ã€‚
æœ‰å…³æ˜ç¤ºæˆ–æš—ç¤ºçš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…è®¸å¯è¯ä¸­çš„æ¡æ¬¾ã€‚

æ³¨æ„ï¼Œè¯¥æ–‡ä»¶æ˜¯ä»¥ Markdown çš„æ ¼å¼ç¼–å†™çš„ï¼Œä½†åŒ…å«äº†ç‰¹å®šè¯­æ³•ï¼Œä¾›æˆ‘ä»¬çš„ doc-builderï¼ˆç±»ä¼¼äº MDXï¼‰ä½¿ç”¨ï¼Œè¿™å¯èƒ½ä¸èƒ½
åœ¨ä½ çš„ Markdown æŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ¸²æŸ“ã€‚-->

# DistilBERT

<div class="flex flex-wrap space-x-1">
<a href="https://huggingface.co/models?filter=distilbert">
<img alt="Models" src="https://img.shields.io/badge/All_model_pages-distilbert-blueviolet">
</a>
<a href="https://huggingface.co/spaces/docs-demos/distilbert-base-uncased">
<img alt="Spaces" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue">
</a>
<a href="https://huggingface.co/papers/1910.01108">
<img alt="Paper page" src="https://img.shields.io/badge/Paper%20page-1910.01108-green">
</a>
</div>

## æ¦‚è¿°

DistilBERT æ¨¡å‹æ˜¯åœ¨åšå®¢æ–‡ç«  [Smaller, faster, cheaper, lighter: Introducing DistilBERT, a
distilled version of BERT](https://medium.com/huggingface/distilbert-8cf3380435b5)å’Œè®ºæ–‡ [DistilBERT, a
distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/papers/1910.01108) ä¸­æå‡ºçš„ã€‚DistilBERT æ˜¯
é€šè¿‡ç²¾ç®€ BERT base æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„ä¸€ä¸ªå°å‹ã€å¿«é€Ÿã€ä¾¿å®œå’Œè½»é‡çº§çš„ Transformer æ¨¡å‹ã€‚ç›¸æ¯”äº *bert-base-uncased*ï¼Œå®ƒçš„å‚æ•°é‡å‡å°‘äº† 40%ï¼Œè¿è¡Œé€Ÿåº¦æé«˜äº† 60%ï¼ŒåŒæ—¶åœ¨ GLUE è¯­è¨€ç†è§£åŸºå‡†æµ‹è¯•ä¸­ä¿æŒäº†è¶…è¿‡ 95% çš„ BERT æ€§èƒ½ã€‚

è®ºæ–‡ä¸­çš„æ‘˜è¦å¦‚ä¸‹ï¼š

*éšç€å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„è¿ç§»å­¦ä¹ åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­å˜å¾—è¶Šæ¥è¶Šæ™®éï¼Œå°†è¿™äº›å¤§æ¨¡å‹æ“ä½œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæˆ–åœ¨è®¡ç®—è®­ç»ƒæˆ–æ¨æ–­èµ„æºå—é™çš„æ¡ä»¶ä¸‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•æ¥é¢„è®­ç»ƒä¸€ä¸ªæ›´å°çš„é€šç”¨è¯­è¨€è¡¨ç¤ºæ¨¡å‹ DistilBERTï¼Œç„¶åï¼Œè¯¥æ¨¡å‹å¯ä»¥åœ¨å„ç§ä»»åŠ¡ä¸Šè¿›è¡Œè‰¯å¥½çš„æ€§èƒ½å¾®è°ƒï¼Œå°±åƒå®ƒçš„è¾ƒå¤§æ¨¡å‹ä¸€æ ·ã€‚è™½ç„¶å¤§å¤šæ•°ä¹‹å‰çš„å·¥ä½œéƒ½ç ”ç©¶äº†ä½¿ç”¨è’¸é¦æ–¹æ³•æ„å»ºç‰¹å®šä»»åŠ¡æ¨¡å‹çš„ç”¨é€”ï¼Œä½†æˆ‘ä»¬åˆ©ç”¨äº†è’¸é¦çŸ¥è¯†åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œå¹¶æ˜¾ç¤ºä¸€ä¸ª BERT æ¨¡å‹çš„å¤§å°å¯ä»¥å‡å°‘ 40%ï¼Œè€Œå…¶è¯­è¨€ç†è§£èƒ½åŠ›ä¿æŒåœ¨ 97%ï¼Œé€Ÿåº¦æé«˜äº† 60%ã€‚ä¸ºäº†åˆ©ç”¨é¢„è®­ç»ƒæœŸé—´å¤§å‹æ¨¡å‹å­¦ä¹ åˆ°çš„å½’çº³åå·®ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸‰é‡æŸå¤±ï¼Œç»“åˆè¯­è¨€å»ºæ¨¡ã€è’¸é¦å’Œä½™å¼¦ç›¸ä¼¼åº¦æŸå¤±ã€‚æˆ‘ä»¬çš„è¾ƒå°ã€æ›´å¿«å’Œæ›´è½»çš„æ¨¡å‹æ›´ä¾¿å®œè¿›è¡Œé¢„è®­ç»ƒï¼Œæˆ‘ä»¬åœ¨æ¦‚å¿µéªŒè¯å®éªŒå’Œè¾¹ç¼˜è®¾å¤‡çš„æ¯”è¾ƒç ”ç©¶ä¸­è¯æ˜äº†å®ƒçš„èƒ½åŠ›ã€‚*

æç¤ºï¼š

- DistilBERT æ¨¡å‹æ²¡æœ‰ `token_type_ids`ï¼Œä½ ä¸éœ€è¦æŒ‡ç¤ºå“ªä¸ªæ ‡è®°å±äºå“ªä¸ªç‰‡æ®µã€‚åªéœ€ä½¿ç”¨åˆ†éš”æ ‡è®° `tokenizer.sep_token`ï¼ˆæˆ– `[SEP]`ï¼‰å°†ç‰‡æ®µåˆ†å¼€å³å¯ã€‚
- DistilBERT æ¨¡å‹æ²¡æœ‰é€‰æ‹©è¾“å…¥ä½ç½®çš„é€‰é¡¹ï¼ˆ`position_ids` è¾“å…¥ï¼‰ã€‚å¦‚æœéœ€è¦ï¼Œå¯ä»¥æ·»åŠ è¯¥é€‰é¡¹ï¼Œåªéœ€è®©æˆ‘ä»¬çŸ¥é“ä½ æ˜¯å¦éœ€è¦ã€‚
- ä¸ BERT ç›¸åŒä½†æ›´å°ã€‚é€šè¿‡å¯¹é¢„è®­ç»ƒçš„ BERT æ¨¡å‹è¿›è¡Œè’¸é¦è®­ç»ƒï¼Œè¿™æ„å‘³ç€å®ƒè¢«è®­ç»ƒä¸ºé¢„æµ‹ä¸è¾ƒå¤§æ¨¡å‹ç›¸åŒçš„æ¦‚ç‡ã€‚å®é™…ç›®æ ‡æ˜¯ï¼š

    * æä¾›ä¸æ•™å¸ˆæ¨¡å‹ç›¸åŒçš„æ¦‚ç‡
    * æ­£ç¡®é¢„æµ‹è¢«æ©ç çš„æ ‡è®°ï¼ˆä½†æ²¡æœ‰ä¸‹ä¸€ä¸ªå¥å­çš„ä»»åŠ¡ï¼‰
    * å­¦ç”Ÿæ¨¡å‹çš„éšè—çŠ¶æ€ä¸æ•™å¸ˆæ¨¡å‹çš„éšè—çŠ¶æ€ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦

æ­¤æ¨¡å‹æ˜¯ç”± [victorsanh](https://huggingface.co/victorsanh) è´¡çŒ®çš„ã€‚æ­¤æ¨¡å‹ jax ç‰ˆæœ¬ç”± [kamalkraj](https://huggingface.co/kamalkraj) è´¡çŒ®çš„ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨ [è¿™é‡Œ](https://github.com/huggingface/transformers/tree/main/examples/research_projects/distillation) æ‰¾åˆ°ã€‚

## èµ„æº

ä»¥ä¸‹æ˜¯å®˜æ–¹ Hugging Face å’Œç¤¾åŒºï¼ˆç”± ğŸŒ æ ‡è®°ï¼‰èµ„æºåˆ—è¡¨ï¼Œå¯å¸®åŠ©ä½ å¼€å§‹ä½¿ç”¨ DistilBERTã€‚å¦‚æœä½ æœ‰å…´è¶£æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æå‡ºæ‹‰å–è¯·æ±‚ï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æ ¸ï¼èµ„æºæœ€å¥½åº”è¯¥å±•ç¤ºä¸€äº›æ–°çš„ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰çš„èµ„æºã€‚

<PipelineTag pipeline="text-classification"/>

- ä¸€ç¯‡å…³äºä½¿ç”¨ Python è¿›è¡Œæƒ…æ„Ÿåˆ†æçš„åšå®¢æ–‡ç«  [Getting Started with Sentiment Analysis using Python](https://huggingface.co/blog/sentiment-analysis-python)ã€‚
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ Blurr è¿›è¡Œ DistilBERT åºåˆ—åˆ†ç±»è®­ç»ƒçš„åšå®¢æ–‡ç«  [train DistilBERT with Blurr for sequence classification](https://huggingface.co/blog/fastai)ã€‚
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ Ray æ¥è°ƒæ•´ DistilBERT è¶…å‚æ•°çš„åšå®¢æ–‡ç«  [train DistilBERT with Ray for hyperparameter tuning](https://huggingface.co/blog/ray-tune)ã€‚
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ Hugging Face å’Œ Amazon SageMaker æ¥è®­ç»ƒ DistilBERT çš„åšå®¢æ–‡ç«  [train DistilBERT with Hugging Face and Amazon SageMaker](https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face)ã€‚
- ä¸€ç¯‡å…³äºå¦‚ä½•å¯¹å¤šæ ‡ç­¾åˆ†ç±»è¿›è¡Œ DistilBERT å¾®è°ƒçš„ç¬”è®°æœ¬ [finetune DistilBERT for multi-label classification](https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb)ã€‚ğŸŒ
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ PyTorch å¯¹å¤šç±»åˆ«åˆ†ç±»è¿›è¡Œ DistilBERT å¾®è°ƒçš„ç¬”è®°æœ¬ [finetune DistilBERT for multiclass classification with PyTorch](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb)ã€‚ğŸŒ
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ TensorFlow å¯¹æ–‡æœ¬åˆ†ç±»è¿›è¡Œ DistilBERT å¾®è°ƒçš„ç¬”è®°æœ¬ [finetune DistilBERT for text classification in TensorFlow](https://colab.research.google.com/github/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb)ã€‚ğŸŒ
- [`DistilBertForSequenceClassification`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`TFDistilBertForSequenceClassification`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/text-classification) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification-tf.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`FlaxDistilBertForSequenceClassification`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/flax/text-classification) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification_flax.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [åºåˆ—åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/sequence_classification)

<PipelineTag pipeline="token-classification"/>

- [`DistilBertForTokenClassification`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/pytorch/token-classification) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`TFDistilBertForTokenClassification`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/token-classification) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`FlaxDistilBertForTokenClassification`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/flax/token-classification) ä¸­æ‰¾åˆ°ã€‚
- [ğŸ¤— Hugging Face è¯¾ç¨‹ä¸­çš„æ ‡è®°åˆ†ç±»](https://huggingface.co/course/chapter7/2?fw=pt) ç« èŠ‚ã€‚
- [æ ‡è®°åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/token_classification)

<PipelineTag pipeline="fill-mask"/>

- [`DistilBertForMaskedLM`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling#robertabertdistilbert-and-masked-language-modeling) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`TFDistilBertForMaskedLM`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/language-modeling#run_mlmpy) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`FlaxDistilBertForMaskedLM`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#masked-language-modeling) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/masked_language_modeling_flax.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [ğŸ¤— Hugging Face è¯¾ç¨‹ä¸­çš„æ©ç è¯­è¨€å»ºæ¨¡](https://huggingface.co/course/chapter7/3?fw=pt) ç« èŠ‚ã€‚
- [æ©ç è¯­è¨€å»ºæ¨¡ä»»åŠ¡æŒ‡å—](../tasks/masked_language_modeling)

<PipelineTag pipeline="question-answering"/>

- [`DistilBertForQuestionAnswering`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`TFDistilBertForQuestionAnswering`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/question-answering) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`FlaxDistilBertForQuestionAnswering`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/flax/question-answering) ä¸­æ‰¾åˆ°ã€‚
- [ğŸ¤— Hugging Face è¯¾ç¨‹ä¸­çš„é—®ç­”](https://huggingface.co/course/chapter7/7?fw=pt) ç« èŠ‚ã€‚
- [é—®ç­”ä»»åŠ¡æŒ‡å—](../tasks/question_answering)

**å¤šé€‰é¢˜**
- [`DistilBertForMultipleChoice`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/pytorch/multiple-choice) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [`TFDistilBertForMultipleChoice`] çš„ç¤ºä¾‹è„šæœ¬å¯åœ¨æ­¤ [é“¾æ¥](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/multiple-choice) å’Œ [ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb) ä¸­æ‰¾åˆ°ã€‚
- [å¤šé€‰é¢˜ä»»åŠ¡æŒ‡å—](../tasks/multiple_choice)

âš—ï¸ ä¼˜åŒ–

- ä¸€ç¯‡å…³äºå¦‚ä½•åˆ©ç”¨ ğŸ¤— Optimum å’Œ Intel å¯¹ DistilBERT è¿›è¡Œé‡åŒ–çš„åšå®¢æ–‡ç«  [quantize DistilBERT with ğŸ¤— Optimum and Intel](https://huggingface.co/blog/intel)ã€‚
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ ğŸ¤— Optimum ä¼˜åŒ– GPU ä¸Šçš„ Transformers çš„åšå®¢æ–‡ç«  [Optimizing Transformers for GPUs with ğŸ¤— Optimum](https://www.philschmid.de/optimizing-transformers-with-optimum-gpu)ã€‚
- ä¸€ç¯‡å…³äºä½¿ç”¨ Hugging Face Optimum ä¼˜åŒ– Transformers çš„åšå®¢æ–‡ç«  [Optimizing Transformers with Hugging Face Optimum](https://www.philschmid.de/optimizing-transformers-with-optimum)ã€‚

âš¡ï¸ æ¨ç†

- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ Hugging Face Transformers å’Œ AWS Inferentia åŠ é€Ÿ BERT æ¨ç†çš„åšå®¢æ–‡ç«  [Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia](https://huggingface.co/blog/bert-inferentia-sagemaker)ï¼Œä½¿ç”¨ DistilBERTã€‚
- ä¸€ç¯‡å…³äº [ä½¿ç”¨ Hugging Face çš„ Transformersã€DistilBERT å’Œ Amazon SageMaker è¿›è¡Œæ— æœåŠ¡å™¨æ¨ç†](https://www.philschmid.de/sagemaker-serverless-huggingface-distilbert) çš„åšå®¢æ–‡ç« ã€‚

ğŸš€ éƒ¨ç½²

- ä¸€ç¯‡å…³äºå¦‚ä½•åœ¨ Google Cloud ä¸Šéƒ¨ç½² DistilBERT çš„åšå®¢æ–‡ç«  [deploy DistilBERT on Google Cloud](https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds)ã€‚
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ Amazon SageMaker éƒ¨ç½² DistilBERT çš„åšå®¢æ–‡ç«  [deploy DistilBERT with Amazon SageMaker](https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker)ã€‚
- ä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨ Hugging Face Transformersã€Amazon SageMaker å’Œ Terraform æ¨¡å—éƒ¨ç½² BERT çš„åšå®¢æ–‡ç«  [Deploy BERT with Hugging Face Transformers, Amazon SageMaker and Terraform module](https://www.philschmid.de/terraform-huggingface-amazon-sagemaker)ã€‚

## DistilBertConfig

[[autodoc]] DistilBertConfig

## DistilBertTokenizer

[[autodoc]] DistilBertTokenizer

## DistilBertTokenizerFast

[[autodoc]] DistilBertTokenizerFast

## DistilBertModel

[[autodoc]] DistilBertModel
    - forward

## DistilBertForMaskedLM

[[autodoc]] DistilBertForMaskedLM
    - forward

## DistilBertForSequenceClassification

[[autodoc]] DistilBertForSequenceClassification
    - forward

## DistilBertForMultipleChoice

[[autodoc]] DistilBertForMultipleChoice
    - forward

## DistilBertForTokenClassification

[[autodoc]] DistilBertForTokenClassification
    - forward

## DistilBertForQuestionAnswering

[[autodoc]] DistilBertForQuestionAnswering
    - forward

## TFDistilBertModel

[[autodoc]] TFDistilBertModel
    - call

## TFDistilBertForMaskedLM

[[autodoc]] TFDistilBertForMaskedLM
    - call

## TFDistilBertForSequenceClassification

[[autodoc]] TFDistilBertForSequenceClassification
    - call

## TFDistilBertForMultipleChoice

[[autodoc]] TFDistilBertForMultipleChoice
    - call

## TFDistilBertForTokenClassification

[[autodoc]] TFDistilBertForTokenClassification
    - call

## TFDistilBertForQuestionAnswering

[[autodoc]] TFDistilBertForQuestionAnswering
    - call

## FlaxDistilBertModel

[[autodoc]] FlaxDistilBertModel
    - __call__

## FlaxDistilBertForMaskedLM

[[autodoc]] FlaxDistilBertForMaskedLM
    - __call__

## FlaxDistilBertForSequenceClassification

[[autodoc]] FlaxDistilBertForSequenceClassification
    - __call__

## FlaxDistilBertForMultipleChoice

[[autodoc]] FlaxDistilBertForMultipleChoice
    - __call__

## FlaxDistilBertForTokenClassification

[[autodoc]] FlaxDistilBertForTokenClassification
    - __call__

## FlaxDistilBertForQuestionAnswering

[[autodoc]] FlaxDistilBertForQuestionAnswering
    - __call__