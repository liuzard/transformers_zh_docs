ç‰ˆæƒæ‰€æœ‰2023å¹´The HuggingFaceå›¢é˜Ÿã€‚Apacheè®¸å¯è¯ç¬¬2.0ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰è®¸å¯ï¼Œé™¤éç¬¦åˆè®¸å¯è¯çš„è¦æ±‚,å¦åˆ™ä½ ä¸èƒ½ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚ä½ å¯ä»¥è·å–è®¸å¯è¯çš„å‰¯æœ¬ã€‚http://www.apache.org/licenses/LICENSE-2.0 unless You may obtain a copy of the License atã€‚è®¸å¯è¯è¦æ±‚é€‚ç”¨æ³•å¾‹æˆ–ä»¥ä¹¦é¢å½¢å¼åŒæ„ï¼Œç»æˆæƒåˆ†å‘è½¯ä»¶ä»…ä»¥â€œåªæ˜¯â€ä¸ºåŸºç¡€ï¼Œä¸é™„å¸¦ä»»ä½•ä¿è¯æˆ–æ¡ä»¶ã€‚è¯·å‚é˜…è®¸å¯ä»¥äº†è§£ç‰¹å®šè¯­è¨€ä¸‹è®¸å¯è¯çš„é™åˆ¶å’Œè§„å®šã€‚âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶æ˜¯Markdownæ ¼å¼ï¼Œä½†åŒ…å«æˆ‘ä»¬doc-builder(ç±»ä¼¼äºMDX)çš„ç‰¹å®šè¯­æ³•ï¼Œå¯èƒ½åœ¨ä½ çš„Markdownè§†å›¾å™¨ä¸­æ— æ³•æ­£ç¡®æ¸²æŸ“çš„å†…å®¹ã€‚

# MMS

## æ¦‚è¿°

[MMSæ¨¡å‹](https://arxiv.org/abs/2305.13516)(å°†è¯­éŸ³æŠ€æœ¯æ‰©å±•åˆ°1000å¤šç§è¯­è¨€)ç”±Vineel Pratapã€Andros Tjandraã€Bowen Shiã€Paden Tomaselloã€Arun Babuã€Sayani Kunduã€Ali Elkahkyã€Zhaoheng Niã€Apoorv Vyasã€Maryam Fazel-Zarandiã€Alexei Baevskiã€Yossiadã€Xiaohui Zhangã€Wei-Ning Hsuã€Alexis Conneauã€Michael Auliæå‡ºã€‚

æ¥è‡ªè¯¥è®ºæ–‡çš„æ‘˜è¦å¦‚ä¸‹ï¼š

æ‰©å¤§è¯­éŸ³æŠ€æœ¯çš„è¯­è¨€è¦†ç›–é¢ï¼Œå¯ä»¥æé«˜æ›´å¤šçš„äººè·å–ä¿¡æ¯ã€‚ç„¶è€Œï¼Œå½“å‰çš„è¯­éŸ³æŠ€æœ¯ä»…é™äºçº¦100ç§è¯­è¨€ï¼Œè¿™åªæ˜¯ä¸–ç•Œä¸Šçº¦7000ç§è¯­è¨€çš„ä¸€å°éƒ¨åˆ†ã€‚å¤§è§„æ¨¡å¤šè¯­è¨€è¯­éŸ³(MMS)é¡¹ç›®å°†æ”¯æŒçš„è¯­è¨€æ•°é‡å¢åŠ äº†10-40å€ï¼Œå…·ä½“å–å†³äºä»»åŠ¡ã€‚ä¸»è¦æˆåˆ†æ˜¯åŸºäºå…¬å¼€å¯ç”¨å®—æ•™æ–‡æœ¬çš„é˜…è¯»çš„æ–°æ•°æ®é›†ï¼Œä»¥åŠæœ‰æ•ˆåˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ ã€‚æˆ‘ä»¬æ„å»ºäº†é¢„è®­ç»ƒçš„wav2vec 2.0æ¨¡å‹ï¼Œè¦†ç›–äº†1406ç§è¯­è¨€ï¼Œä¸€ç§æ”¯æŒ1107ç§è¯­è¨€çš„å•ä¸€å¤šè¯­è¨€è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œä¸ºç›¸åŒæ•°é‡çš„è¯­è¨€å»ºç«‹äº†è¯­éŸ³åˆæˆæ¨¡å‹ï¼Œä»¥åŠä¸€ç§æ”¯æŒ4017ç§è¯­è¨€çš„è¯­è¨€è¯†åˆ«æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„å¤šè¯­éŸ³è¯†åˆ«æ¨¡å‹åœ¨"FLEURSåŸºå‡†æµ‹è¯•"çš„54ç§è¯­è¨€çš„"Whisper"çš„å•è¯é”™è¯¯ç‡ä¸‹é™50%ï¼Œè€Œç»ƒä¹ æ—¶ï¼Œåªæ˜¯ä½¿ç”¨äº†ä¸€å°éƒ¨åˆ†æ ‡è®°æ•°æ®ã€‚

ä¸‹é¢æ˜¯MMSé¡¹ç›®ä¸­å¼€æºçš„ä¸åŒæ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å’Œä»£ç æœ€åˆåœ¨[è¿™é‡Œ](https://github.com/facebookresearch/fairseq/tree/main/examples/mms)å‘å¸ƒã€‚æˆ‘ä»¬å°†å®ƒä»¬æ·»åŠ åˆ°äº†`transformers`æ¡†æ¶ä¸­ï¼Œä½¿å®ƒä»¬æ›´å®¹æ˜“ä½¿ç”¨ã€‚

### è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)

ASRæ¨¡å‹æ£€æŸ¥ç‚¹å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ï¼š[mms-1b-fl102](https://huggingface.co/facebook/mms-1b-fl102), [mms-1b-l1107](https://huggingface.co/facebook/mms-1b-l1107), [mms-1b-all](https://huggingface.co/facebook/mms-1b-all)ã€‚ä¸ºäº†è·å¾—æœ€ä½³å‡†ç¡®æ€§ï¼Œä½¿ç”¨`mms-1b-all`æ¨¡å‹ã€‚

æç¤ºï¼š

- æ‰€æœ‰ASRæ¨¡å‹éƒ½æ¥å—ä¸è¯­éŸ³ä¿¡å·çš„åŸå§‹æ³¢å½¢å¯¹åº”çš„æµ®ç‚¹æ•°æ•°ç»„ã€‚åŸå§‹æ³¢å½¢åº”ä½¿ç”¨[`Wav2Vec2FeatureExtractor`]è¿›è¡Œé¢„å¤„ç†ã€‚
- è¿™äº›æ¨¡å‹ä½¿ç”¨è¿æ¥æ—¶é—´åˆ†ç±»(CTC)è¿›è¡Œè®­ç»ƒï¼Œå› æ­¤æ¨¡å‹è¾“å‡ºå¿…é¡»ä½¿ç”¨[`Wav2Vec2CTCTokenizer`]è¿›è¡Œè§£ç ã€‚
- ä½ å¯ä»¥é€šè¿‡[`~Wav2Vec2PreTrainedModel.load_adapter`]ä¸ºä¸åŒçš„è¯­è¨€åŠ è½½ä¸åŒçš„è¯­è¨€é€‚é…å™¨çš„æƒé‡ã€‚è¯­è¨€é€‚é…å™¨åªåŒ…å«å¤§çº¦200ä¸‡ä¸ªå‚æ•°ï¼Œå› æ­¤åœ¨éœ€è¦æ—¶å¯ä»¥é«˜æ•ˆåœ°åŠ¨æ€åŠ è½½ã€‚

#### åŠ è½½

é»˜è®¤æƒ…å†µä¸‹ï¼ŒMMSä»…åŠ è½½è‹±è¯­çš„é€‚é…å™¨æƒé‡ã€‚å¦‚æœä½ æƒ³åŠ è½½å…¶ä»–è¯­è¨€çš„é€‚é…å™¨æƒé‡ï¼Œè¯·ç¡®ä¿åŒæ—¶æŒ‡å®š`target_lang=<ä½ é€‰æ‹©çš„ç›®æ ‡è¯­è¨€>`å’Œ`ignore_mismatched_sizes=True`ã€‚è¦å…è®¸æ ¹æ®æŒ‡å®šè¯­è¨€çš„è¯æ±‡è¡¨è°ƒæ•´è¯­è¨€æ¨¡å‹å¤´çš„å¤§å°ï¼Œå¿…é¡»ä¼ é€’`ignore_mismatched_sizes=True`å…³é”®å­—ã€‚åŒæ ·ï¼Œå¤„ç†å™¨åº”è¯¥ä½¿ç”¨ç›¸åŒçš„ç›®æ ‡è¯­è¨€åŠ è½½ã€‚

```py
from transformers import Wav2Vec2ForCTC, AutoProcessor

model_id = "facebook/mms-1b-all"
target_lang = "fra"

processor = AutoProcessor.from_pretrained(model_id, target_lang=target_lang)
model = Wav2Vec2ForCTC.from_pretrained(model_id, target_lang=target_lang, ignore_mismatched_sizes=True)
```

<Tip>

ä½ å¯ä»¥å®‰å…¨åœ°å¿½ç•¥å¦‚ä¸‹è­¦å‘Šï¼š

```text
Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/mms-1b-all and are newly initialized because the shapes did not match:
- lm_head.bias: found shape torch.Size([154]) in the checkpoint and torch.Size([314]) in the model instantiated
- lm_head.weight: found shape torch.Size([154, 1280]) in the checkpoint and torch.Size([314, 1280]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
```

</Tip>

å¦‚æœä½ æƒ³ä½¿ç”¨ASRæµæ°´çº¿ï¼Œå¯ä»¥åƒè¿™æ ·åŠ è½½æ‰€é€‰çš„ç›®æ ‡è¯­è¨€ï¼š

```py
from transformers import pipeline

model_id = "facebook/mms-1b-all"
target_lang = "fra"

pipe = pipeline(model=model_id, model_kwargs={"target_lang": "fra", "ignore_mismatched_sizes": True})
```

#### æ¨ç†

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨æ¨ç†ä¸­è¿è¡ŒMMSå¹¶åœ¨è°ƒç”¨[`~PretrainedModel.from_pretrained`]ä¹‹åæ›´æ”¹é€‚é…å™¨å±‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨[Datasets](https://github.com/huggingface/datasets)åŠ è½½ä¸åŒè¯­è¨€çš„éŸ³é¢‘æ•°æ®ã€‚

```py
from datasets import load_dataset, Audio

# è‹±è¯­
stream_data = load_dataset("mozilla-foundation/common_voice_13_0", "en", split="test", streaming=True)
stream_data = stream_data.cast_column("audio", Audio(sampling_rate=16000))
en_sample = next(iter(stream_data))["audio"]["array"]

# æ³•è¯­
stream_data = load_dataset("mozilla-foundation/common_voice_13_0", "fr", split="test", streaming=True)
stream_data = stream_data.cast_column("audio", Audio(sampling_rate=16000))
fr_sample = next(iter(stream_data))["audio"]["array"]
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨ã€‚

```py
from transformers import Wav2Vec2ForCTC, AutoProcessor
import torch

model_id = "facebook/mms-1b-all"

processor = AutoProcessor.from_pretrained(model_id)
model = Wav2Vec2ForCTC.from_pretrained(model_id)
```

ç°åœ¨æˆ‘ä»¬å¤„ç†éŸ³é¢‘æ•°æ®ï¼Œå°†å¤„ç†åçš„éŸ³é¢‘æ•°æ®ä¼ é€’ç»™æ¨¡å‹å¹¶è½¬å½•æ¨¡å‹è¾“å‡ºï¼Œå°±åƒæˆ‘ä»¬é€šå¸¸å¤„ç†[`Wav2Vec2ForCTC`]ä¸€æ ·ã€‚

```py
inputs = processor(en_sample, sampling_rate=16_000, return_tensors="pt")

with torch.no_grad():
    outputs = model(**inputs).logits

ids = torch.argmax(outputs, dim=-1)[0]
transcription = processor.decode(ids)
# 'joe keton disapproved of films and buster also had reservations about the media'
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†ç›¸åŒçš„æ¨¡å‹ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œåªéœ€è°ƒç”¨æ¨¡å‹çš„æ–¹ä¾¿çš„[`~Wav2Vec2ForCTC.load_adapter`]åŠŸèƒ½ï¼Œä»¥åŠä»¤ç‰Œå™¨çš„[`~Wav2Vec2CTCTokenizer.set_target_lang`]åŠŸèƒ½ æ¥æ›´æ”¹è¯­è¨€é€‚é…å™¨ã€‚æˆ‘ä»¬å°†ç›®æ ‡è¯­è¨€ä½œä¸ºè¾“å…¥ä¼ é€’ç»™å®ƒï¼Œå¯¹äºæ³•è¯­æ˜¯`"fra"`ã€‚

```py
processor.tokenizer.set_target_lang("fra")
model.load_adapter("fra")

inputs = processor(fr_sample, sampling_rate=16_000, return_tensors="pt")

with torch.no_grad():
    outputs = model(**inputs).logits

ids = torch.argmax(outputs, dim=-1)[0]
transcription = processor.decode(ids)
# "ce dernier est volÃ© tout au long de l'histoire romaine"
```

åŒæ ·ï¼Œå¯ä»¥ä¸ºæ‰€æœ‰å…¶ä»–æ”¯æŒçš„è¯­è¨€åˆ‡æ¢è¯­è¨€ã€‚è¯·æŸ¥çœ‹ï¼š

```py
processor.tokenizer.vocab.keys()
```

ä»¥æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„è¯­è¨€ã€‚

è¦è¿›ä¸€æ­¥æ”¹å–„ASRæ¨¡å‹çš„æ€§èƒ½ï¼Œå¯ä»¥ä½¿ç”¨è¯­è¨€æ¨¡å‹è§£ç ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹[æ­¤å¤„](https://huggingface.co/facebook/mms-1b-all)çš„æ–‡æ¡£ã€‚

### è¯­éŸ³åˆæˆï¼ˆTTSï¼‰

MMS-TTSä½¿ç”¨ä¸VITSç›¸åŒçš„æ¨¡å‹æ¶æ„ï¼Œè¯¥æ¨¡å‹æ¶æ„åœ¨v4.33ä¸­æ·»åŠ åˆ°äº†ğŸ¤— Transformers ã€‚MMSä¸ºé¡¹ç›®ä¸­çš„1100å¤šç§è¯­è¨€è®­ç»ƒäº†å•ç‹¬çš„æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚æ‰€æœ‰å¯ç”¨æ£€æŸ¥ç‚¹éƒ½å¯ä»¥åœ¨Hugging Face Hubä¸Šæ‰¾åˆ°ï¼š[facebook/mms-tts](https://huggingface.co/models?sort=trending&search=facebook%2Fmms-tts)ï¼Œæ¨ç†æ–‡æ¡£åœ¨[VITS](https://huggingface.co/docs/transformers/main/en/model_doc/vits)ä¸‹ã€‚

#### æ¨ç†

è¦ä½¿ç”¨MMSæ¨¡å‹ï¼Œé¦–å…ˆè¯·ç¡®ä¿å°†Transformersåº“å‡çº§åˆ°æœ€æ–°ç‰ˆæœ¬ï¼š

```bash
pip install --upgrade transformers accelerate
```

ç”±äºVITSä¸­çš„åŸºäºæµçš„æ¨¡å‹æ˜¯éç¡®å®šæ€§çš„ï¼Œä¸ºäº†ç¡®ä¿è¾“å‡ºçš„å¯é‡å¤æ€§ï¼Œæœ€å¥½è®¾ç½®ä¸€ä¸ªç§å­ã€‚

- å¯¹äºå…·æœ‰ç½—é©¬å­—æ¯çš„è¯­è¨€ï¼ˆå¦‚è‹±è¯­æˆ–æ³•è¯­ï¼‰ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ä»¤ç‰Œå™¨å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ã€‚ä»¥ä¸‹ä»£ç ç¤ºä¾‹è¿è¡Œäº†ä½¿ç”¨MMS-TTSè‹±è¯­æ£€æŸ¥ç‚¹çš„æ­£å‘ä¼ é€’ï¼š

```python
import torch
from transformers import VitsTokenizer, VitsModel, set_seed

tokenizer = VitsTokenizer.from_pretrained("facebook/mms-tts-eng")
model = VitsModel.from_pretrained("facebook/mms-tts-eng")

inputs = tokenizer(text="Hello - my dog is cute", return_tensors="pt")

set_seed(555)  # è®©å…¶å…·æœ‰ç¡®å®šæ€§

with torch.no_grad():
   outputs = model(**inputs)

waveform = outputs.waveform[0]
```

ç”Ÿæˆçš„æ³¢å½¢å¯ä»¥ä¿å­˜ä¸º`.wav`æ–‡ä»¶ï¼š

```python
import scipy

scipy.io.wavfile.write("synthesized_speech.wav", rate=model.config.sampling_rate, data=waveform)
```

æˆ–åœ¨Jupyter Notebook / Google Colabä¸­æ˜¾ç¤ºï¼š

```python
from IPython.display import Audio

Audio(waveform, rate=model.config.sampling_rate)
```

å¯¹äºæŸäº›å…·æœ‰éç½—é©¬å­—æ¯æ–¹æ¡ˆï¼ˆå¦‚é˜¿æ‹‰ä¼¯è¯­ã€æ±‰è¯­æˆ–å°åœ°è¯­ï¼‰çš„è¯­è¨€ï¼Œéœ€è¦[`uroman`](https://github.com/isi-nlp/uroman)Perlè½¯ä»¶åŒ…æ¥å¯¹æ–‡æœ¬è¾“å…¥è¿›è¡Œé¢„å¤„ç†ï¼Œå°†æ–‡å­—è½¬æ¢ä¸ºç½—é©¬å­—æ¯ã€‚

ä½ å¯ä»¥é€šè¿‡æ£€æŸ¥é¢„è®­ç»ƒä»¤ç‰Œå™¨çš„`is_uroman`å±æ€§æ¥ç¡®å®šä½ çš„è¯­è¨€æ˜¯å¦éœ€è¦`uroman`è½¯ä»¶åŒ…ï¼š

```python
from transformers import VitsTokenizer

tokenizer = VitsTokenizer.from_pretrained("facebook/mms-tts-eng")
print(tokenizer.is_uroman)
```

å¦‚æœéœ€è¦ï¼Œä½ åº”è¯¥åœ¨å°†æ–‡æœ¬è¾“å…¥ä¼ é€’ç»™`VitsTokenizer`ä¹‹å‰ï¼Œå…ˆå°†uromanè½¯ä»¶åŒ…åº”ç”¨äºä½ çš„æ–‡æœ¬è¾“å…¥ã€‚å› ä¸ºç›®å‰ä»¤ç‰Œå™¨ä¸æ”¯æŒæ‰§è¡Œé¢„å¤„ç†æœ¬èº«ã€‚

è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œé¦–å…ˆå°†uromanå­˜å‚¨åº“å…‹éš†åˆ°æœ¬åœ°è®¡ç®—æœºï¼Œå¹¶å°†bashå˜é‡`UROMAN`è®¾ç½®ä¸ºæœ¬åœ°è·¯å¾„ï¼š

```bash
git clone https://github.com/isi-nlp/uroman.git
cd uroman
export UROMAN=$(pwd)
```

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç æ®µä½¿ç”¨uromanè½¯ä»¶åŒ…å¯¹æ–‡æœ¬è¾“å…¥è¿›è¡Œé¢„å¤„ç†ã€‚ä½ å¯ä»¥ä¾èµ–ä½¿ç”¨bashå˜é‡`UROMAN`æŒ‡å‘uromanå­˜å‚¨åº“ï¼Œä¹Ÿå¯ä»¥å°†uromanç›®å½•ä½œä¸ºå‚æ•°ä¼ é€’ç»™`uroman`å‡½æ•°ï¼š

```python
import torch
from transformers import VitsTokenizer, VitsModel, set_seed
import os
import subprocess

tokenizer = VitsTokenizer.from_pretrained("facebook/mms-tts-kor")
model = VitsModel.from_pretrained("facebook/mms-tts-kor")

def uromanize(input_string, uroman_path):
    """ä½¿ç”¨`uroman` Perlè½¯ä»¶åŒ…å°†éç½—é©¬å­—æ¯å­—ç¬¦ä¸²è½¬æ¢ä¸ºç½—é©¬å­—æ¯ã€‚"""
    script_path = os.path.join(uroman_path, "bin", "uroman.pl")

    command = ["perl", script_path]

    process = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    # æ‰§è¡Œperlå‘½ä»¤
    stdout, stderr = process.communicate(input=input_string.encode())

    if process.returncode != 0:
        raise ValueError(f"Error {process.returncode}: {stderr.decode()}")

    # ä½œä¸ºå­—ç¬¦ä¸²è¿”å›è¾“å‡ºï¼Œå¹¶è·³è¿‡æœ«å°¾çš„æ¢è¡Œç¬¦
    return stdout.decode()[:-1]

text = "ì´ë´ ë¬´ìŠ¨ ì¼ì´ì•¼"
uromaized_text = uromanize(text, uroman_path=os.environ["UROMAN"])

inputs = tokenizer(text=uromaized_text, return_tensors="pt")

set_seed(555)  # make deterministic
with torch.no_grad():
   outputs = model(inputs["input_ids"])

waveform = outputs.waveform[0]
```

**æç¤ºï¼š**

* MMS-TTSæ£€æŸ¥ç‚¹æ˜¯åœ¨å°å†™ã€æ— æ ‡ç‚¹çš„æ–‡æœ¬ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œ`VitsTokenizer` *å½’ä¸€åŒ–*è¾“å…¥ï¼Œé€šè¿‡åˆ é™¤æ‰€æœ‰å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·ï¼Œä»¥é¿å…å°†æœªç™»å½•å­—ç¬¦ä¼ é€’ç»™æ¨¡å‹ã€‚å› æ­¤ï¼Œæ¨¡å‹ä¸å—å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·çš„å½±å“ï¼Œå› æ­¤åœ¨æ–‡æœ¬æç¤ºä¸­åº”é¿å…ä½¿ç”¨å®ƒä»¬ã€‚ä½ å¯ä»¥é€šè¿‡åœ¨è°ƒç”¨ä»¤ç‰Œå™¨æ—¶è®¾ç½®`noramlize=False`æ¥ç¦ç”¨å½’ä¸€åŒ–ï¼Œä½†è¿™å°†å¯¼è‡´éé¢„æœŸçš„è¡Œä¸ºï¼Œä¸å»ºè®®è¿™æ ·åšã€‚
* é€šè¿‡å°†å±æ€§`model.speaking_rate`è®¾ç½®ä¸ºæ‰€é€‰æ‹©çš„å€¼ï¼Œå¯ä»¥å˜åŒ–è¯´è¯é€Ÿåº¦ã€‚åŒç†ï¼Œå™ªå£°çš„éšæœºæ€§ç”±`model.noise_scale`æ§åˆ¶ã€‚

```python
import torch
from transformers import VitsTokenizer, VitsModel, set_seed

tokenizer = VitsTokenizer.from_pretrained("facebook/mms-tts-eng")
model = VitsModel.from_pretrained("facebook/mms-tts-eng")

inputs = tokenizer(text="Hello - my dog is cute", return_tensors="pt")

# make deterministic
set_seed(555)  

# è°ƒèŠ‚è¯­é€Ÿå’Œå™ªå£°çš„å¹…åº¦
model.speaking_rate = 1.5
model.noise_scale = 0.8

with torch.no_grad():
   outputs = model(**inputs)
```


### è¯­è¨€è¯†åˆ«ï¼ˆLIDï¼‰

æ ¹æ®å®ƒä»¬èƒ½å¤Ÿè¯†åˆ«çš„è¯­è¨€æ•°é‡ï¼Œæä¾›äº†ä¸åŒçš„LIDæ¨¡å‹-[126](https://huggingface.co/facebook/mms-lid-126), [256](https://huggingface.co/facebook/mms-lid-256), [512](https://huggingface.co/facebook/mms-lid-512), [1024](https://huggingface.co/facebook/mms-lid-1024), [2048](https://huggingface.co/facebook/mms-lid-2048), [4017](https://huggingface.co/facebook/mms-lid-4017)ã€‚

#### æ¨ç†
é¦–å…ˆï¼Œæˆ‘ä»¬å®‰è£…transformerså’Œå…¶ä»–ä¸€äº›åº“

```bash
pip install torch accelerate datasets[audio]
pip install --upgrade transformers
````

æ¥ä¸‹æ¥ï¼Œé€šè¿‡`datasets`åŠ è½½ä¸€äº›éŸ³é¢‘æ ·æœ¬ã€‚ç¡®ä¿éŸ³é¢‘æ•°æ®é‡‡æ ·ä¸º16000 kHzã€‚

```py
from datasets import load_dataset, Audio

# è‹±è¯­
stream_data = load_dataset("mozilla-foundation/common_voice_13_0", "en", split="test", streaming=True)
stream_data = stream_data.cast_column("audio", Audio(sampling_rate=16000))
en_sample = next(iter(stream_data))["audio"]["array"]

# é˜¿æ‹‰ä¼¯è¯­
stream_data = load_dataset("mozilla-foundation/common_voice_13_0", "ar", split="test", streaming=True)
stream_data = stream_data.cast_column("audio", Audio(sampling_rate=16000))
ar_sample = next(iter(stream_data))["audio"]["array"]
```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨

```py
from transformers import Wav2Vec2ForSequenceClassification, AutoFeatureExtractor
import torch

model_id = "facebook/mms-lid-126"

processor = AutoFeatureExtractor.from_pretrained(model_id)
model = Wav2Vec2ForSequenceClassification.from_pretrained(model_id)
```

ç°åœ¨æˆ‘ä»¬å¤„ç†éŸ³é¢‘æ•°æ®ï¼Œå°†å¤„ç†åçš„éŸ³é¢‘æ•°æ®ä¼ é€’ç»™æ¨¡å‹è¿›è¡Œè¯­è¨€è¯†åˆ«ï¼Œå°±åƒæˆ‘ä»¬é€šå¸¸å¤„ç†è¯¸å¦‚[ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition](https://huggingface.co/harshit345/xlsr-wav2vec-speech-emotion-recognition)çš„Wav2Vec2éŸ³é¢‘åˆ†ç±»æ¨¡å‹ä¸€æ ·ã€‚

```py
# è‹±è¯­
inputs = processor(en_sample, sampling_rate=16_000, return_tensors="pt")

with torch.no_grad():
    outputs = model(**inputs).logits

lang_id = torch.argmax(outputs, dim=-1)[0].item()
detected_lang = model.config.id2label[lang_id]
# 'eng'

# é˜¿æ‹‰ä¼¯è¯­
inputs = processor(ar_sample, sampling_rate=16_000, return_tensors="pt")

ä½¿ç”¨`torch.no_grad()`æ¥ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼š
```python
outputs = model(**inputs).logits

lang_id = torch.argmax(outputs, dim=-1)[0].item()
detected_lang = model.config.id2label[lang_id]
# 'ara'
```

è¦æŸ¥çœ‹æ£€æŸ¥ç‚¹æ”¯æŒçš„æ‰€æœ‰è¯­è¨€ï¼Œå¯ä»¥æŒ‰å¦‚ä¸‹æ–¹å¼æ‰“å°å‡ºè¯­è¨€IDï¼š
```python
processor.id2label.values()
```

### é¢„è®­ç»ƒéŸ³é¢‘æ¨¡å‹

é¢„è®­ç»ƒæ¨¡å‹æœ‰ä¸¤ç§ä¸åŒçš„å¤§å°å¯ç”¨ - [300M](https://huggingface.co/facebook/mms-300m) ï¼Œ[1Bil](https://huggingface.co/facebook/mms-1b)ã€‚æ¨¡å‹çš„æ¶æ„åŸºäºWav2Vec2æ¨¡å‹ï¼Œå› æ­¤å¯ä»¥å‚è€ƒ[Wav2Vec2çš„æ–‡æ¡£é¡µé¢](wav2vec2)äº†è§£å¦‚ä½•ä½¿ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œå„ç§ä¸‹æ¸¸ä»»åŠ¡çš„å¾®è°ƒçš„æ›´å¤šç»†èŠ‚ã€‚