<!--ç‰ˆæƒæ‰€æœ‰2020å¹´HuggingFaceå›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apacheè®¸å¯è¯ç¬¬2ç‰ˆï¼ˆâ€œè®¸å¯è¯â€ï¼‰çš„æ¡æ¬¾ï¼Œé™¤éç¬¦åˆè®¸å¯è¯çš„è§„å®š
ä½ å°†æ— æ³•ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚

ä½ å¯ä»¥è·å¾—è®¸å¯è¯çš„å‰¯æœ¬ï¼Œåœ¨ä¸‹é¢çš„é“¾æ¥ä¸­è·å¾—è¯¥è®¸å¯è¯

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œå¦åˆ™æ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶å°†æŒ‰
â€œæŒ‰åŸæ ·â€åˆ†å¸ƒï¼Œæ²¡æœ‰ä»»ä½•å½¢å¼çš„æ‹…ä¿æˆ–æ¡ä»¶ï¼Œæ— è®ºæ˜¯æ˜ç¤ºè¿˜æ˜¯æš—ç¤ºã€‚æœ‰å…³è®¸å¯ä¸‹çš„ç‰¹å®šè¯­è¨€çš„è¯¦ç»†ä¿¡æ¯
ä½ å¯èƒ½çš„é™åˆ¶ã€‚

âš ï¸è¯·æ³¨æ„ï¼Œæ­¤æ–‡ä»¶é‡‡ç”¨Markdownæ ¼å¼ï¼Œä½†åŒ…å«æˆ‘ä»¬çš„doc-builderçš„ç‰¹å®šè¯­æ³•ï¼ˆç±»ä¼¼äºMDXï¼‰ï¼Œå¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤ºåœ¨ä½ çš„MarkdownæŸ¥çœ‹å™¨ä¸­ã€‚

-->

# å¼€æ”¾äººå·¥æ™ºèƒ½ GPT2

<div class="flex flex-wrap space-x-1">
<a href="https://huggingface.co/models?filter=gpt2">
<img alt="Models" src="https://img.shields.io/badge/All_model_pages-gpt2-blueviolet">
</a>
<a href="https://huggingface.co/spaces/docs-demos/gpt2">
<img alt="Spaces" src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue">
</a>
</div>

## æ¦‚è¿°

OpenAI GPT-2æ¨¡å‹ç”±Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodeiå’ŒIlya Sutskeveræå‡ºï¼Œè¯¦ç»†å†…å®¹è¯·è§[è¯­è¨€æ¨¡å‹æ˜¯æ— ç›‘ç£çš„å¤šä»»åŠ¡å­¦ä¹ å™¨](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)ï¼Œæ¥è‡ª[OpenAI](https://huggingface.co/openai)ã€‚å®ƒæ˜¯ä¸€ä¸ªå› æœï¼ˆå•å‘ï¼‰å˜æ¢å™¨ï¼Œä½¿ç”¨äº†å¾ˆå¤§çš„è¯­æ–™åº“ï¼ˆçº¦40GBçš„æ–‡æœ¬æ•°æ®ï¼‰è¿›è¡Œäº†è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒã€‚

è®ºæ–‡æ‘˜è¦å¦‚ä¸‹ï¼š

*GPT-2æ˜¯ä¸€ä¸ªåŸºäºå˜æ¢å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰15äº¿ä¸ªå‚æ•°ï¼Œä½¿ç”¨åŒ…å«800ä¸‡ä¸ªç½‘é¡µçš„æ•°æ®é›†[1]è¿›è¡Œäº†è®­ç»ƒã€‚GPT-2çš„è®­ç»ƒç›®æ ‡å¾ˆç®€å•ï¼šæ ¹æ®æ–‡æœ¬ä¸­ä¹‹å‰çš„æ‰€æœ‰å•è¯æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚æ•°æ®é›†çš„å¤šæ ·æ€§ä½¿å¾—è¿™ä¸ªç®€å•çš„ç›®æ ‡åŒ…å«äº†è®¸å¤šä»»åŠ¡åœ¨ä¸åŒé¢†åŸŸä¸­çš„è‡ªç„¶ç¤ºèŒƒã€‚ GPT-2æ˜¯GPTçš„ç›´æ¥æ‰©å¤§ï¼Œå‚æ•°æ•°é‡æ˜¯GPTçš„10å€ä»¥ä¸Šï¼Œä½¿ç”¨äº†10å€ä»¥ä¸Šçš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚*

æç¤ºï¼š

- GPT-2æ˜¯ä¸€ä¸ªå…·æœ‰ç»å¯¹ä½ç½®åµŒå…¥çš„æ¨¡å‹ï¼Œå› æ­¤é€šå¸¸å»ºè®®åœ¨å³ä¾§è€Œä¸æ˜¯å·¦ä¾§å¡«å……è¾“å…¥ã€‚
- GPT-2æ˜¯é€šè¿‡å› æœè¯­è¨€å»ºæ¨¡ï¼ˆCLMï¼‰ç›®æ ‡è¿›è¡Œè®­ç»ƒçš„ï¼Œå› æ­¤åœ¨é¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªæ ‡è®°æ—¶å…·æœ‰å¼ºå¤§çš„èƒ½åŠ›ã€‚åˆ©ç”¨è¿™ä¸ªç‰¹æ€§ï¼ŒGPT-2èƒ½å¤Ÿç”Ÿæˆå¥æ³•è¿è´¯çš„æ–‡æœ¬ï¼Œå¯ä»¥åœ¨*run_generation.py*ç¤ºä¾‹è„šæœ¬ä¸­è§‚å¯Ÿåˆ°ã€‚
- è¯¥æ¨¡å‹å¯ä»¥æ¥å—*past_key_values*ï¼ˆå¯¹äºPyTorchï¼‰æˆ–*past*ï¼ˆå¯¹äºTFï¼‰ä½œä¸ºè¾“å…¥ï¼Œå…¶ä¸­åŒ…å«ä¹‹å‰è®¡ç®—çš„é”®/å€¼æ³¨æ„å¯¹ã€‚ä½¿ç”¨è¿™ä¸ªï¼ˆ*past_key_values*æˆ–*past*ï¼‰å€¼å¯ä»¥é˜²æ­¢æ¨¡å‹åœ¨æ–‡æœ¬ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ä¸­é‡æ–°è®¡ç®—å·²é¢„å…ˆè®¡ç®—çš„å€¼ã€‚æœ‰å…³ä½¿ç”¨è¯´æ˜ï¼Œè¯·å‚é˜…PyTorchçš„[`GPT2Model.forward`]æ–¹æ³•çš„*past_key_values*å‚æ•°ï¼Œæˆ–TFçš„[`TFGPT2Model.call`]æ–¹æ³•çš„*past*å‚æ•°ã€‚
- å¯ç”¨*scale_attn_by_inverse_layer_idx*å’Œ*reorder_and_upcast_attn*æ ‡å¿—å°†åº”ç”¨[Mistral](https://github.com/stanford-crfm/mistral/)çš„è®­ç»ƒç¨³å®šæ€§æ”¹è¿›ï¼ˆä»…é€‚ç”¨äºPyTorchï¼‰ã€‚

[Write With Transformer](https://transformer.huggingface.co/doc/gpt2-large)æ˜¯ç”±Hugging Faceåˆ›å»ºå’Œæ‰˜ç®¡çš„ç½‘é¡µåº”ç”¨ç¨‹åºï¼Œå±•ç¤ºäº†å¤šä¸ªæ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚GPT-2æ˜¯å…¶ä¸­ä¹‹ä¸€ï¼Œæœ‰äº”ä¸ªä¸åŒçš„å¤§å°å¯ç”¨ï¼šsmallï¼Œmediumï¼Œlargeï¼Œxlä»¥åŠsmallæ¨¡å‹çš„è’¸é¦ç‰ˆæœ¬ï¼š*distilgpt-2*ã€‚

æ­¤æ¨¡å‹ç”±[thomwolf](https://huggingface.co/thomwolf)è´¡çŒ®ã€‚åŸå§‹ä»£ç å¯ä»¥åœ¨[è¿™é‡Œ](https://openai.com/blog/better-language-models/)æ‰¾åˆ°ã€‚

## èµ„æº

ä»¥ä¸‹æ˜¯å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒè¡¨ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œä»¥å¸®åŠ©ä½ å¼€å§‹ä½¿ç”¨GPT2ã€‚å¦‚æœä½ å¸Œæœ›æäº¤èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶æäº¤Pull Requestï¼Œæˆ‘ä»¬å°†è¿›è¡Œå®¡æ ¸ï¼èµ„æºåº”è¯¥æ˜¯æ–°é¢–çš„ï¼Œè€Œä¸æ˜¯é‡å¤çš„ç°æœ‰èµ„æºã€‚

<PipelineTag pipeline="text-generation"/>

- ä¸€ç¯‡åšå®¢ä»‹ç»å¦‚ä½•[ä½¿ç”¨Hugging Faceå¯¹éè‹±è¯­GPT-2æ¨¡å‹è¿›è¡Œå¾®è°ƒ](https://www.philschmid.de/fine-tune-a-non-english-gpt-2-model-with-huggingface)ã€‚
- ä¸€ç¯‡ä»‹ç»[å¦‚ä½•ç”Ÿæˆæ–‡æœ¬ï¼šä½¿ç”¨Transformersçš„ä¸åŒè§£ç æ–¹æ³•è¿›è¡Œè¯­è¨€ç”Ÿæˆ](https://huggingface.co/blog/how-to-generate)çš„åšå®¢ï¼Œå…¶ä¸­åŒ…æ‹¬GPT-2ã€‚
- ä¸€ç¯‡å…³äº[ä»é›¶å¼€å§‹è®­ç»ƒCodeParrot ğŸ¦œ](https://huggingface.co/blog/codeparrot)çš„å¤§å‹GPT-2æ¨¡å‹çš„åšå®¢ã€‚
- ä¸€ç¯‡å…³äº[å¦‚ä½•ä½¿ç”¨TensorFlowå’ŒXLAå¿«é€Ÿç”Ÿæˆæ–‡æœ¬](https://huggingface.co/blog/tf-xla-generate)çš„åšå®¢ï¼Œå…¶ä¸­åŒ…æ‹¬GPT-2ã€‚
- ä¸€ç¯‡å…³äº[å¦‚ä½•ä½¿ç”¨Megatron-LMè®­ç»ƒè¯­è¨€æ¨¡å‹](https://huggingface.co/blog/megatron-training)çš„åšå®¢ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªGPT-2æ¨¡å‹ã€‚
- ä¸€ç¯‡æœ‰å…³[å¦‚ä½•ä½¿ç”¨GPT2å¾®è°ƒç”Ÿæˆä½ æœ€å–œçˆ±çš„è‰ºæœ¯å®¶é£æ ¼çš„æ­Œè¯çš„ç¬”è®°æœ¬](https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb)ã€‚ ğŸŒ
- ä¸€ç¯‡æœ‰å…³[å¦‚ä½•ä½¿ç”¨GPT2å¾®è°ƒç”Ÿæˆä½ æœ€å–œçˆ±çš„Twitterç”¨æˆ·é£æ ¼çš„æ¨æ–‡çš„ç¬”è®°æœ¬](https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb)ã€‚ ğŸŒ
- [å› æœè¯­è¨€æ¨¡å‹](https://huggingface.co/course/en/chapter7/6?fw=pt#training-a-causal-language-model-from-scratch)ä¸€ç« çš„ğŸ¤—Hugging Faceè¯¾ç¨‹ã€‚
- [`GPT2LMHeadModel`]ç”±æ­¤[å› æœè¯­è¨€å»ºæ¨¡ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/language-modeling#gpt-2gpt-and-causal-language-modeling)ã€[æ–‡æœ¬ç”Ÿæˆç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)æ”¯æŒã€‚
- [`TFGPT2LMHeadModel`]ç”±æ­¤[å› æœè¯­è¨€å»ºæ¨¡ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/tensorflow/language-modeling#run_clmpy)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb)æ”¯æŒã€‚
- [`FlaxGPT2LMHeadModel`]ç”±æ­¤[å› æœè¯­è¨€å»ºæ¨¡ç¤ºä¾‹è„šæœ¬](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling#causal-language-modeling)å’Œ[ç¬”è®°æœ¬](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/causal_language_modeling_flax.ipynb)æ”¯æŒã€‚
- [æ–‡æœ¬åˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/sequence_classification)
- [tokenåˆ†ç±»ä»»åŠ¡æŒ‡å—](../tasks/token_classification)
- [å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡æŒ‡å—](../tasks/language_modeling)

## GPT2Config

[[autodoc]] GPT2Config

## GPT2Tokenizer

[[autodoc]] GPT2Tokenizer
    - save_vocabulary

## GPT2TokenizerFast

[[autodoc]] GPT2TokenizerFast

## GPT2ç‰¹å®šçš„è¾“å‡º

[[autodoc]] models.gpt2.modeling_gpt2.GPT2DoubleHeadsModelOutput

[[autodoc]] models.gpt2.modeling_tf_gpt2.TFGPT2DoubleHeadsModelOutput

## GPT2æ¨¡å‹

[[autodoc]] GPT2Model
    - forward

## GPT2LMHeadModel

[[autodoc]] GPT2LMHeadModel
    - forward

## GPT2DoubleHeadsModel

[[autodoc]] GPT2DoubleHeadsModel
    - forward

## GPT2ForQuestionAnswering

[[autodoc]] GPT2ForQuestionAnswering
    - forward

## GPT2ForSequenceClassification

[[autodoc]] GPT2ForSequenceClassification
    - forward

## GPT2ForTokenClassification

[[autodoc]] GPT2ForTokenClassification
    - forward

## TFGPT2Model

[[autodoc]] TFGPT2Model
    - call

## TFGPT2LMHeadModel

[[autodoc]] TFGPT2LMHeadModel
    - call

## TFGPT2DoubleHeadsModel

[[autodoc]] TFGPT2DoubleHeadsModel
    - call

## TFGPT2ForSequenceClassification

[[autodoc]] TFGPT2ForSequenceClassification
    - call

## TFSequenceClassifierOutputWithPast

[[autodoc]] modeling_tf_outputs.TFSequenceClassifierOutputWithPast

## TFGPT2Tokenizer

[[autodoc]] TFGPT2Tokenizer

## FlaxGPT2Model

[[autodoc]] FlaxGPT2Model
    - __call__

## FlaxGPT2LMHeadModel

[[autodoc]] FlaxGPT2LMHeadModel
    - __call__