<!--ç‰ˆæƒÂ© 2022 HuggingFaceå›¢é˜Ÿã€‚ä¿ç•™æ‰€æœ‰æƒåˆ©ã€‚

æ ¹æ®Apache License, Version 2.0è®¸å¯è¯ï¼ˆ"è®¸å¯è¯"ï¼‰è¿›è¡Œè®¸å¯ï¼›é™¤éç¬¦åˆè®¸å¯è¯çš„è¦æ±‚ï¼Œå¦åˆ™ä¸èƒ½ä½¿ç”¨æ­¤æ–‡ä»¶ã€‚ä½ å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€è·å–è®¸å¯è¯çš„å‰¯æœ¬ï¼š

http://www.apache.org/licenses/LICENSE-2.0

é™¤éé€‚ç”¨æ³•å¾‹è¦æ±‚æˆ–ä¹¦é¢åŒæ„ï¼Œæ ¹æ®è®¸å¯è¯åˆ†å‘çš„è½¯ä»¶åŸºäº"æŒ‰åŸæ ·"çš„åŸºç¡€åˆ†å‘ï¼Œæ²¡æœ‰ä»»ä½•æ˜ç¤ºæˆ–æš—ç¤ºçš„ä¿è¯æˆ–æ¡ä»¶ã€‚è¯·å‚é˜…è®¸å¯è¯äº†è§£ç‰¹å®šè¯­è¨€ä¸‹çš„æƒé™å’Œé™åˆ¶ã€‚

âš ï¸æ³¨æ„ï¼Œæ­¤æ–‡ä»¶é‡‡ç”¨Markdownæ ¼å¼ï¼Œä½†åŒ…å«ç‰¹å®šè¯­æ³•ä»¥ç”¨äºæ–‡æ¡£æ„å»ºå™¨ï¼ˆç±»ä¼¼äºMDXï¼‰ï¼Œå¯èƒ½æ— æ³•åœ¨MarkdownæŸ¥çœ‹å™¨ä¸­æ­£ç¡®æ˜¾ç¤ºã€‚-->

# LLaMA

## æ¦‚è¿°

LLaMAæ¨¡å‹æ˜¯ç”±Hugo Touvronã€Thibaut Lavrilã€Gautier Izacardã€Xavier Martinetã€Marie-Anne Lachauxã€TimothÃ©e Lacroixã€Baptiste RoziÃ¨reã€Naman Goyalã€Eric Hambroã€Faisal Azharã€Aurelien Rodriguezã€Armand Joulinã€Edouard Graveå’ŒGuillaume Lampleåœ¨è®ºæ–‡[LLaMAï¼šOpen and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)ä¸­æå‡ºçš„ã€‚ å®ƒæ˜¯ä¸€ä¸ªåŒ…æ‹¬ä»7Båˆ°65Bå‚æ•°çš„åŸºç¡€è¯­è¨€æ¨¡å‹çš„é›†åˆã€‚

è®ºæ–‡ä¸­çš„æ‘˜è¦å¦‚ä¸‹ï¼š

*æˆ‘ä»¬ä»‹ç»äº†LLaMAï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…æ‹¬ä»7Båˆ°65Bå‚æ•°çš„åŸºç¡€è¯­è¨€æ¨¡å‹çš„é›†åˆã€‚æˆ‘ä»¬ä½¿ç”¨å…¬å¼€å¯ç”¨çš„æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œè€Œä¸ä½¿ç”¨ä¸“æœ‰å’Œä¸å¯è®¿é—®çš„æ•°æ®é›†ï¼Œå¹¶è¯æ˜å¯ä»¥è®­ç»ƒå‡ºæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯ï¼ŒLLaMA-13Båœ¨å¤§å¤šæ•°åŸºå‡†æµ‹è¯•ä¸­èƒœè¿‡GPT-3ï¼ˆ175Bï¼‰ï¼ŒLLaMA-65Bä¸æœ€ä½³æ¨¡å‹Chinchilla-70Bå’ŒPaLM-540Bç›¸å½“ã€‚æˆ‘ä»¬å°†æ‰€æœ‰çš„æ¨¡å‹éƒ½å‘å¸ƒç»™ç ”ç©¶ç¤¾åŒºã€‚*

æç¤ºï¼š

- å¯ä»¥é€šè¿‡å¡«å†™[æ­¤è¡¨å•](https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform?usp=send_form)è·å–LLaMAæ¨¡å‹çš„æƒé‡ã€‚
- ä¸‹è½½æƒé‡åï¼Œéœ€è¦ä½¿ç”¨[è½¬æ¢è„šæœ¬](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py)å°†å…¶è½¬æ¢ä¸ºHugging Face Transformersæ ¼å¼ã€‚å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è°ƒç”¨è„šæœ¬ï¼ˆç¤ºä¾‹ï¼‰ï¼š

```bash
python src/transformers/models/llama/convert_llama_weights_to_hf.py \
    --input_dir /path/to/downloaded/llama/weights --model_size 7B --output_dir /output/path
```

- è½¬æ¢åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨ï¼š

```python
from transformers import LlamaForCausalLM, LlamaTokenizer

tokenizer = LlamaTokenizer.from_pretrained("/output/path")
model = LlamaForCausalLM.from_pretrained("/output/path")
```

è¯·æ³¨æ„ï¼Œæ‰§è¡Œè„šæœ¬éœ€è¦è¶³å¤Ÿçš„CPU RAMä»¥å­˜å‚¨æ•´ä¸ªæ¨¡å‹çš„float16ç²¾åº¦ï¼ˆå³ä½¿æœ€å¤§ç‰ˆæœ¬æ˜¯ç”±å¤šä¸ªæ£€æŸ¥ç‚¹ç»„æˆçš„ï¼Œæ¯ä¸ªæ£€æŸ¥ç‚¹éƒ½åŒ…å«æ¨¡å‹çš„ä¸€éƒ¨åˆ†æƒé‡ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦åŠ è½½å®ƒä»¬çš„å…¨éƒ¨å†…å®¹ï¼‰ã€‚å¯¹äº65Bæ¨¡å‹ï¼Œéœ€è¦130GBçš„RAMã€‚

- LLaMAåˆ†è¯å™¨æ˜¯åŸºäº[sentencepiece](https://github.com/google/sentencepiece)çš„BPEæ¨¡å‹ã€‚sentencepieceçš„ä¸€ä¸ªç‰¹æ®Šä¹‹å¤„æ˜¯ï¼Œåœ¨è§£ç åºåˆ—æ—¶ï¼Œå¦‚æœç¬¬ä¸€ä¸ªæ ‡è®°æ˜¯å•è¯çš„å¼€å¤´ï¼ˆä¾‹å¦‚"Banana"ï¼‰ï¼Œåˆ†è¯å™¨ä¸ä¼šåœ¨å­—ç¬¦ä¸²å‰æ·»åŠ å‰ç¼€ç©ºæ ¼ã€‚

æ­¤æ¨¡å‹ç”±[zphang](https://huggingface.co/zphang)è´¡çŒ®ï¼Œå¹¶å¾—åˆ°[BlackSamorez](https://huggingface.co/BlackSamorez)çš„è´¡çŒ®ã€‚Hugging Faceå®ç°çš„ä»£ç åŸºäºGPT-NeoXçš„ä»£ç [æ­¤å¤„](https://github.com/EleutherAI/gpt-neox)ã€‚åŸå§‹ä½œè€…çš„ä»£ç å¯ä»¥åœ¨[æ­¤å¤„](https://github.com/facebookresearch/llama)æ‰¾åˆ°ã€‚


åŸºäºåŸå§‹LLaMAæ¨¡å‹ï¼ŒMeta AIå‘å¸ƒäº†ä¸€äº›åç»­ä½œå“ï¼š

- **Llama2**ï¼šLlama2æ˜¯Llamaçš„æ”¹è¿›ç‰ˆæœ¬ï¼Œå…·æœ‰ä¸€äº›æ¶æ„è°ƒæ•´ï¼ˆGrouped Query Attentionï¼‰ï¼Œå¹¶é¢„è®­ç»ƒ2ä¸‡äº¿ä¸ªæ ‡è®°ã€‚è¯¦ç»†ä¿¡æ¯å¯å‚è§[Llama2](llama2)çš„æ–‡æ¡£ã€‚

## èµ„æº

ä»¥ä¸‹æ˜¯å®˜æ–¹Hugging Faceå’Œç¤¾åŒºï¼ˆç”±ğŸŒæ ‡ç¤ºï¼‰èµ„æºåˆ—è¡¨ï¼Œå¯å¸®åŠ©ä½ å…¥é—¨LLaMAã€‚å¦‚æœä½ æœ‰å…´è¶£æä¾›èµ„æºä»¥åŒ…å«åœ¨æ­¤å¤„ï¼Œè¯·éšæ—¶å‘èµ·æ‹‰å–è¯·æ±‚ï¼Œæˆ‘ä»¬å°†è¿›è¡Œè¯„å®¡ï¼è¯¥èµ„æºåº”è¯¥æœ€å¥½å±•ç¤ºä¸€äº›æ–°çš„ä¸œè¥¿ï¼Œè€Œä¸æ˜¯é‡å¤ç°æœ‰çš„èµ„æºã€‚

<PipelineTag pipeline="text-classification"/>

- ä¸€ä»½å…³äºå¦‚ä½•ä½¿ç”¨prompt tuningæ¥é€‚åº”LLaMAæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„[ç¬”è®°æœ¬](https://colab.research.google.com/github/bigscience-workshop/petals/blob/main/examples/prompt-tuning-sst2.ipynb#scrollTo=f04ba4d2)ã€‚ğŸŒ

<PipelineTag pipeline="question-answering"/>

- [StackLLaMAï¼šä½¿ç”¨RLHFè®­ç»ƒLLaMAçš„å®è·µæŒ‡å—](https://huggingface.co/blog/stackllama#stackllama-a-hands-on-guide-to-train-llama-with-rlhf)ï¼Œä¸€ç¯‡å…³äºå¦‚ä½•ä½¿ç”¨RLHFåœ¨[Stack Exchange](https://stackexchange.com/)ä¸Šè®­ç»ƒLLaMAæ¥å›ç­”é—®é¢˜çš„åšæ–‡ã€‚

âš—ï¸ ä¼˜åŒ–
- ä¸€ä»½å…³äºå¦‚ä½•ä½¿ç”¨xturingåº“åœ¨æœ‰é™çš„GPUå†…å­˜ä¸Šå¾®è°ƒLLaMAæ¨¡å‹çš„[ç¬”è®°æœ¬](https://colab.research.google.com/drive/1SQUXq1AMZPSLD4mk3A3swUIc6Y2dclme?usp=sharing)ã€‚ğŸŒ

âš¡ï¸ æ¨ç†
- ä¸€ä»½å…³äºå¦‚ä½•ä½¿ç”¨ğŸ¤—PEFTåº“ä¸­çš„PeftModelè¿è¡ŒLLaMAæ¨¡å‹çš„[ç¬”è®°æœ¬](https://colab.research.google.com/github/DominguesM/alpaca-lora-ptbr-7b/blob/main/notebooks/02%20-%20Evaluate.ipynb)ã€‚ğŸŒ
- ä¸€ä»½å…³äºå¦‚ä½•ä½¿ç”¨LangChainåŠ è½½PEFTé€‚é…å™¨LLaMAæ¨¡å‹çš„[ç¬”è®°æœ¬](https://colab.research.google.com/drive/1l2GiSSPbajVyp2Nk3CFT4t3uH6-5TiBe?usp=sharing)ã€‚ğŸŒ

ğŸš€ éƒ¨ç½²
- ä¸€ä»½å…³äºå¦‚ä½•ä½¿ç”¨ğŸ¤—PEFTåº“é€šè¿‡LoRAæ–¹æ³•å¾®è°ƒLLaMAæ¨¡å‹çš„[ç¬”è®°æœ¬](https://colab.research.google.com/github/lxe/simple-llama-finetuner/blob/master/Simple_LLaMA_FineTuner.ipynb#scrollTo=3PM_DilAZD8T)ã€‚ğŸŒ
- ä¸€ä»½å…³äºå¦‚ä½•åœ¨Amazon SageMakerä¸Šéƒ¨ç½²ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„Open-LLaMAæ¨¡å‹çš„[ç¬”è®°æœ¬](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/text-generation-open-llama.ipynb)ã€‚ğŸŒ

## LlamaConfig

[[autodoc]] LlamaConfig


## LlamaTokenizer

[[autodoc]] LlamaTokenizer
    - build_inputs_with_special_tokens
    - get_special_tokens_mask
    - create_token_type_ids_from_sequences
    - save_vocabulary

## LlamaTokenizerFast

[[autodoc]] LlamaTokenizerFast
    - build_inputs_with_special_tokens
    - get_special_tokens_mask
    - create_token_type_ids_from_sequences
    - update_post_processor
    - save_vocabulary

## LlamaModel

[[autodoc]] LlamaModel
    - forward


## LlamaForCausalLM

[[autodoc]] LlamaForCausalLM
    - forward

## LlamaForSequenceClassification

[[autodoc]] LlamaForSequenceClassification
    - forward