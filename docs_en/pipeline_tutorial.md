<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# Pipelinesç”¨äºæ¨ç†

[`pipeline`]ä½¿å¾—åœ¨ä»»ä½•è¯­è¨€ã€è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸Šä½¿ç”¨[Hub](https://huggingface.co/models)ä¸­çš„ä»»ä½•æ¨¡å‹å˜å¾—éå¸¸ç®€å•ã€‚å³ä½¿æ‚¨å¯¹ç‰¹å®šæ¨¡æ€æ²¡æœ‰ç»éªŒæˆ–ä¸ç†Ÿæ‚‰æ¨¡å‹èƒŒåçš„åº•å±‚ä»£ç ï¼Œæ‚¨ä»ç„¶å¯ä»¥ä½¿ç”¨[`pipeline`]è¿›è¡Œæ¨ç†ï¼æœ¬æ•™ç¨‹å°†æ•™æ‚¨ï¼š

- ä½¿ç”¨[`pipeline`]è¿›è¡Œæ¨ç†ã€‚
- ä½¿ç”¨ç‰¹å®šçš„åˆ†è¯å™¨æˆ–æ¨¡å‹ã€‚
- åœ¨éŸ³é¢‘ã€è§†è§‰å’Œå¤šæ¨¡æ€ä»»åŠ¡ä¸­ä½¿ç”¨[`pipeline`]ã€‚

<Tip>

æŸ¥çœ‹[`pipeline`]æ–‡æ¡£ï¼Œä»¥è·å–æ”¯æŒçš„ä»»åŠ¡åˆ—è¡¨å’Œå¯ç”¨å‚æ•°çš„å®Œæ•´ä¿¡æ¯ã€‚

</Tip>

## Pipeline usage

è™½ç„¶æ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªç›¸å…³è”çš„[`pipeline`]ï¼Œä½†ä½¿ç”¨é€šç”¨çš„[`pipeline`]æŠ½è±¡æ›´ä¸ºç®€å•ï¼Œè¯¥æŠ½è±¡åŒ…å«äº†æ‰€æœ‰ç‰¹å®šä»»åŠ¡çš„pipelinesã€‚[`pipeline`]ä¼šè‡ªåŠ¨åŠ è½½é»˜è®¤æ¨¡å‹å’Œé€‚ç”¨äºæ‚¨ä»»åŠ¡çš„é¢„å¤„ç†ç±»ï¼Œä»¥å®ç°æ¨ç†åŠŸèƒ½ã€‚

1. é¦–å…ˆåˆ›å»ºä¸€ä¸ª[`pipeline`]å¹¶æŒ‡å®šä¸€ä¸ªæ¨ç†ä»»åŠ¡ï¼š

```py
>>> from transformers import pipeline

>>> generator = pipeline(task="automatic-speech-recognition")
```

2. å°†è¾“å…¥æ–‡æœ¬ä¼ é€’ç»™[`pipeline`]ï¼š

```py
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}
```

ç»“æœä¸ç¬¦åˆæ‚¨çš„æœŸæœ›ï¼Ÿè¯·æŸ¥çœ‹Hubä¸Šä¸€äº›[æœ€å—æ¬¢è¿çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«æ¨¡å‹](https://huggingface.co/models?pipeline_tag=automatic-speech-recognition&sort=downloads)ï¼Œçœ‹çœ‹æ˜¯å¦å¯ä»¥è·å¾—æ›´å¥½çš„è½¬å½•ç»“æœã€‚ 

è®©æˆ‘ä»¬å°è¯•ä¸€ä¸‹[openai/whisper-large](https://huggingface.co/openai/whisper-large)ï¼š

```py
>>> generator = pipeline(model="openai/whisper-large")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

ç°åœ¨çš„ç»“æœçœ‹èµ·æ¥æ›´å‡†ç¡®äº†ï¼

æˆ‘ä»¬é¼“åŠ±æ‚¨åœ¨Hubä¸Šå¯»æ‰¾é€‚ç”¨äºä¸åŒè¯­è¨€ã€ä¸“é—¨é’ˆå¯¹æ‚¨é¢†åŸŸçš„æ¨¡å‹ç­‰ã€‚æ‚¨å¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨ä¸ŠæŸ¥çœ‹å’Œæ¯”è¾ƒHubä¸Šçš„æ¨¡å‹ç»“æœï¼Œä»¥ç¡®å®šæ˜¯å¦ç¬¦åˆæ‚¨çš„éœ€æ±‚æˆ–æ˜¯å¦èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†ç‰¹æ®Šæƒ…å†µã€‚å¦‚æœæ‚¨æ²¡æœ‰æ‰¾åˆ°é€‚åˆæ‚¨ç”¨ä¾‹çš„æ¨¡å‹ï¼Œæ‚¨å§‹ç»ˆå¯ä»¥å¼€å§‹[è®­ç»ƒ](http://www.liuzard.com/training)è‡ªå·±çš„æ¨¡å‹ï¼

å¦‚æœæ‚¨æœ‰å¤šä¸ªè¾“å…¥ï¼Œæ‚¨å¯ä»¥å°†è¾“å…¥ä½œä¸ºåˆ—è¡¨ä¼ é€’ç»™[`pipeline`]ï¼š

```py
generator(
    [
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac",
        "https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/1.flac",
    ]
)
```

å¦‚æœæ‚¨æƒ³è¿­ä»£æ•´ä¸ªæ•°æ®é›†ï¼Œæˆ–è€…æƒ³å°†å…¶ç”¨äºWebæœåŠ¡å™¨ä¸­çš„æ¨ç†ï¼Œè¯·æŸ¥çœ‹ä¸“é—¨çš„éƒ¨åˆ†

[åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨pipelines](#using-pipelines-on-a-dataset)

[åœ¨WebæœåŠ¡å™¨ä¸Šä½¿ç”¨pipelines](pipeline_webserver.md)

## å‚æ•°

[`pipeline`]æ”¯æŒè®¸å¤šå‚æ•°ï¼›å…¶ä¸­ä¸€äº›æ˜¯ç‰¹å®šäºä»»åŠ¡çš„ï¼Œè€Œå¦ä¸€äº›æ˜¯é€‚ç”¨äºæ‰€æœ‰pipelinesçš„é€šç”¨å‚æ•°ã€‚
ä¸€èˆ¬æ¥è¯´ï¼Œæ‚¨å¯ä»¥åœ¨ä»»ä½•åœ°æ–¹æŒ‡å®šå‚æ•°ï¼š

```py
generator = pipeline(model="openai/whisper-large", my_parameter=1)
out = generator(...)  # This will use `my_parameter=1`.
out = generator(..., my_parameter=2)  # This will override and use `my_parameter=2`.
out = generator(...)  # This will go back to using `my_parameter=1`.
```

è®©æˆ‘ä»¬æŸ¥çœ‹ä¸‰ä¸ªé‡è¦çš„å‚æ•°ï¼š

### è®¾å¤‡ï¼ˆDeviceï¼‰

å¦‚æœæ‚¨ä½¿ç”¨`device=n`ï¼Œåˆ™[`pipeline`]ä¼šè‡ªåŠ¨å°†æ¨¡å‹æ”¾ç½®åœ¨æŒ‡å®šçš„è®¾å¤‡ä¸Šã€‚
æ— è®ºæ‚¨æ˜¯ä½¿ç”¨PyTorchè¿˜æ˜¯Tensorflowï¼Œéƒ½å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‚æ•°ã€‚

```py
generator = pipeline(model="openai/whisper-large", device=0)
```

å¦‚æœæ¨¡å‹å¯¹äºå•ä¸ªGPUæ¥è¯´å¤ªå¤§äº†ï¼Œæ‚¨å¯ä»¥å°†`device_map="auto"`è®¾ç½®ä¸ºå…è®¸ğŸ¤— [Accelerate](https://huggingface.co/docs/accelerate)è‡ªåŠ¨ç¡®å®šå¦‚ä½•åŠ è½½å’Œå­˜å‚¨æ¨¡å‹æƒé‡ã€‚

```py
#!pip install accelerate
generator = pipeline(model="openai/whisper-large", device_map="auto")
```

è¯·æ³¨æ„ï¼Œå¦‚æœä¼ é€’äº†`device_map="auto"`å‚æ•°ï¼Œåˆ™åœ¨å®ä¾‹åŒ–[`pipeline`]æ—¶ä¸éœ€è¦æ·»åŠ `device=device`å‚æ•°ï¼Œå¦åˆ™å¯èƒ½ä¼šé‡åˆ°ä¸€äº›æ„å¤–çš„è¡Œä¸ºï¼

### æ‰¹å¤„ç†å¤§å°ï¼ˆBatch sizeï¼‰

é»˜è®¤æƒ…å†µä¸‹ï¼Œpipelinesä¸ä¼šå¯¹æ¨ç†è¿›è¡Œæ‰¹å¤„ç†ï¼Œè¯¦ç»†åŸå› å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching)æ‰¾åˆ°ã€‚åŸå› æ˜¯æ‰¹å¤„ç†å¹¶ä¸ä¸€å®šæ›´å¿«ï¼Œè€Œä¸”åœ¨æŸäº›æƒ…å†µä¸‹å®é™…ä¸Šå¯èƒ½æ›´æ…¢ã€‚

ä½†æ˜¯ï¼Œå¦‚æœåœ¨æ‚¨çš„ç”¨ä¾‹ä¸­å¯ä»¥ä½¿ç”¨æ‰¹å¤„ç†ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹å¼ï¼š

```py
generator = pipeline(model="openai/whisper-large", device=0, batch_size=2)
audio_filenames = [f"audio_{i}.flac" for i in range(10)]
texts = generator(audio_filenames)
```

è¿™ä¼šå¯¹æä¾›çš„10ä¸ªéŸ³é¢‘æ–‡ä»¶è¿è¡Œpipelineï¼Œä½†å®ƒä¼šå°†å®ƒä»¬ä»¥2ä¸ªä¸€ç»„çš„æ‰¹æ¬¡ä¼ é€’ç»™æ¨¡å‹ï¼ˆæ¨¡å‹ä½äºGPUä¸Šï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹æ‰¹å¤„ç†å¯èƒ½æ›´æœ‰å¸®åŠ©ï¼‰ï¼Œè€Œæ— éœ€æ‚¨è¿›ä¸€æ­¥ç¼–å†™ä»»ä½•ä»£ç ã€‚ è¾“å‡ºåº”è¯¥å§‹ç»ˆä¸æ‚¨åœ¨æ²¡æœ‰æ‰¹å¤„ç†çš„æƒ…å†µä¸‹æ¥æ”¶åˆ°çš„ç»“æœç›¸åŒ¹é…ã€‚è¿™åªæ˜¯ä¸€ç§å¸®åŠ©æ‚¨æé«˜pipelineé€Ÿåº¦çš„æ–¹å¼ã€‚

pipelinesè¿˜å¯ä»¥å‡è½»æ‰¹å¤„ç†çš„ä¸€äº›å¤æ‚æ€§ï¼Œå› ä¸ºå¯¹äºæŸäº›pipelinesæ¥è¯´ï¼Œéœ€è¦å°†å•ä¸ªé¡¹ç›®ï¼ˆå¦‚é•¿éŸ³é¢‘æ–‡ä»¶ï¼‰åˆ†æˆå¤šä¸ªéƒ¨åˆ†ä»¥ä¾›æ¨¡å‹å¤„ç†ã€‚pipelineä¼šä¸ºæ‚¨æ‰§è¡Œè¿™ç§[*chunk batching*](http://www.liuzard.com/main_classes/pipelines#pipeline-chunk-batching)ã€‚

### ç‰¹å®šä»»åŠ¡çš„å‚æ•°

æ‰€æœ‰ä»»åŠ¡éƒ½æä¾›ç‰¹å®šä»»åŠ¡çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°å…è®¸é¢å¤–çš„çµæ´»æ€§å’Œé€‰é¡¹ï¼Œä»¥å¸®åŠ©æ‚¨å®Œæˆå·¥ä½œã€‚ ä¾‹å¦‚ï¼Œ[`transformers.AutomaticSpeechRecognitionPipeline.__call__`]æ–¹æ³•å…·æœ‰ä¸€ä¸ª`return_timestamps`å‚æ•°ï¼Œå¯¹äºä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•ä¼¼ä¹æ˜¯ä¸€ä¸ªæœ‰å¸Œæœ›çš„é€‰æ‹©ï¼š

### ç‰¹å®šä»»åŠ¡çš„å‚æ•°

æ‰€æœ‰ä»»åŠ¡éƒ½æä¾›ç‰¹å®šä»»åŠ¡çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°å…è®¸é¢å¤–çš„çµæ´»æ€§å’Œé€‰é¡¹ï¼Œä»¥å¸®åŠ©æ‚¨å®Œæˆå·¥ä½œã€‚
ä¾‹å¦‚ï¼Œ[`transformers.AutomaticSpeechRecognitionPipeline.__call__`]æ–¹æ³•å…·æœ‰ä¸€ä¸ª`return_timestamps`å‚æ•°ï¼Œå¯¹äºä¸ºè§†é¢‘ç”Ÿæˆå­—å¹•ä¼¼ä¹æ˜¯ä¸€ä¸ªæœ‰å¸Œæœ›çš„é€‰æ‹©ï¼š


```py
>>> # Not using whisper, as it cannot provide timestamps.
>>> generator = pipeline(model="facebook/wav2vec2-large-960h-lv60-self", return_timestamps="word")
>>> generator("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP AND LIVE OUT THE TRUE MEANING OF ITS CREED', 'chunks': [{'text': 'I', 'timestamp': (1.22, 1.24)}, {'text': 'HAVE', 'timestamp': (1.42, 1.58)}, {'text': 'A', 'timestamp': (1.66, 1.68)}, {'text': 'DREAM', 'timestamp': (1.76, 2.14)}, {'text': 'BUT', 'timestamp': (3.68, 3.8)}, {'text': 'ONE', 'timestamp': (3.94, 4.06)}, {'text': 'DAY', 'timestamp': (4.16, 4.3)}, {'text': 'THIS', 'timestamp': (6.36, 6.54)}, {'text': 'NATION', 'timestamp': (6.68, 7.1)}, {'text': 'WILL', 'timestamp': (7.32, 7.56)}, {'text': 'RISE', 'timestamp': (7.8, 8.26)}, {'text': 'UP', 'timestamp': (8.38, 8.48)}, {'text': 'AND', 'timestamp': (10.08, 10.18)}, {'text': 'LIVE', 'timestamp': (10.26, 10.48)}, {'text': 'OUT', 'timestamp': (10.58, 10.7)}, {'text': 'THE', 'timestamp': (10.82, 10.9)}, {'text': 'TRUE', 'timestamp': (10.98, 11.18)}, {'text': 'MEANING', 'timestamp': (11.26, 11.58)}, {'text': 'OF', 'timestamp': (11.66, 11.7)}, {'text': 'ITS', 'timestamp': (11.76, 11.88)}, {'text': 'CREED', 'timestamp': (12.0, 12.38)}]}
```

æ­£å¦‚æ‚¨æ‰€è§ï¼Œæ¨¡å‹æ¨æ–­å‡ºäº†æ–‡æœ¬ï¼Œå¹¶è¾“å‡ºäº†å¥å­ä¸­å„ä¸ªå•è¯çš„å‘éŸ³æ—¶é—´ã€‚

æ¯ä¸ªä»»åŠ¡éƒ½æœ‰è®¸å¤šå¯ç”¨çš„å‚æ•°ï¼Œå› æ­¤è¯·æŸ¥çœ‹æ¯ä¸ªä»»åŠ¡çš„APIå‚è€ƒï¼Œäº†è§£æ‚¨å¯ä»¥è¿›è¡Œå“ªäº›è°ƒæ•´ï¼ä¾‹å¦‚ï¼Œ[`~transformers.AutomaticSpeechRecognitionPipeline`]å…·æœ‰ä¸€ä¸ª`chunk_length_s`å‚æ•°ï¼Œå¯¹äºå¤„ç†éå¸¸é•¿çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼Œä¸ºæ•´éƒ¨ç”µå½±æˆ–é•¿è¾¾ä¸€å°æ—¶çš„è§†é¢‘æ·»åŠ å­—å¹•ï¼‰éå¸¸æœ‰å¸®åŠ©ã€‚è¿™æ ·çš„éŸ³é¢‘æ–‡ä»¶é€šå¸¸ä¸€ä¸ªæ¨¡å‹æ— æ³•ç‹¬è‡ªå¤„ç†ã€‚

å¦‚æœæ‚¨æ‰¾ä¸åˆ°çœŸæ­£æœ‰ç”¨çš„å‚æ•°ï¼Œè¯·éšæ—¶[æå‡ºè¯·æ±‚](https://github.com/huggingface/transformers/issues/new?assignees=&labels=feature&template=feature-request.yml)ï¼

## åœ¨æ•°æ®é›†ä¸Šä½¿ç”¨pipelines

pipelineè¿˜å¯ä»¥åœ¨å¤§å‹æ•°æ®é›†ä¸Šè¿è¡Œæ¨ç†ã€‚æˆ‘ä»¬å»ºè®®çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨è¿­ä»£å™¨ï¼š

```py
def data():
    for i in range(1000):
        yield f"My example {i}"


pipe = pipeline(model="gpt2", device=0)
generated_characters = 0
for out in pipe(data()):
    generated_characters += len(out[0]["generated_text"])
```

è¿­ä»£å™¨`data()`ä¼šé€ä¸ªç”Ÿæˆç»“æœï¼Œè€Œpipelineä¼šè‡ªåŠ¨è¯†åˆ«è¾“å…¥ä¸ºå¯è¿­ä»£å¯¹è±¡ï¼Œå¹¶åœ¨ç»§ç»­åœ¨GPUä¸Šå¤„ç†æ•°æ®çš„åŒæ—¶å¼€å§‹è·å–æ•°æ®ï¼ˆè¿™åœ¨åº•å±‚ä½¿ç”¨äº†[DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)ï¼‰ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºæ‚¨ä¸éœ€è¦ä¸ºæ•´ä¸ªæ•°æ®é›†åˆ†é…å†…å­˜ï¼Œå¯ä»¥å°½å¯èƒ½å¿«åœ°å°†æ•°æ®æä¾›ç»™GPUã€‚

ç”±äºæ‰¹å¤„ç†å¯èƒ½åŠ å¿«é€Ÿåº¦ï¼Œè°ƒæ•´`batch_size`å‚æ•°å¯èƒ½ä¼šæœ‰æ‰€å¸®åŠ©ã€‚

è¿­ä»£æ•´ä¸ªæ•°æ®é›†çš„æœ€ç®€å•æ–¹æ³•å°±æ˜¯ä»ğŸ¤— [Datasets](https://github.com/huggingface/datasets/)ä¸­åŠ è½½æ•°æ®é›†ï¼š

```py
# KeyDataset is a util that will just output the item we're interested in.
from transformers.pipelines.pt_utils import KeyDataset
from datasets import load_dataset

pipe = pipeline(model="hf-internal-testing/tiny-random-wav2vec2", device=0)
dataset = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation[:10]")

for out in pipe(KeyDataset(dataset, "audio")):
    print(out)
```

## ä½¿ç”¨pipelinesæ„å»ºWebæœåŠ¡å™¨

<Tip> åˆ›å»ºæ¨ç†å¼•æ“æ˜¯ä¸€ä¸ªå¤æ‚çš„ä¸»é¢˜ï¼Œå€¼å¾—æ‹¥æœ‰è‡ªå·±çš„é¡µé¢ã€‚ </Tip>

[é“¾æ¥](http://www.liuzard.com/pipeline_webserver)

## è§†è§‰ä»»åŠ¡çš„pipeline

å¯¹äºè§†è§‰ä»»åŠ¡ï¼Œä½¿ç”¨[`pipeline`]å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚

æŒ‡å®šæ‚¨çš„ä»»åŠ¡ï¼Œå¹¶å°†å›¾åƒä¼ é€’ç»™åˆ†ç±»å™¨ã€‚å›¾åƒå¯ä»¥æ˜¯é“¾æ¥ã€æœ¬åœ°è·¯å¾„æˆ–Base64ç¼–ç çš„å›¾åƒã€‚ä¾‹å¦‚ï¼Œä¸‹é¢æ˜¾ç¤ºçš„æ˜¯å“ªç§çŒ«çš„å“ç§ï¼Ÿ

![pipeline-cat-chonk](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg)

```py
>>> from transformers import pipeline

>>> vision_classifier = pipeline(model="google/vit-base-patch16-224")
>>> preds = vision_classifier(
...     images="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4335, 'label': 'lynx, catamount'}, {'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}, {'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}, {'score': 0.0239, 'label': 'Egyptian cat'}, {'score': 0.0229, 'label': 'tiger cat'}]
```

## æ–‡æœ¬ä»»åŠ¡çš„pipeline

å¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ï¼Œä½¿ç”¨[`pipeline`]å‡ ä¹æ˜¯ç›¸åŒçš„ã€‚

```py
>>> from transformers import pipeline

>>> # This model is a `zero-shot-classification` model.
>>> # It will classify text, except you are free to choose any label you might imagine
>>> classifier = pipeline(model="facebook/bart-large-mnli")
>>> classifier(
...     "I have a problem with my iphone that needs to be resolved asap!!",
...     candidate_labels=["urgent", "not urgent", "phone", "tablet", "computer"],
... )
{'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}
```

## å¤šæ¨¡æ€ä»»åŠ¡çš„pipeline

[`pipeline`]æ”¯æŒå¤šä¸ªæ¨¡æ€ã€‚ä¾‹å¦‚ï¼Œè§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ç»“åˆäº†æ–‡æœ¬å’Œå›¾åƒã€‚æ‚¨å¯ä»¥éšæ„ä½¿ç”¨ä»»ä½•æ‚¨å–œæ¬¢çš„å›¾åƒé“¾æ¥å’Œè¦æå‡ºçš„é—®é¢˜ã€‚å›¾åƒå¯ä»¥æ˜¯URLæˆ–æŒ‡å‘å›¾åƒçš„æœ¬åœ°è·¯å¾„ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨è¿™å¼ [å‘ç¥¨å›¾åƒ](https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png)ï¼š

```py
>>> from transformers import pipeline

>>> vqa = pipeline(model="impira/layoutlm-document-qa")
>>> vqa(
...     image="https://huggingface.co/spaces/impira/docquery/resolve/2359223c1837a7587402bda0f2643382a6eefeab/invoice.png",
...     question="What is the invoice number?",
... )
[{'score': 0.42515, 'answer': 'us-001', 'start': 16, 'end': 16}]
```

<Tip>

è¦è¿è¡Œä¸Šé¢çš„ç¤ºä¾‹ï¼Œé™¤äº†ğŸ¤— Transformersä¹‹å¤–ï¼Œæ‚¨è¿˜éœ€è¦å®‰è£…[`pytesseract`](https://pypi.org/project/pytesseract/)ï¼š

```bash
sudo apt install -y tesseract-ocr
pip install pytesseract
```

</Tip>

## ä½¿ç”¨`pipeline`å¤„ç†å¤§å‹æ¨¡å‹ä¸ğŸ¤— `accelerate`ï¼š

æ‚¨å¯ä»¥ä½¿ç”¨ğŸ¤— `accelerate`è½»æ¾åœ°åœ¨å¤§å‹æ¨¡å‹ä¸Šè¿è¡Œ`pipeline`ï¼é¦–å…ˆç¡®ä¿å·²ç»ä½¿ç”¨`pip install accelerate`å®‰è£…äº†`accelerate`ã€‚

é¦–å…ˆä½¿ç”¨`device_map="auto"`åŠ è½½æ‚¨çš„æ¨¡å‹ï¼æˆ‘ä»¬å°†åœ¨ç¤ºä¾‹ä¸­ä½¿ç”¨`facebook/opt-1.3b`ã€‚

```py
# pip install accelerate
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", torch_dtype=torch.bfloat16, device_map="auto")
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

å¦‚æœæ‚¨å®‰è£…äº†`bitsandbytes`å¹¶æ·»åŠ äº†å‚æ•°`load_in_8bit=True`ï¼Œè¿˜å¯ä»¥ä¼ é€’åŠ è½½çš„8ä½æ¨¡å‹ã€‚

```py
# pip install accelerate bitsandbytes
import torch
from transformers import pipeline

pipe = pipeline(model="facebook/opt-1.3b", device_map="auto", model_kwargs={"load_in_8bit": True})
output = pipe("This is a cool example!", do_sample=True, top_p=0.95)
```

è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥å°†æ£€æŸ¥ç‚¹æ›¿æ¢ä¸ºä»»ä½•æ”¯æŒå¤§æ¨¡å‹åŠ è½½çš„Hugging Faceæ¨¡å‹ï¼Œä¾‹å¦‚BLOOMï¼
